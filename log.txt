namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0100, time: 12.50
[000001] f: 3.600, acc: 10.00, fv: 3.584, accv: 10.00, lr: 0.0100, time: 10.03
[000063] f: 1.854, acc: 30.53, fv: 1.848, accv: 30.11, lr: 0.0100, time: 10.15
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0100, time: 16.81
[000001] f: 4.715, acc: 10.00, fv: 4.234, accv: 10.00, lr: 0.0100, time: 14.48
[000063] f: 1.854, acc: 32.54, fv: 1.833, accv: 32.83, lr: 0.0100, time: 14.49
[000125] f: 1.692, acc: 38.16, fv: 1.698, accv: 36.79, lr: 0.0100, time: 16.71
[000187] f: 1.537, acc: 46.07, fv: 1.524, accv: 44.51, lr: 0.0100, time: 17.48
[000249] f: 1.410, acc: 50.27, fv: 1.425, accv: 48.76, lr: 0.0100, time: 15.38
[000251] f: 1.359, acc: 51.75, fv: 1.356, accv: 51.10, lr: 0.0100, time: 16.59
[000313] f: 1.253, acc: 56.13, fv: 1.249, accv: 55.62, lr: 0.0100, time: 17.49
[000375] f: 1.192, acc: 58.73, fv: 1.202, accv: 58.21, lr: 0.0100, time: 15.65
[000437] f: 1.204, acc: 56.94, fv: 1.251, accv: 55.37, lr: 0.0100, time: 17.30
[000499] f: 1.145, acc: 60.10, fv: 1.195, accv: 57.58, lr: 0.0100, time: 15.82
[000501] f: 1.150, acc: 60.05, fv: 1.186, accv: 57.97, lr: 0.0100, time: 15.73
[000563] f: 1.001, acc: 65.55, fv: 0.993, accv: 65.19, lr: 0.0100, time: 16.12
[000625] f: 0.987, acc: 64.92, fv: 1.017, accv: 64.02, lr: 0.0100, time: 15.18
[000687] f: 1.073, acc: 63.38, fv: 1.123, accv: 62.34, lr: 0.0100, time: 16.62
[000749] f: 0.895, acc: 69.20, fv: 0.911, accv: 68.05, lr: 0.0100, time: 17.99
[000751] f: 0.918, acc: 68.19, fv: 0.951, accv: 66.94, lr: 0.0100, time: 15.51
[000813] f: 1.031, acc: 64.82, fv: 1.043, accv: 64.61, lr: 0.0100, time: 17.29
[000875] f: 1.078, acc: 63.79, fv: 1.259, accv: 61.01, lr: 0.0100, time: 15.32
[000937] f: 0.811, acc: 72.49, fv: 0.818, accv: 71.54, lr: 0.0100, time: 15.23
[000999] f: 0.815, acc: 72.37, fv: 0.852, accv: 70.50, lr: 0.0100, time: 15.05
[001001] f: 0.818, acc: 72.37, fv: 0.873, accv: 70.14, lr: 0.0100, time: 17.14
[001063] f: 0.795, acc: 72.63, fv: 0.882, accv: 70.42, lr: 0.0100, time: 15.93
[001125] f: 0.891, acc: 69.58, fv: 0.964, accv: 68.09, lr: 0.0100, time: 16.12
[001187] f: 0.751, acc: 74.01, fv: 0.770, accv: 73.46, lr: 0.0100, time: 16.20
[001249] f: 0.759, acc: 73.71, fv: 0.838, accv: 71.96, lr: 0.0100, time: 16.49
[001500] f: 0.634, acc: 78.29, fv: 0.692, accv: 76.15, lr: 0.0100, time: 17.88
[001750] f: 0.579, acc: 80.43, fv: 0.670, accv: 77.15, lr: 0.0100, time: 17.26
[002000] f: 0.609, acc: 78.80, fv: 0.676, accv: 76.60, lr: 0.0100, time: 18.16
[002250] f: 0.586, acc: 79.77, fv: 0.650, accv: 77.50, lr: 0.0100, time: 16.32
[002500] f: 0.575, acc: 80.18, fv: 0.677, accv: 77.03, lr: 0.0099, time: 18.43
[002750] f: 0.547, acc: 81.30, fv: 0.625, accv: 78.65, lr: 0.0099, time: 17.28
[003000] f: 0.470, acc: 83.91, fv: 0.560, accv: 80.78, lr: 0.0099, time: 19.87
[003250] f: 0.456, acc: 84.52, fv: 0.554, accv: 81.01, lr: 0.0099, time: 16.79
[003500] f: 0.456, acc: 84.43, fv: 0.569, accv: 80.93, lr: 0.0099, time: 17.43
[003750] f: 0.403, acc: 86.39, fv: 0.520, accv: 82.69, lr: 0.0099, time: 17.56
[004000] f: 0.411, acc: 85.92, fv: 0.527, accv: 82.29, lr: 0.0098, time: 17.42
[004250] f: 0.391, acc: 86.72, fv: 0.523, accv: 82.27, lr: 0.0098, time: 16.70
[004500] f: 0.404, acc: 85.87, fv: 0.539, accv: 81.55, lr: 0.0098, time: 16.66
[004750] f: 0.447, acc: 84.04, fv: 0.592, accv: 80.33, lr: 0.0098, time: 16.86
[005000] f: 0.445, acc: 84.53, fv: 0.628, accv: 80.75, lr: 0.0098, time: 16.50
[005250] f: 0.344, acc: 87.79, fv: 0.512, accv: 83.08, lr: 0.0097, time: 18.82
[005500] f: 0.415, acc: 85.80, fv: 0.598, accv: 81.19, lr: 0.0097, time: 16.69
[005750] f: 0.359, acc: 87.47, fv: 0.569, accv: 82.22, lr: 0.0097, time: 17.56
[006000] f: 0.340, acc: 88.05, fv: 0.491, accv: 83.37, lr: 0.0096, time: 16.69
[006250] f: 0.341, acc: 88.09, fv: 0.485, accv: 84.01, lr: 0.0096, time: 17.47
[006500] f: 0.304, acc: 89.57, fv: 0.502, accv: 84.22, lr: 0.0096, time: 16.74
[007250] f: 0.304, acc: 89.35, fv: 0.495, accv: 83.80, lr: 0.0095, time: 16.77
[008250] f: 0.295, acc: 89.63, fv: 0.526, accv: 83.54, lr: 0.0093, time: 16.59
[009250] f: 0.334, acc: 88.14, fv: 0.572, accv: 83.19, lr: 0.0092, time: 16.97
[010250] f: 0.243, acc: 91.40, fv: 0.499, accv: 84.60, lr: 0.0090, time: 17.47
[011250] f: 0.229, acc: 91.82, fv: 0.492, accv: 85.32, lr: 0.0088, time: 19.32
[012250] f: 0.250, acc: 91.30, fv: 0.568, accv: 83.51, lr: 0.0086, time: 17.21
[013250] f: 0.209, acc: 92.54, fv: 0.537, accv: 84.84, lr: 0.0084, time: 17.95
[014250] f: 0.159, acc: 94.48, fv: 0.489, accv: 85.61, lr: 0.0081, time: 17.21
[015250] f: 0.148, acc: 94.76, fv: 0.496, accv: 86.20, lr: 0.0079, time: 16.91
[016250] f: 0.183, acc: 93.46, fv: 0.554, accv: 84.61, lr: 0.0076, time: 16.26
[019000] f: 0.109, acc: 96.24, fv: 0.507, accv: 86.51, lr: 0.0068, time: 17.27
[022750] f: 0.091, acc: 96.73, fv: 0.532, accv: 86.67, lr: 0.0057, time: 16.28
[026500] f: 0.065, acc: 97.82, fv: 0.546, accv: 86.55, lr: 0.0045, time: 16.42
[030250] f: 0.047, acc: 98.58, fv: 0.563, accv: 86.81, lr: 0.0034, time: 17.67
[034000] f: 0.032, acc: 99.08, fv: 0.561, accv: 87.30, lr: 0.0023, time: 17.02
[037750] f: 0.022, acc: 99.43, fv: 0.589, accv: 87.46, lr: 0.0014, time: 16.53
[041500] f: 0.017, acc: 99.63, fv: 0.581, accv: 87.60, lr: 0.0007, time: 15.95
[045250] f: 0.015, acc: 99.69, fv: 0.581, accv: 87.66, lr: 0.0002, time: 14.25
[049000] f: 0.014, acc: 99.75, fv: 0.586, accv: 87.68, lr: 0.0000, time: 14.06
[050000] f: 0.014, acc: 99.74, fv: 0.586, accv: 87.58, lr: 0.0000, time: 13.94
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0100, time: 12.45
[000001] f: 2.303, acc: 12.94, fv: 2.303, accv: 12.70, lr: 0.0100, time: 9.80
[000063] f: 1.864, acc: 36.66, fv: 1.862, accv: 36.94, lr: 0.0100, time: 10.22
[000125] f: 1.787, acc: 40.93, fv: 1.787, accv: 40.39, lr: 0.0100, time: 10.75
[000187] f: 1.743, acc: 43.68, fv: 1.745, accv: 42.94, lr: 0.0100, time: 10.91
[000249] f: 1.712, acc: 45.54, fv: 1.715, accv: 45.15, lr: 0.0100, time: 13.59
[000251] f: 1.730, acc: 44.22, fv: 1.733, accv: 44.13, lr: 0.0100, time: 10.74
[000313] f: 1.671, acc: 48.14, fv: 1.676, accv: 47.18, lr: 0.0100, time: 12.05
[000375] f: 1.628, acc: 48.59, fv: 1.633, accv: 48.14, lr: 0.0100, time: 12.76
[000437] f: 1.628, acc: 47.55, fv: 1.634, accv: 47.25, lr: 0.0100, time: 11.06
[000499] f: 1.589, acc: 50.58, fv: 1.598, accv: 50.09, lr: 0.0100, time: 12.61
[000501] f: 1.584, acc: 51.08, fv: 1.595, accv: 49.93, lr: 0.0100, time: 13.87
[000563] f: 1.572, acc: 51.81, fv: 1.585, accv: 50.61, lr: 0.0100, time: 10.48
[000625] f: 1.552, acc: 51.89, fv: 1.563, accv: 50.86, lr: 0.0100, time: 12.41
[000687] f: 1.532, acc: 52.57, fv: 1.546, accv: 51.16, lr: 0.0100, time: 11.76
[000749] f: 1.500, acc: 53.73, fv: 1.517, accv: 52.08, lr: 0.0100, time: 10.45
[000751] f: 1.506, acc: 51.92, fv: 1.522, accv: 50.54, lr: 0.0100, time: 12.63
[000813] f: 1.495, acc: 53.75, fv: 1.512, accv: 52.74, lr: 0.0100, time: 11.09
[000875] f: 1.475, acc: 54.67, fv: 1.492, accv: 53.60, lr: 0.0100, time: 11.59
[000937] f: 1.456, acc: 53.83, fv: 1.475, accv: 52.33, lr: 0.0100, time: 12.67
[000999] f: 1.446, acc: 55.03, fv: 1.469, accv: 53.36, lr: 0.0100, time: 10.79
[001001] f: 1.435, acc: 55.64, fv: 1.459, accv: 53.80, lr: 0.0100, time: 11.06
[001063] f: 1.417, acc: 55.94, fv: 1.435, accv: 54.41, lr: 0.0100, time: 12.21
[001125] f: 1.412, acc: 55.85, fv: 1.439, accv: 54.56, lr: 0.0100, time: 11.46
[001187] f: 1.390, acc: 56.59, fv: 1.412, accv: 55.48, lr: 0.0100, time: 12.22
[001249] f: 1.379, acc: 57.27, fv: 1.402, accv: 55.51, lr: 0.0100, time: 13.02
[001500] f: 1.327, acc: 59.63, fv: 1.357, accv: 57.71, lr: 0.0100, time: 11.59
[001750] f: 1.275, acc: 61.58, fv: 1.310, accv: 59.76, lr: 0.0100, time: 12.61
[002000] f: 1.211, acc: 62.75, fv: 1.253, accv: 60.46, lr: 0.0100, time: 11.37
[002250] f: 1.185, acc: 63.41, fv: 1.229, accv: 61.12, lr: 0.0100, time: 12.79
[002500] f: 1.145, acc: 64.85, fv: 1.192, accv: 62.55, lr: 0.0099, time: 12.37
[002750] f: 1.090, acc: 67.36, fv: 1.149, accv: 64.31, lr: 0.0099, time: 11.46
[003000] f: 1.088, acc: 66.78, fv: 1.144, accv: 64.44, lr: 0.0099, time: 13.13
[003250] f: 1.069, acc: 66.56, fv: 1.137, accv: 63.16, lr: 0.0099, time: 11.91
[003500] f: 0.991, acc: 69.89, fv: 1.064, accv: 66.53, lr: 0.0099, time: 12.52
[003750] f: 0.995, acc: 69.80, fv: 1.071, accv: 66.37, lr: 0.0099, time: 11.72
[004000] f: 0.958, acc: 70.45, fv: 1.042, accv: 66.07, lr: 0.0098, time: 12.09
[004250] f: 0.923, acc: 72.42, fv: 1.010, accv: 67.92, lr: 0.0098, time: 12.13
[004500] f: 0.923, acc: 71.83, fv: 1.019, accv: 66.96, lr: 0.0098, time: 12.87
[004750] f: 0.876, acc: 73.96, fv: 0.976, accv: 68.96, lr: 0.0098, time: 12.33
[005000] f: 0.859, acc: 74.02, fv: 0.961, accv: 69.47, lr: 0.0098, time: 12.83
[005250] f: 0.844, acc: 74.78, fv: 0.960, accv: 68.95, lr: 0.0097, time: 11.83
[005500] f: 0.796, acc: 76.80, fv: 0.915, accv: 70.91, lr: 0.0097, time: 11.74
[005750] f: 0.807, acc: 75.94, fv: 0.931, accv: 70.36, lr: 0.0097, time: 11.80
[006000] f: 0.767, acc: 77.96, fv: 0.899, accv: 71.35, lr: 0.0096, time: 11.63
[006250] f: 0.762, acc: 77.55, fv: 0.896, accv: 71.36, lr: 0.0096, time: 11.60
[006500] f: 0.743, acc: 78.59, fv: 0.886, accv: 71.25, lr: 0.0096, time: 13.46
[007250] f: 0.673, acc: 81.38, fv: 0.840, accv: 73.20, lr: 0.0095, time: 11.73
[008250] f: 0.613, acc: 83.41, fv: 0.812, accv: 73.52, lr: 0.0093, time: 12.33
[009250] f: 0.597, acc: 83.32, fv: 0.828, accv: 72.40, lr: 0.0092, time: 13.21
[010250] f: 0.503, acc: 87.63, fv: 0.771, accv: 75.31, lr: 0.0090, time: 12.07
[011250] f: 0.483, acc: 87.94, fv: 0.773, accv: 74.75, lr: 0.0088, time: 12.06
[012250] f: 0.429, acc: 89.99, fv: 0.756, accv: 75.29, lr: 0.0086, time: 11.53
[013250] f: 0.381, acc: 92.63, fv: 0.737, accv: 75.90, lr: 0.0084, time: 13.17
[014250] f: 0.332, acc: 94.22, fv: 0.714, accv: 76.80, lr: 0.0081, time: 12.66
[015250] f: 0.292, acc: 95.29, fv: 0.700, accv: 76.93, lr: 0.0079, time: 13.46
[016250] f: 0.272, acc: 95.75, fv: 0.706, accv: 76.92, lr: 0.0076, time: 12.94
[019000] f: 0.208, acc: 98.26, fv: 0.696, accv: 77.30, lr: 0.0068, time: 11.97
[022750] f: 0.141, acc: 99.39, fv: 0.681, accv: 77.55, lr: 0.0057, time: 13.59
[026500] f: 0.104, acc: 99.73, fv: 0.674, accv: 77.64, lr: 0.0045, time: 11.51
[030250] f: 0.083, acc: 99.91, fv: 0.672, accv: 77.71, lr: 0.0034, time: 12.11
[034000] f: 0.073, acc: 99.95, fv: 0.673, accv: 77.70, lr: 0.0023, time: 12.03
[037750] f: 0.067, acc: 99.94, fv: 0.670, accv: 77.72, lr: 0.0014, time: 11.30
[041500] f: 0.063, acc: 99.97, fv: 0.671, accv: 77.39, lr: 0.0007, time: 11.38
[045250] f: 0.062, acc: 99.97, fv: 0.671, accv: 77.46, lr: 0.0002, time: 10.34
[049000] f: 0.061, acc: 99.97, fv: 0.670, accv: 77.55, lr: 0.0000, time: 10.06
[050000] f: 0.062, acc: 99.97, fv: 0.670, accv: 77.49, lr: 0.0000, time: 9.93
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0100, time: 16.77
[000001] f: 2.303, acc: 11.13, fv: 2.303, accv: 13.80, lr: 0.0100, time: 14.24
[000063] f: 1.912, acc: 33.55, fv: 1.892, accv: 32.23, lr: 0.0100, time: 14.81
[000125] f: 1.851, acc: 37.38, fv: 1.826, accv: 36.15, lr: 0.0100, time: 16.60
[000187] f: 1.808, acc: 39.70, fv: 1.783, accv: 37.89, lr: 0.0100, time: 17.48
[000249] f: 1.771, acc: 41.92, fv: 1.743, accv: 40.62, lr: 0.0100, time: 15.70
[000251] f: 1.760, acc: 42.42, fv: 1.729, accv: 41.59, lr: 0.0100, time: 16.77
[000313] f: 1.730, acc: 42.14, fv: 1.699, accv: 42.65, lr: 0.0100, time: 16.14
[000375] f: 1.717, acc: 43.14, fv: 1.680, accv: 42.89, lr: 0.0100, time: 16.09
[000437] f: 1.679, acc: 45.13, fv: 1.651, accv: 44.55, lr: 0.0100, time: 15.92
[000499] f: 1.661, acc: 46.29, fv: 1.626, accv: 45.54, lr: 0.0100, time: 15.72
[000501] f: 1.661, acc: 46.37, fv: 1.632, accv: 45.45, lr: 0.0100, time: 15.01
[000563] f: 1.644, acc: 48.14, fv: 1.608, accv: 47.94, lr: 0.0100, time: 16.61
[000625] f: 1.619, acc: 48.14, fv: 1.585, accv: 48.22, lr: 0.0100, time: 14.63
[000687] f: 1.596, acc: 49.47, fv: 1.571, accv: 48.80, lr: 0.0100, time: 15.60
[000749] f: 1.585, acc: 48.76, fv: 1.556, accv: 48.03, lr: 0.0100, time: 16.24
[000751] f: 1.587, acc: 48.85, fv: 1.569, accv: 47.80, lr: 0.0100, time: 17.12
[000813] f: 1.569, acc: 49.62, fv: 1.539, accv: 49.44, lr: 0.0100, time: 15.39
[000875] f: 1.551, acc: 50.24, fv: 1.525, accv: 49.47, lr: 0.0100, time: 15.92
[000937] f: 1.528, acc: 50.88, fv: 1.499, accv: 50.26, lr: 0.0100, time: 16.39
[000999] f: 1.513, acc: 52.03, fv: 1.478, accv: 52.03, lr: 0.0100, time: 15.12
[001001] f: 1.528, acc: 51.21, fv: 1.498, accv: 50.41, lr: 0.0100, time: 16.37
[001063] f: 1.502, acc: 51.64, fv: 1.476, accv: 51.10, lr: 0.0100, time: 16.29
[001125] f: 1.480, acc: 53.06, fv: 1.455, accv: 52.12, lr: 0.0100, time: 15.06
[001187] f: 1.480, acc: 53.23, fv: 1.453, accv: 52.96, lr: 0.0100, time: 16.56
[001249] f: 1.478, acc: 52.66, fv: 1.449, accv: 52.18, lr: 0.0100, time: 16.26
[001500] f: 1.403, acc: 56.29, fv: 1.385, accv: 54.40, lr: 0.0100, time: 15.29
[001750] f: 1.365, acc: 57.11, fv: 1.353, accv: 55.22, lr: 0.0100, time: 16.13
[002000] f: 1.326, acc: 58.13, fv: 1.318, accv: 56.29, lr: 0.0100, time: 16.90
[002250] f: 1.301, acc: 58.18, fv: 1.295, accv: 56.98, lr: 0.0100, time: 15.67
[002500] f: 1.273, acc: 59.93, fv: 1.263, accv: 58.11, lr: 0.0099, time: 15.84
[002750] f: 1.221, acc: 61.30, fv: 1.226, accv: 59.21, lr: 0.0099, time: 16.64
[003000] f: 1.162, acc: 63.60, fv: 1.154, accv: 62.61, lr: 0.0099, time: 15.85
[003250] f: 1.190, acc: 60.42, fv: 1.194, accv: 59.75, lr: 0.0099, time: 16.27
[003500] f: 1.165, acc: 61.42, fv: 1.157, accv: 61.01, lr: 0.0099, time: 15.98
[003750] f: 1.112, acc: 65.51, fv: 1.107, accv: 64.59, lr: 0.0099, time: 16.35
[004000] f: 1.078, acc: 65.96, fv: 1.073, accv: 64.91, lr: 0.0098, time: 15.86
[004250] f: 1.050, acc: 67.00, fv: 1.054, accv: 65.69, lr: 0.0098, time: 16.85
[004500] f: 1.042, acc: 67.18, fv: 1.055, accv: 65.58, lr: 0.0098, time: 15.40
[004750] f: 1.074, acc: 64.65, fv: 1.090, accv: 63.24, lr: 0.0098, time: 15.30
[005000] f: 0.991, acc: 69.05, fv: 0.997, accv: 67.38, lr: 0.0098, time: 15.52
[005250] f: 0.976, acc: 68.35, fv: 0.986, accv: 67.09, lr: 0.0097, time: 16.63
[005500] f: 1.151, acc: 61.21, fv: 1.231, accv: 57.88, lr: 0.0097, time: 15.80
[005750] f: 0.967, acc: 69.64, fv: 0.982, accv: 67.57, lr: 0.0097, time: 15.57
[006000] f: 0.931, acc: 70.93, fv: 0.954, accv: 68.99, lr: 0.0096, time: 15.78
[006250] f: 0.900, acc: 71.90, fv: 0.906, accv: 70.22, lr: 0.0096, time: 17.52
[006500] f: 0.892, acc: 72.40, fv: 0.916, accv: 69.87, lr: 0.0096, time: 15.79
[007250] f: 0.868, acc: 72.85, fv: 0.893, accv: 70.55, lr: 0.0095, time: 15.99
[008250] f: 0.830, acc: 73.44, fv: 0.864, accv: 71.01, lr: 0.0093, time: 16.15
[009250] f: 0.768, acc: 76.16, fv: 0.804, accv: 73.35, lr: 0.0092, time: 15.96
[010250] f: 0.715, acc: 77.82, fv: 0.757, accv: 74.94, lr: 0.0090, time: 16.31
[011250] f: 0.683, acc: 78.76, fv: 0.727, accv: 75.70, lr: 0.0088, time: 15.39
[012250] f: 0.645, acc: 80.62, fv: 0.681, accv: 77.75, lr: 0.0086, time: 15.57
[013250] f: 0.619, acc: 81.01, fv: 0.660, accv: 77.88, lr: 0.0084, time: 17.11
[014250] f: 0.604, acc: 81.53, fv: 0.658, accv: 78.36, lr: 0.0081, time: 16.28
[015250] f: 0.573, acc: 82.85, fv: 0.630, accv: 79.35, lr: 0.0079, time: 16.98
[016250] f: 0.551, acc: 83.35, fv: 0.616, accv: 79.85, lr: 0.0076, time: 16.53
[019000] f: 0.507, acc: 84.78, fv: 0.577, accv: 80.97, lr: 0.0068, time: 17.83
[022750] f: 0.463, acc: 86.46, fv: 0.551, accv: 81.66, lr: 0.0057, time: 15.97
[026500] f: 0.415, acc: 88.26, fv: 0.511, accv: 82.97, lr: 0.0045, time: 16.16
[030250] f: 0.390, acc: 88.88, fv: 0.493, accv: 83.91, lr: 0.0034, time: 16.76
[034000] f: 0.367, acc: 89.75, fv: 0.481, accv: 83.83, lr: 0.0023, time: 15.95
[037750] f: 0.353, acc: 90.22, fv: 0.469, accv: 84.41, lr: 0.0014, time: 15.81
[041500] f: 0.343, acc: 90.72, fv: 0.460, accv: 84.77, lr: 0.0007, time: 16.03
[045250] f: 0.338, acc: 91.07, fv: 0.459, accv: 84.72, lr: 0.0002, time: 14.43
[049000] f: 0.335, acc: 91.00, fv: 0.458, accv: 84.73, lr: 0.0000, time: 14.46
[050000] f: 0.337, acc: 90.98, fv: 0.458, accv: 84.76, lr: 0.0000, time: 14.19
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.1000, time: 12.64
[000001] f: 2.300, acc: 11.15, fv: 2.300, accv: 11.16, lr: 0.1000, time: 10.06
[000063] f: 1.724, acc: 42.27, fv: 1.727, accv: 42.26, lr: 0.1000, time: 10.13
[000125] f: 1.636, acc: 45.22, fv: 1.639, accv: 45.08, lr: 0.1000, time: 10.49
[000187] f: 1.492, acc: 49.75, fv: 1.506, accv: 49.36, lr: 0.1000, time: 11.07
[000249] f: 1.466, acc: 50.78, fv: 1.483, accv: 49.33, lr: 0.1000, time: 10.62
[000251] f: 1.461, acc: 50.46, fv: 1.477, accv: 50.04, lr: 0.1000, time: 13.38
[000313] f: 1.383, acc: 54.23, fv: 1.409, accv: 52.68, lr: 0.1000, time: 11.36
[000375] f: 1.299, acc: 56.02, fv: 1.321, accv: 54.88, lr: 0.1000, time: 11.13
[000437] f: 1.260, acc: 57.75, fv: 1.288, accv: 56.11, lr: 0.1000, time: 11.73
[000499] f: 1.173, acc: 61.42, fv: 1.215, accv: 59.66, lr: 0.1000, time: 11.28
[000501] f: 1.256, acc: 57.29, fv: 1.294, accv: 55.50, lr: 0.1000, time: 15.48
[000563] f: 1.130, acc: 62.43, fv: 1.173, accv: 60.52, lr: 0.1000, time: 12.07
[000625] f: 1.110, acc: 62.94, fv: 1.155, accv: 60.88, lr: 0.1000, time: 11.56
[000687] f: 1.112, acc: 62.52, fv: 1.159, accv: 60.57, lr: 0.1000, time: 11.68
[000749] f: 1.018, acc: 66.50, fv: 1.070, accv: 64.04, lr: 0.0999, time: 11.17
[000751] f: 1.028, acc: 65.70, fv: 1.082, accv: 62.98, lr: 0.0999, time: 11.32
[000813] f: 0.978, acc: 67.79, fv: 1.040, accv: 64.58, lr: 0.0999, time: 12.20
[000875] f: 1.108, acc: 61.93, fv: 1.157, accv: 60.01, lr: 0.0999, time: 12.15
[000937] f: 0.965, acc: 68.40, fv: 1.034, accv: 65.00, lr: 0.0999, time: 12.41
[000999] f: 0.924, acc: 69.31, fv: 1.001, accv: 65.53, lr: 0.0999, time: 12.18
[001001] f: 0.945, acc: 68.12, fv: 1.018, accv: 64.94, lr: 0.0999, time: 12.81
[001063] f: 0.857, acc: 72.06, fv: 0.934, accv: 68.68, lr: 0.0999, time: 13.46
[001125] f: 0.873, acc: 71.37, fv: 0.956, accv: 67.91, lr: 0.0999, time: 12.98
[001187] f: 0.837, acc: 73.07, fv: 0.923, accv: 69.32, lr: 0.0999, time: 11.50
[001249] f: 0.854, acc: 71.72, fv: 0.932, accv: 68.77, lr: 0.0998, time: 11.96
[001500] f: 0.724, acc: 77.29, fv: 0.837, accv: 72.03, lr: 0.0998, time: 12.21
[001750] f: 0.640, acc: 80.43, fv: 0.770, accv: 74.53, lr: 0.0997, time: 12.39
[002000] f: 0.582, acc: 82.15, fv: 0.740, accv: 75.25, lr: 0.0996, time: 12.11
[002250] f: 0.529, acc: 83.78, fv: 0.710, accv: 75.65, lr: 0.0995, time: 12.20
[002500] f: 0.482, acc: 85.66, fv: 0.694, accv: 76.39, lr: 0.0994, time: 12.41
[002750] f: 0.413, acc: 88.29, fv: 0.669, accv: 77.57, lr: 0.0993, time: 12.88
[003000] f: 0.418, acc: 87.67, fv: 0.699, accv: 76.29, lr: 0.0991, time: 12.50
[003250] f: 0.343, acc: 91.11, fv: 0.659, accv: 78.14, lr: 0.0990, time: 13.22
[003500] f: 0.292, acc: 93.09, fv: 0.633, accv: 78.85, lr: 0.0988, time: 12.31
[003750] f: 0.274, acc: 93.56, fv: 0.653, accv: 77.78, lr: 0.0986, time: 14.45
[004000] f: 0.228, acc: 95.65, fv: 0.624, accv: 79.17, lr: 0.0984, time: 12.45
[004250] f: 0.195, acc: 96.64, fv: 0.617, accv: 79.02, lr: 0.0982, time: 12.54
[004500] f: 0.171, acc: 97.62, fv: 0.626, accv: 78.80, lr: 0.0980, time: 12.05
[004750] f: 0.127, acc: 98.80, fv: 0.611, accv: 79.40, lr: 0.0978, time: 12.32
[005000] f: 0.105, acc: 99.25, fv: 0.599, accv: 79.67, lr: 0.0976, time: 12.06
[005250] f: 0.091, acc: 99.56, fv: 0.604, accv: 79.84, lr: 0.0973, time: 12.17
[005500] f: 0.079, acc: 99.62, fv: 0.609, accv: 79.38, lr: 0.0970, time: 13.43
[005750] f: 0.064, acc: 99.89, fv: 0.600, accv: 79.77, lr: 0.0968, time: 12.13
[006000] f: 0.051, acc: 99.94, fv: 0.594, accv: 80.22, lr: 0.0965, time: 13.04
[006250] f: 0.046, acc: 99.95, fv: 0.594, accv: 80.08, lr: 0.0962, time: 12.68
[006500] f: 0.035, acc: 99.99, fv: 0.587, accv: 80.40, lr: 0.0959, time: 14.99
[007250] f: 0.025, acc: 100.00, fv: 0.593, accv: 80.20, lr: 0.0949, time: 12.18
[008250] f: 0.016, acc: 100.00, fv: 0.597, accv: 80.33, lr: 0.0934, time: 13.13
[009250] f: 0.013, acc: 100.00, fv: 0.598, accv: 80.12, lr: 0.0918, time: 13.03
[010250] f: 0.010, acc: 100.00, fv: 0.600, accv: 80.34, lr: 0.0900, time: 12.98
[011250] f: 0.009, acc: 100.00, fv: 0.602, accv: 80.29, lr: 0.0880, time: 13.68
[012250] f: 0.007, acc: 100.00, fv: 0.608, accv: 80.35, lr: 0.0859, time: 12.63
[013250] f: 0.006, acc: 100.00, fv: 0.604, accv: 80.59, lr: 0.0837, time: 12.12
[014250] f: 0.006, acc: 100.00, fv: 0.609, accv: 80.51, lr: 0.0813, time: 12.22
[015250] f: 0.005, acc: 100.00, fv: 0.612, accv: 80.53, lr: 0.0788, time: 12.25
[016250] f: 0.005, acc: 100.00, fv: 0.614, accv: 80.44, lr: 0.0761, time: 13.32
[019000] f: 0.004, acc: 100.00, fv: 0.616, accv: 80.67, lr: 0.0684, time: 13.02
[022750] f: 0.003, acc: 100.00, fv: 0.620, accv: 80.52, lr: 0.0570, time: 14.24
[026500] f: 0.003, acc: 100.00, fv: 0.622, accv: 80.54, lr: 0.0453, time: 13.59
[030250] f: 0.002, acc: 100.00, fv: 0.626, accv: 80.53, lr: 0.0338, time: 12.84
[034000] f: 0.002, acc: 100.00, fv: 0.628, accv: 80.30, lr: 0.0232, time: 12.58
[037750] f: 0.002, acc: 100.00, fv: 0.629, accv: 80.35, lr: 0.0141, time: 12.44
[041500] f: 0.002, acc: 100.00, fv: 0.630, accv: 80.40, lr: 0.0070, time: 12.05
[045250] f: 0.002, acc: 100.00, fv: 0.630, accv: 80.31, lr: 0.0022, time: 9.78
[049000] f: 0.002, acc: 100.00, fv: 0.629, accv: 80.44, lr: 0.0001, time: 9.79
[050000] f: 0.002, acc: 100.00, fv: 0.632, accv: 80.28, lr: 0.0000, time: 9.51
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.1000, time: 16.60
[000001] f: 2.300, acc: 13.00, fv: 2.299, accv: 13.10, lr: 0.1000, time: 14.28
[000063] f: 1.822, acc: 33.61, fv: 1.803, accv: 33.89, lr: 0.1000, time: 14.54
[000125] f: 1.683, acc: 42.57, fv: 1.658, accv: 42.33, lr: 0.1000, time: 15.30
[000187] f: 1.624, acc: 43.25, fv: 1.595, accv: 42.89, lr: 0.1000, time: 14.95
[000249] f: 1.593, acc: 45.80, fv: 1.631, accv: 44.11, lr: 0.1000, time: 15.53
[000251] f: 1.540, acc: 47.28, fv: 1.540, accv: 45.02, lr: 0.1000, time: 15.26
[000313] f: 1.417, acc: 52.57, fv: 1.403, accv: 52.01, lr: 0.1000, time: 17.98
[000375] f: 1.471, acc: 49.99, fv: 1.463, accv: 49.05, lr: 0.1000, time: 15.01
[000437] f: 1.360, acc: 53.30, fv: 1.360, accv: 52.22, lr: 0.1000, time: 16.87
[000499] f: 1.274, acc: 56.58, fv: 1.276, accv: 55.42, lr: 0.1000, time: 17.45
[000501] f: 1.316, acc: 54.38, fv: 1.326, accv: 53.40, lr: 0.1000, time: 15.45
[000563] f: 1.361, acc: 52.94, fv: 1.361, accv: 51.35, lr: 0.1000, time: 15.49
[000625] f: 1.221, acc: 58.04, fv: 1.213, accv: 57.29, lr: 0.1000, time: 15.54
[000687] f: 1.254, acc: 56.89, fv: 1.257, accv: 55.77, lr: 0.1000, time: 16.67
[000749] f: 1.268, acc: 55.04, fv: 1.323, accv: 52.86, lr: 0.0999, time: 16.15
[000751] f: 1.158, acc: 60.55, fv: 1.167, accv: 59.68, lr: 0.0999, time: 15.47
[000813] f: 1.153, acc: 60.19, fv: 1.177, accv: 58.70, lr: 0.0999, time: 17.30
[000875] f: 1.093, acc: 63.59, fv: 1.097, accv: 62.12, lr: 0.0999, time: 18.12
[000937] f: 1.111, acc: 61.54, fv: 1.138, accv: 59.68, lr: 0.0999, time: 15.51
[000999] f: 1.052, acc: 65.08, fv: 1.066, accv: 63.02, lr: 0.0999, time: 15.68
[001001] f: 1.065, acc: 63.80, fv: 1.075, accv: 62.21, lr: 0.0999, time: 15.55
[001063] f: 1.017, acc: 65.95, fv: 1.027, accv: 65.09, lr: 0.0999, time: 16.39
[001125] f: 1.312, acc: 55.89, fv: 1.370, accv: 54.97, lr: 0.0999, time: 17.45
[001187] f: 1.008, acc: 65.77, fv: 1.016, accv: 65.03, lr: 0.0999, time: 16.34
[001249] f: 0.989, acc: 67.04, fv: 0.994, accv: 65.89, lr: 0.0998, time: 15.58
[001500] f: 0.884, acc: 70.59, fv: 0.919, accv: 68.45, lr: 0.0998, time: 15.79
[001750] f: 0.842, acc: 71.46, fv: 0.868, accv: 69.68, lr: 0.0997, time: 16.59
[002000] f: 0.794, acc: 73.89, fv: 0.829, accv: 71.53, lr: 0.0996, time: 15.88
[002250] f: 0.719, acc: 76.19, fv: 0.749, accv: 74.31, lr: 0.0995, time: 15.78
[002500] f: 0.673, acc: 77.57, fv: 0.713, accv: 75.68, lr: 0.0994, time: 16.83
[002750] f: 0.645, acc: 78.81, fv: 0.698, accv: 75.78, lr: 0.0993, time: 15.91
[003000] f: 0.597, acc: 80.71, fv: 0.636, accv: 78.11, lr: 0.0991, time: 17.69
[003250] f: 0.593, acc: 80.64, fv: 0.643, accv: 77.94, lr: 0.0990, time: 16.29
[003500] f: 0.547, acc: 82.20, fv: 0.598, accv: 79.44, lr: 0.0988, time: 17.18
[003750] f: 0.557, acc: 81.96, fv: 0.623, accv: 78.55, lr: 0.0986, time: 16.17
[004000] f: 0.508, acc: 83.86, fv: 0.554, accv: 81.17, lr: 0.0984, time: 17.44
[004250] f: 0.478, acc: 84.91, fv: 0.539, accv: 81.23, lr: 0.0982, time: 16.38
[004500] f: 0.478, acc: 84.34, fv: 0.543, accv: 81.30, lr: 0.0980, time: 15.74
[004750] f: 0.454, acc: 85.44, fv: 0.537, accv: 81.29, lr: 0.0978, time: 16.60
[005000] f: 0.441, acc: 86.27, fv: 0.511, accv: 82.75, lr: 0.0976, time: 15.56
[005250] f: 0.437, acc: 86.29, fv: 0.518, accv: 82.67, lr: 0.0973, time: 18.84
[005500] f: 0.430, acc: 86.24, fv: 0.526, accv: 81.82, lr: 0.0970, time: 15.66
[005750] f: 0.408, acc: 87.37, fv: 0.494, accv: 83.15, lr: 0.0968, time: 16.46
[006000] f: 0.401, acc: 87.38, fv: 0.501, accv: 82.72, lr: 0.0965, time: 16.76
[006250] f: 0.397, acc: 87.36, fv: 0.486, accv: 83.55, lr: 0.0962, time: 18.33
[006500] f: 0.389, acc: 87.85, fv: 0.487, accv: 83.77, lr: 0.0959, time: 16.71
[007250] f: 0.338, acc: 89.45, fv: 0.450, accv: 84.73, lr: 0.0949, time: 16.25
[008250] f: 0.318, acc: 90.10, fv: 0.447, accv: 84.63, lr: 0.0934, time: 18.37
[009250] f: 0.312, acc: 90.11, fv: 0.461, accv: 84.46, lr: 0.0918, time: 17.35
[010250] f: 0.274, acc: 91.63, fv: 0.430, accv: 85.19, lr: 0.0900, time: 17.40
[011250] f: 0.248, acc: 92.33, fv: 0.407, accv: 86.31, lr: 0.0880, time: 17.80
[012250] f: 0.242, acc: 92.52, fv: 0.414, accv: 86.00, lr: 0.0859, time: 16.80
[013250] f: 0.223, acc: 93.27, fv: 0.402, accv: 86.24, lr: 0.0837, time: 17.27
[014250] f: 0.210, acc: 93.86, fv: 0.402, accv: 86.65, lr: 0.0813, time: 17.14
[015250] f: 0.196, acc: 94.32, fv: 0.396, accv: 86.88, lr: 0.0788, time: 19.49
[016250] f: 0.186, acc: 94.56, fv: 0.398, accv: 86.35, lr: 0.0761, time: 18.19
[019000] f: 0.161, acc: 95.52, fv: 0.394, accv: 86.92, lr: 0.0684, time: 17.25
[022750] f: 0.132, acc: 96.40, fv: 0.395, accv: 87.06, lr: 0.0570, time: 17.75
[026500] f: 0.107, acc: 97.40, fv: 0.387, accv: 87.43, lr: 0.0453, time: 16.53
[030250] f: 0.088, acc: 98.13, fv: 0.382, accv: 87.73, lr: 0.0338, time: 16.60
[034000] f: 0.077, acc: 98.58, fv: 0.380, accv: 87.81, lr: 0.0232, time: 16.35
[037750] f: 0.068, acc: 98.81, fv: 0.386, accv: 87.81, lr: 0.0141, time: 15.88
[041500] f: 0.064, acc: 98.97, fv: 0.382, accv: 87.86, lr: 0.0070, time: 15.75
[045250] f: 0.063, acc: 99.02, fv: 0.382, accv: 87.97, lr: 0.0022, time: 14.55
[049000] f: 0.061, acc: 99.08, fv: 0.383, accv: 87.86, lr: 0.0001, time: 14.20
[050000] f: 0.062, acc: 99.10, fv: 0.383, accv: 87.90, lr: 0.0000, time: 14.20
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0100, time: 12.36
[000001] f: 2.302, acc: 16.22, fv: 2.302, accv: 16.16, lr: 0.0100, time: 9.95
[000063] f: 1.708, acc: 43.97, fv: 1.708, accv: 44.10, lr: 0.0100, time: 10.46
[000125] f: 1.550, acc: 48.48, fv: 1.556, accv: 47.56, lr: 0.0100, time: 10.30
[000187] f: 1.428, acc: 54.73, fv: 1.448, accv: 53.24, lr: 0.0100, time: 13.98
[000249] f: 1.368, acc: 54.90, fv: 1.390, accv: 53.30, lr: 0.0100, time: 10.55
[000251] f: 1.351, acc: 55.96, fv: 1.370, accv: 55.31, lr: 0.0100, time: 10.63
[000313] f: 1.274, acc: 59.28, fv: 1.302, accv: 57.98, lr: 0.0100, time: 13.72
[000375] f: 1.204, acc: 60.22, fv: 1.232, accv: 58.73, lr: 0.0100, time: 10.93
[000437] f: 1.162, acc: 62.30, fv: 1.201, accv: 60.88, lr: 0.0100, time: 11.20
[000499] f: 1.098, acc: 64.25, fv: 1.139, accv: 62.21, lr: 0.0100, time: 12.34
[000501] f: 1.105, acc: 63.78, fv: 1.150, accv: 61.63, lr: 0.0100, time: 11.01
[000563] f: 1.043, acc: 66.02, fv: 1.089, accv: 63.79, lr: 0.0100, time: 11.50
[000625] f: 1.040, acc: 65.46, fv: 1.090, accv: 63.13, lr: 0.0100, time: 11.75
[000687] f: 0.997, acc: 67.15, fv: 1.050, accv: 64.55, lr: 0.0100, time: 11.93
[000749] f: 0.964, acc: 69.07, fv: 1.023, accv: 66.65, lr: 0.0100, time: 10.54
[000751] f: 0.951, acc: 68.89, fv: 1.011, accv: 65.90, lr: 0.0100, time: 12.97
[000813] f: 0.900, acc: 70.94, fv: 0.967, accv: 67.98, lr: 0.0100, time: 14.19
[000875] f: 0.901, acc: 70.27, fv: 0.978, accv: 67.07, lr: 0.0100, time: 10.75
[000937] f: 0.869, acc: 71.75, fv: 0.950, accv: 68.24, lr: 0.0100, time: 10.98
[000999] f: 0.841, acc: 72.34, fv: 0.920, accv: 68.54, lr: 0.0100, time: 12.10
[001001] f: 0.840, acc: 72.59, fv: 0.926, accv: 68.42, lr: 0.0100, time: 12.14
[001063] f: 0.790, acc: 75.13, fv: 0.877, accv: 71.15, lr: 0.0100, time: 11.69
[001125] f: 0.770, acc: 75.43, fv: 0.866, accv: 71.22, lr: 0.0100, time: 12.01
[001187] f: 0.771, acc: 75.48, fv: 0.867, accv: 71.29, lr: 0.0100, time: 11.51
[001249] f: 0.753, acc: 75.90, fv: 0.850, accv: 71.73, lr: 0.0100, time: 12.57
[001500] f: 0.658, acc: 79.46, fv: 0.788, accv: 73.71, lr: 0.0100, time: 11.63
[001750] f: 0.605, acc: 81.14, fv: 0.764, accv: 74.81, lr: 0.0100, time: 12.17
[002000] f: 0.543, acc: 83.34, fv: 0.727, accv: 75.34, lr: 0.0100, time: 11.44
[002250] f: 0.473, acc: 86.38, fv: 0.677, accv: 76.93, lr: 0.0100, time: 11.80
[002500] f: 0.426, acc: 88.32, fv: 0.669, accv: 77.83, lr: 0.0099, time: 13.15
[002750] f: 0.357, acc: 91.06, fv: 0.626, accv: 79.12, lr: 0.0099, time: 12.04
[003000] f: 0.339, acc: 91.43, fv: 0.638, accv: 78.32, lr: 0.0099, time: 12.60
[003250] f: 0.282, acc: 93.34, fv: 0.613, accv: 79.43, lr: 0.0099, time: 11.65
[003500] f: 0.257, acc: 94.20, fv: 0.620, accv: 78.86, lr: 0.0099, time: 11.32
[003750] f: 0.213, acc: 95.91, fv: 0.602, accv: 79.70, lr: 0.0099, time: 13.68
[004000] f: 0.202, acc: 96.09, fv: 0.629, accv: 78.72, lr: 0.0098, time: 12.86
[004250] f: 0.159, acc: 97.63, fv: 0.604, accv: 79.18, lr: 0.0098, time: 11.63
[004500] f: 0.131, acc: 98.71, fv: 0.593, accv: 80.03, lr: 0.0098, time: 11.81
[004750] f: 0.116, acc: 99.00, fv: 0.598, accv: 79.77, lr: 0.0098, time: 12.17
[005000] f: 0.092, acc: 99.52, fv: 0.592, accv: 79.92, lr: 0.0098, time: 12.87
[005250] f: 0.076, acc: 99.74, fv: 0.589, accv: 79.95, lr: 0.0097, time: 11.56
[005500] f: 0.061, acc: 99.81, fv: 0.590, accv: 79.69, lr: 0.0097, time: 11.88
[005750] f: 0.053, acc: 99.91, fv: 0.591, accv: 80.03, lr: 0.0097, time: 13.06
[006000] f: 0.043, acc: 99.95, fv: 0.586, accv: 80.08, lr: 0.0096, time: 11.33
[006250] f: 0.037, acc: 99.98, fv: 0.584, accv: 80.37, lr: 0.0096, time: 12.17
[006500] f: 0.031, acc: 99.98, fv: 0.582, accv: 80.09, lr: 0.0096, time: 12.58
[007250] f: 0.022, acc: 100.00, fv: 0.583, accv: 80.37, lr: 0.0095, time: 12.16
[008250] f: 0.015, acc: 100.00, fv: 0.584, accv: 80.38, lr: 0.0093, time: 11.93
[009250] f: 0.012, acc: 100.00, fv: 0.588, accv: 80.41, lr: 0.0092, time: 11.79
[010250] f: 0.009, acc: 100.00, fv: 0.591, accv: 80.36, lr: 0.0090, time: 12.40
[011250] f: 0.008, acc: 100.00, fv: 0.597, accv: 80.25, lr: 0.0088, time: 12.80
[012250] f: 0.007, acc: 100.00, fv: 0.595, accv: 80.39, lr: 0.0086, time: 11.73
[013250] f: 0.006, acc: 100.00, fv: 0.596, accv: 80.52, lr: 0.0084, time: 12.53
[014250] f: 0.005, acc: 100.00, fv: 0.603, accv: 80.22, lr: 0.0081, time: 11.98
[015250] f: 0.005, acc: 100.00, fv: 0.602, accv: 80.16, lr: 0.0079, time: 12.37
[016250] f: 0.004, acc: 100.00, fv: 0.604, accv: 80.16, lr: 0.0076, time: 13.71
[019000] f: 0.004, acc: 100.00, fv: 0.609, accv: 80.09, lr: 0.0068, time: 11.75
[022750] f: 0.003, acc: 100.00, fv: 0.612, accv: 79.92, lr: 0.0057, time: 11.82
[026500] f: 0.003, acc: 100.00, fv: 0.612, accv: 79.97, lr: 0.0045, time: 11.80
[030250] f: 0.002, acc: 100.00, fv: 0.616, accv: 79.89, lr: 0.0034, time: 12.43
[034000] f: 0.002, acc: 100.00, fv: 0.617, accv: 79.91, lr: 0.0023, time: 12.99
[037750] f: 0.002, acc: 100.00, fv: 0.618, accv: 79.91, lr: 0.0014, time: 12.45
[041500] f: 0.002, acc: 100.00, fv: 0.619, accv: 79.86, lr: 0.0007, time: 11.36
[045250] f: 0.002, acc: 100.00, fv: 0.620, accv: 79.89, lr: 0.0002, time: 10.14
[049000] f: 0.002, acc: 100.00, fv: 0.618, accv: 79.93, lr: 0.0000, time: 9.97
[050000] f: 0.002, acc: 100.00, fv: 0.620, accv: 79.85, lr: 0.0000, time: 10.03
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0100, time: 16.83
[000001] f: 2.303, acc: 13.49, fv: 2.302, accv: 16.10, lr: 0.0100, time: 14.32
[000063] f: 1.771, acc: 39.20, fv: 1.743, accv: 39.01, lr: 0.0100, time: 14.61
[000125] f: 1.630, acc: 44.82, fv: 1.601, accv: 44.46, lr: 0.0100, time: 16.29
[000187] f: 1.545, acc: 48.69, fv: 1.526, accv: 47.35, lr: 0.0100, time: 17.03
[000249] f: 1.476, acc: 50.09, fv: 1.475, accv: 48.09, lr: 0.0100, time: 16.61
[000251] f: 1.447, acc: 50.73, fv: 1.434, accv: 49.84, lr: 0.0100, time: 16.96
[000313] f: 1.336, acc: 55.31, fv: 1.317, accv: 54.78, lr: 0.0100, time: 15.23
[000375] f: 1.437, acc: 51.60, fv: 1.426, accv: 51.07, lr: 0.0100, time: 15.14
[000437] f: 1.258, acc: 58.76, fv: 1.252, accv: 58.01, lr: 0.0100, time: 15.51
[000499] f: 1.208, acc: 59.65, fv: 1.221, accv: 57.84, lr: 0.0100, time: 18.09
[000501] f: 1.248, acc: 58.17, fv: 1.265, accv: 56.75, lr: 0.0100, time: 15.20
[000563] f: 1.204, acc: 60.20, fv: 1.195, accv: 59.81, lr: 0.0100, time: 16.81
[000625] f: 1.133, acc: 62.31, fv: 1.134, accv: 60.89, lr: 0.0100, time: 15.11
[000687] f: 1.094, acc: 63.40, fv: 1.115, accv: 61.34, lr: 0.0100, time: 18.56
[000749] f: 1.104, acc: 62.96, fv: 1.135, accv: 60.53, lr: 0.0100, time: 15.24
[000751] f: 1.096, acc: 63.03, fv: 1.110, accv: 61.51, lr: 0.0100, time: 15.56
[000813] f: 1.065, acc: 63.98, fv: 1.068, accv: 63.07, lr: 0.0100, time: 14.94
[000875] f: 1.020, acc: 65.91, fv: 1.048, accv: 64.24, lr: 0.0100, time: 15.77
[000937] f: 0.978, acc: 67.51, fv: 0.982, accv: 66.55, lr: 0.0100, time: 15.74
[000999] f: 0.937, acc: 69.79, fv: 0.948, accv: 68.18, lr: 0.0100, time: 16.09
[001001] f: 0.949, acc: 69.15, fv: 0.973, accv: 66.87, lr: 0.0100, time: 16.03
[001063] f: 0.951, acc: 68.34, fv: 0.973, accv: 67.24, lr: 0.0100, time: 17.27
[001125] f: 0.913, acc: 69.86, fv: 0.920, accv: 68.35, lr: 0.0100, time: 15.18
[001187] f: 0.881, acc: 71.15, fv: 0.893, accv: 69.90, lr: 0.0100, time: 15.79
[001249] f: 0.897, acc: 69.77, fv: 0.912, accv: 68.54, lr: 0.0100, time: 15.55
[001500] f: 0.804, acc: 73.53, fv: 0.832, accv: 71.61, lr: 0.0100, time: 15.30
[001750] f: 0.798, acc: 73.37, fv: 0.834, accv: 71.07, lr: 0.0100, time: 16.68
[002000] f: 0.716, acc: 76.43, fv: 0.745, accv: 74.68, lr: 0.0100, time: 15.39
[002250] f: 0.678, acc: 78.27, fv: 0.702, accv: 76.10, lr: 0.0100, time: 17.57
[002500] f: 0.617, acc: 80.20, fv: 0.652, accv: 77.88, lr: 0.0099, time: 16.41
[002750] f: 0.605, acc: 80.43, fv: 0.639, accv: 78.79, lr: 0.0099, time: 15.50
[003000] f: 0.570, acc: 81.45, fv: 0.610, accv: 79.17, lr: 0.0099, time: 15.12
[003250] f: 0.552, acc: 82.44, fv: 0.612, accv: 79.37, lr: 0.0099, time: 16.42
[003500] f: 0.513, acc: 83.44, fv: 0.567, accv: 80.80, lr: 0.0099, time: 15.82
[003750] f: 0.502, acc: 84.08, fv: 0.559, accv: 81.70, lr: 0.0099, time: 16.27
[004000] f: 0.480, acc: 84.89, fv: 0.544, accv: 81.79, lr: 0.0098, time: 16.30
[004250] f: 0.473, acc: 84.89, fv: 0.542, accv: 81.20, lr: 0.0098, time: 16.50
[004500] f: 0.456, acc: 85.33, fv: 0.527, accv: 81.75, lr: 0.0098, time: 15.36
[004750] f: 0.433, acc: 86.42, fv: 0.506, accv: 82.72, lr: 0.0098, time: 16.30
[005000] f: 0.422, acc: 86.65, fv: 0.501, accv: 83.28, lr: 0.0098, time: 16.07
[005250] f: 0.424, acc: 86.56, fv: 0.504, accv: 82.91, lr: 0.0097, time: 16.51
[005500] f: 0.402, acc: 87.23, fv: 0.496, accv: 82.98, lr: 0.0097, time: 15.01
[005750] f: 0.393, acc: 87.31, fv: 0.495, accv: 83.36, lr: 0.0097, time: 16.85
[006000] f: 0.371, acc: 88.28, fv: 0.477, accv: 83.53, lr: 0.0096, time: 15.90
[006250] f: 0.373, acc: 88.13, fv: 0.468, accv: 84.52, lr: 0.0096, time: 17.23
[006500] f: 0.375, acc: 88.08, fv: 0.484, accv: 83.29, lr: 0.0096, time: 16.00
[007250] f: 0.335, acc: 89.74, fv: 0.442, accv: 84.91, lr: 0.0095, time: 18.46
[008250] f: 0.302, acc: 90.66, fv: 0.440, accv: 85.10, lr: 0.0093, time: 16.27
[009250] f: 0.295, acc: 90.79, fv: 0.439, accv: 85.08, lr: 0.0092, time: 16.07
[010250] f: 0.261, acc: 92.12, fv: 0.425, accv: 85.58, lr: 0.0090, time: 17.89
[011250] f: 0.243, acc: 92.60, fv: 0.414, accv: 86.10, lr: 0.0088, time: 16.27
[012250] f: 0.224, acc: 93.35, fv: 0.400, accv: 86.43, lr: 0.0086, time: 17.44
[013250] f: 0.211, acc: 93.73, fv: 0.400, accv: 86.31, lr: 0.0084, time: 17.73
[014250] f: 0.191, acc: 94.42, fv: 0.395, accv: 86.60, lr: 0.0081, time: 16.25
[015250] f: 0.183, acc: 94.61, fv: 0.394, accv: 86.81, lr: 0.0079, time: 15.84
[016250] f: 0.172, acc: 95.15, fv: 0.398, accv: 86.99, lr: 0.0076, time: 16.76
[019000] f: 0.150, acc: 95.70, fv: 0.402, accv: 87.06, lr: 0.0068, time: 17.44
[022750] f: 0.124, acc: 96.66, fv: 0.408, accv: 86.97, lr: 0.0057, time: 16.68
[026500] f: 0.099, acc: 97.62, fv: 0.394, accv: 87.61, lr: 0.0045, time: 18.14
[030250] f: 0.084, acc: 98.19, fv: 0.394, accv: 87.61, lr: 0.0034, time: 17.97
[034000] f: 0.070, acc: 98.76, fv: 0.394, accv: 87.87, lr: 0.0023, time: 15.99
[037750] f: 0.061, acc: 99.07, fv: 0.391, accv: 88.02, lr: 0.0014, time: 16.57
[041500] f: 0.058, acc: 99.17, fv: 0.388, accv: 88.19, lr: 0.0007, time: 16.18
[045250] f: 0.056, acc: 99.24, fv: 0.387, accv: 88.08, lr: 0.0002, time: 14.44
[049000] f: 0.055, acc: 99.29, fv: 0.387, accv: 88.09, lr: 0.0000, time: 14.46
[050000] f: 0.055, acc: 99.28, fv: 0.386, accv: 88.14, lr: 0.0000, time: 14.05
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.1000, time: 12.23
[000001] f: 2.297, acc: 10.11, fv: 2.297, accv: 10.18, lr: 0.1000, time: 9.86
[000063] f: 1.616, acc: 41.40, fv: 1.616, accv: 41.48, lr: 0.1000, time: 10.12
[000125] f: 1.386, acc: 50.80, fv: 1.391, accv: 50.56, lr: 0.1000, time: 10.28
[000187] f: 1.212, acc: 57.72, fv: 1.234, accv: 56.61, lr: 0.1000, time: 10.73
[000249] f: 1.260, acc: 55.23, fv: 1.289, accv: 54.72, lr: 0.1000, time: 10.83
[000251] f: 1.229, acc: 56.34, fv: 1.242, accv: 55.73, lr: 0.1000, time: 11.51
[000313] f: 1.176, acc: 58.41, fv: 1.214, accv: 56.78, lr: 0.1000, time: 11.06
[000375] f: 1.066, acc: 62.49, fv: 1.107, accv: 61.08, lr: 0.1000, time: 11.31
[000437] f: 0.933, acc: 67.54, fv: 0.982, accv: 65.43, lr: 0.1000, time: 11.56
[000499] f: 0.967, acc: 65.71, fv: 1.023, accv: 63.10, lr: 0.1000, time: 11.22
[000501] f: 0.889, acc: 69.07, fv: 0.945, accv: 66.40, lr: 0.1000, time: 11.10
[000563] f: 0.826, acc: 71.57, fv: 0.890, accv: 68.50, lr: 0.1000, time: 11.95
[000625] f: 0.933, acc: 67.29, fv: 1.011, accv: 64.81, lr: 0.1000, time: 12.21
[000687] f: 0.791, acc: 72.84, fv: 0.877, accv: 69.21, lr: 0.1000, time: 11.80
[000749] f: 0.739, acc: 74.98, fv: 0.834, accv: 71.03, lr: 0.0999, time: 14.82
[000751] f: 0.719, acc: 75.51, fv: 0.815, accv: 71.66, lr: 0.0999, time: 12.42
[000813] f: 0.698, acc: 75.98, fv: 0.810, accv: 71.91, lr: 0.0999, time: 11.68
[000875] f: 0.638, acc: 78.29, fv: 0.753, accv: 74.20, lr: 0.0999, time: 11.47
[000937] f: 0.669, acc: 76.88, fv: 0.806, accv: 71.75, lr: 0.0999, time: 11.47
[000999] f: 0.591, acc: 80.08, fv: 0.733, accv: 74.65, lr: 0.0999, time: 11.57
[001001] f: 0.580, acc: 80.47, fv: 0.727, accv: 74.77, lr: 0.0999, time: 12.70
[001063] f: 0.549, acc: 81.52, fv: 0.700, accv: 75.75, lr: 0.0999, time: 13.39
[001125] f: 0.502, acc: 83.24, fv: 0.678, accv: 76.47, lr: 0.0999, time: 11.50
[001187] f: 0.546, acc: 82.06, fv: 0.726, accv: 75.51, lr: 0.0999, time: 11.49
[001249] f: 0.496, acc: 84.11, fv: 0.676, accv: 76.94, lr: 0.0998, time: 12.62
[001500] f: 0.390, acc: 87.77, fv: 0.626, accv: 78.32, lr: 0.0998, time: 12.35
[001750] f: 0.366, acc: 88.18, fv: 0.652, accv: 77.58, lr: 0.0997, time: 12.09
[002000] f: 0.267, acc: 91.66, fv: 0.624, accv: 78.76, lr: 0.0996, time: 12.19
[002250] f: 0.207, acc: 94.26, fv: 0.605, accv: 79.53, lr: 0.0995, time: 12.98
[002500] f: 0.159, acc: 96.14, fv: 0.610, accv: 79.52, lr: 0.0994, time: 13.40
[002750] f: 0.121, acc: 97.07, fv: 0.646, accv: 79.30, lr: 0.0993, time: 12.55
[003000] f: 0.080, acc: 98.46, fv: 0.618, accv: 80.78, lr: 0.0991, time: 14.42
[003250] f: 0.047, acc: 99.59, fv: 0.608, accv: 80.80, lr: 0.0990, time: 12.68
[003500] f: 0.026, acc: 99.91, fv: 0.601, accv: 81.14, lr: 0.0988, time: 12.05
[003750] f: 0.016, acc: 99.98, fv: 0.608, accv: 81.39, lr: 0.0986, time: 13.22
[004000] f: 0.010, acc: 100.00, fv: 0.598, accv: 81.79, lr: 0.0984, time: 12.40
[004250] f: 0.007, acc: 100.00, fv: 0.600, accv: 81.91, lr: 0.0982, time: 14.07
[004500] f: 0.006, acc: 100.00, fv: 0.610, accv: 81.71, lr: 0.0980, time: 12.74
[004750] f: 0.005, acc: 100.00, fv: 0.605, accv: 81.62, lr: 0.0978, time: 13.99
[005000] f: 0.004, acc: 100.00, fv: 0.612, accv: 81.70, lr: 0.0976, time: 12.40
[005250] f: 0.003, acc: 100.00, fv: 0.610, accv: 81.94, lr: 0.0973, time: 12.80
[005500] f: 0.003, acc: 100.00, fv: 0.615, accv: 81.69, lr: 0.0970, time: 12.45
[005750] f: 0.003, acc: 100.00, fv: 0.620, accv: 81.76, lr: 0.0968, time: 13.86
[006000] f: 0.003, acc: 100.00, fv: 0.624, accv: 81.74, lr: 0.0965, time: 12.84
[006250] f: 0.002, acc: 100.00, fv: 0.628, accv: 81.74, lr: 0.0962, time: 12.47
[006500] f: 0.002, acc: 100.00, fv: 0.629, accv: 81.75, lr: 0.0959, time: 12.47
[007250] f: 0.002, acc: 100.00, fv: 0.635, accv: 81.66, lr: 0.0949, time: 13.16
[008250] f: 0.001, acc: 100.00, fv: 0.642, accv: 81.67, lr: 0.0934, time: 12.82
[009250] f: 0.001, acc: 100.00, fv: 0.650, accv: 81.72, lr: 0.0918, time: 13.01
[010250] f: 0.001, acc: 100.00, fv: 0.656, accv: 81.59, lr: 0.0900, time: 12.02
[011250] f: 0.001, acc: 100.00, fv: 0.659, accv: 81.66, lr: 0.0880, time: 12.99
[012250] f: 0.001, acc: 100.00, fv: 0.661, accv: 81.43, lr: 0.0859, time: 13.01
[013250] f: 0.001, acc: 100.00, fv: 0.666, accv: 81.60, lr: 0.0837, time: 12.55
[014250] f: 0.001, acc: 100.00, fv: 0.670, accv: 81.60, lr: 0.0813, time: 12.78
[015250] f: 0.001, acc: 100.00, fv: 0.669, accv: 81.57, lr: 0.0788, time: 13.05
[016250] f: 0.001, acc: 100.00, fv: 0.677, accv: 81.63, lr: 0.0761, time: 14.48
[019000] f: 0.000, acc: 100.00, fv: 0.682, accv: 81.67, lr: 0.0684, time: 12.79
[022750] f: 0.000, acc: 100.00, fv: 0.686, accv: 81.56, lr: 0.0570, time: 13.39
[026500] f: 0.000, acc: 100.00, fv: 0.690, accv: 81.51, lr: 0.0453, time: 13.16
[030250] f: 0.000, acc: 100.00, fv: 0.695, accv: 81.63, lr: 0.0338, time: 12.41
[034000] f: 0.000, acc: 100.00, fv: 0.698, accv: 81.54, lr: 0.0232, time: 12.90
[037750] f: 0.000, acc: 100.00, fv: 0.699, accv: 81.54, lr: 0.0141, time: 12.88
[041500] f: 0.000, acc: 100.00, fv: 0.700, accv: 81.36, lr: 0.0070, time: 12.16
[045250] f: 0.000, acc: 100.00, fv: 0.699, accv: 81.46, lr: 0.0022, time: 10.58
[049000] f: 0.000, acc: 100.00, fv: 0.698, accv: 81.53, lr: 0.0001, time: 10.16
[050000] f: 0.000, acc: 100.00, fv: 0.701, accv: 81.46, lr: 0.0000, time: 9.76
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.1000, time: 16.59
[000001] f: 2.296, acc: 10.38, fv: 2.295, accv: 10.56, lr: 0.1000, time: 14.42
[000063] f: 1.646, acc: 40.35, fv: 1.620, accv: 40.17, lr: 0.1000, time: 14.71
[000125] f: 1.480, acc: 46.51, fv: 1.475, accv: 46.04, lr: 0.1000, time: 15.20
[000187] f: 1.408, acc: 48.97, fv: 1.429, accv: 48.57, lr: 0.1000, time: 15.66
[000249] f: 1.236, acc: 56.49, fv: 1.263, accv: 55.13, lr: 0.1000, time: 16.63
[000251] f: 1.216, acc: 56.90, fv: 1.240, accv: 55.90, lr: 0.1000, time: 15.03
[000313] f: 1.190, acc: 58.17, fv: 1.226, accv: 57.58, lr: 0.1000, time: 17.57
[000375] f: 1.232, acc: 57.83, fv: 1.261, accv: 56.97, lr: 0.1000, time: 19.07
[000437] f: 1.009, acc: 64.89, fv: 1.024, accv: 64.00, lr: 0.1000, time: 15.96
[000499] f: 0.981, acc: 65.88, fv: 1.036, accv: 64.05, lr: 0.1000, time: 15.72
[000501] f: 1.082, acc: 61.74, fv: 1.140, accv: 60.65, lr: 0.1000, time: 15.45
[000563] f: 0.985, acc: 65.52, fv: 1.040, accv: 63.40, lr: 0.1000, time: 17.04
[000625] f: 0.899, acc: 68.82, fv: 0.912, accv: 68.25, lr: 0.1000, time: 15.32
[000687] f: 0.896, acc: 68.33, fv: 0.953, accv: 66.75, lr: 0.1000, time: 16.34
[000749] f: 0.867, acc: 70.37, fv: 0.924, accv: 68.33, lr: 0.0999, time: 16.61
[000751] f: 0.857, acc: 70.39, fv: 0.893, accv: 69.16, lr: 0.0999, time: 17.13
[000813] f: 0.824, acc: 71.65, fv: 0.845, accv: 70.54, lr: 0.0999, time: 17.35
[000875] f: 0.876, acc: 70.05, fv: 0.946, accv: 68.29, lr: 0.0999, time: 15.76
[000937] f: 0.783, acc: 73.22, fv: 0.805, accv: 72.44, lr: 0.0999, time: 16.00
[000999] f: 0.793, acc: 72.73, fv: 0.849, accv: 70.21, lr: 0.0999, time: 15.15
[001001] f: 0.726, acc: 75.37, fv: 0.765, accv: 73.65, lr: 0.0999, time: 16.35
[001063] f: 0.719, acc: 75.25, fv: 0.774, accv: 73.72, lr: 0.0999, time: 16.36
[001125] f: 0.736, acc: 74.44, fv: 0.785, accv: 73.16, lr: 0.0999, time: 15.97
[001187] f: 0.683, acc: 76.78, fv: 0.721, accv: 75.50, lr: 0.0999, time: 15.47
[001249] f: 0.663, acc: 77.52, fv: 0.703, accv: 75.89, lr: 0.0998, time: 16.08
[001500] f: 0.606, acc: 79.19, fv: 0.671, accv: 77.39, lr: 0.0998, time: 16.54
[001750] f: 0.548, acc: 81.30, fv: 0.633, accv: 78.42, lr: 0.0997, time: 16.38
[002000] f: 0.551, acc: 80.95, fv: 0.650, accv: 78.67, lr: 0.0996, time: 17.14
[002250] f: 0.527, acc: 81.94, fv: 0.612, accv: 79.45, lr: 0.0995, time: 16.38
[002500] f: 0.461, acc: 84.21, fv: 0.551, accv: 81.77, lr: 0.0994, time: 15.87
[002750] f: 0.452, acc: 84.41, fv: 0.563, accv: 81.16, lr: 0.0993, time: 15.98
[003000] f: 0.453, acc: 84.44, fv: 0.555, accv: 81.23, lr: 0.0991, time: 17.41
[003250] f: 0.413, acc: 86.28, fv: 0.530, accv: 82.38, lr: 0.0990, time: 18.14
[003500] f: 0.385, acc: 87.21, fv: 0.511, accv: 82.84, lr: 0.0988, time: 17.36
[003750] f: 0.380, acc: 86.96, fv: 0.511, accv: 83.08, lr: 0.0986, time: 16.90
[004000] f: 0.357, acc: 87.83, fv: 0.495, accv: 83.83, lr: 0.0984, time: 15.82
[004250] f: 0.349, acc: 88.15, fv: 0.484, accv: 83.55, lr: 0.0982, time: 16.34
[004500] f: 0.329, acc: 88.63, fv: 0.458, accv: 84.48, lr: 0.0980, time: 16.11
[004750] f: 0.328, acc: 88.79, fv: 0.484, accv: 83.90, lr: 0.0978, time: 15.83
[005000] f: 0.315, acc: 89.34, fv: 0.462, accv: 84.72, lr: 0.0976, time: 16.39
[005250] f: 0.333, acc: 88.77, fv: 0.489, accv: 84.13, lr: 0.0973, time: 16.41
[005500] f: 0.302, acc: 89.86, fv: 0.466, accv: 84.66, lr: 0.0970, time: 15.47
[005750] f: 0.289, acc: 90.20, fv: 0.473, accv: 84.65, lr: 0.0968, time: 17.41
[006000] f: 0.280, acc: 90.43, fv: 0.474, accv: 84.70, lr: 0.0965, time: 17.97
[006250] f: 0.303, acc: 89.56, fv: 0.476, accv: 84.29, lr: 0.0962, time: 16.65
[006500] f: 0.286, acc: 90.22, fv: 0.467, accv: 84.90, lr: 0.0959, time: 17.01
[007250] f: 0.244, acc: 91.84, fv: 0.434, accv: 85.78, lr: 0.0949, time: 16.56
[008250] f: 0.214, acc: 92.75, fv: 0.436, accv: 85.96, lr: 0.0934, time: 16.19
[009250] f: 0.213, acc: 92.83, fv: 0.454, accv: 85.89, lr: 0.0918, time: 17.65
[010250] f: 0.192, acc: 93.66, fv: 0.433, accv: 86.19, lr: 0.0900, time: 16.84
[011250] f: 0.177, acc: 94.00, fv: 0.443, accv: 86.55, lr: 0.0880, time: 16.89
[012250] f: 0.171, acc: 94.11, fv: 0.462, accv: 86.04, lr: 0.0859, time: 16.08
[013250] f: 0.169, acc: 94.03, fv: 0.483, accv: 85.39, lr: 0.0837, time: 17.77
[014250] f: 0.140, acc: 95.33, fv: 0.447, accv: 86.48, lr: 0.0813, time: 16.27
[015250] f: 0.125, acc: 95.85, fv: 0.435, accv: 86.93, lr: 0.0788, time: 17.31
[016250] f: 0.121, acc: 96.00, fv: 0.445, accv: 87.00, lr: 0.0761, time: 18.21
[019000] f: 0.095, acc: 96.97, fv: 0.444, accv: 87.38, lr: 0.0684, time: 17.38
[022750] f: 0.073, acc: 97.68, fv: 0.471, accv: 87.31, lr: 0.0570, time: 17.55
[026500] f: 0.053, acc: 98.52, fv: 0.470, accv: 87.44, lr: 0.0453, time: 17.37
[030250] f: 0.041, acc: 98.90, fv: 0.477, accv: 87.69, lr: 0.0338, time: 17.46
[034000] f: 0.033, acc: 99.25, fv: 0.472, accv: 87.99, lr: 0.0232, time: 16.80
[037750] f: 0.028, acc: 99.47, fv: 0.471, accv: 88.11, lr: 0.0141, time: 16.26
[041500] f: 0.025, acc: 99.54, fv: 0.477, accv: 88.07, lr: 0.0070, time: 15.74
[045250] f: 0.022, acc: 99.67, fv: 0.475, accv: 88.19, lr: 0.0022, time: 14.22
[049000] f: 0.021, acc: 99.67, fv: 0.478, accv: 88.23, lr: 0.0001, time: 14.22
[050000] f: 0.022, acc: 99.65, fv: 0.478, accv: 88.12, lr: 0.0000, time: 14.03
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0100, time: 12.33
[000001] f: 3.522, acc: 10.00, fv: 3.507, accv: 10.00, lr: 0.0100, time: 9.74
[000063] f: 1.909, acc: 32.71, fv: 1.905, accv: 32.79, lr: 0.0100, time: 10.01
[000125] f: 1.776, acc: 33.78, fv: 1.769, accv: 34.50, lr: 0.0100, time: 10.22
[000187] f: 1.649, acc: 39.45, fv: 1.651, accv: 39.16, lr: 0.0100, time: 10.61
[000249] f: 1.551, acc: 43.17, fv: 1.556, accv: 42.87, lr: 0.0100, time: 10.93
[000251] f: 1.540, acc: 44.72, fv: 1.542, accv: 44.55, lr: 0.0100, time: 10.51
[000313] f: 1.495, acc: 46.55, fv: 1.512, accv: 45.77, lr: 0.0100, time: 11.08
[000375] f: 1.948, acc: 38.32, fv: 1.956, accv: 37.94, lr: 0.0100, time: 11.25
[000437] f: 1.362, acc: 50.63, fv: 1.383, accv: 49.39, lr: 0.0100, time: 11.77
[000499] f: 1.497, acc: 46.84, fv: 1.520, accv: 46.38, lr: 0.0100, time: 12.51
[000501] f: 1.351, acc: 52.48, fv: 1.369, accv: 51.20, lr: 0.0100, time: 10.96
[000563] f: 1.285, acc: 54.85, fv: 1.296, accv: 53.91, lr: 0.0100, time: 13.36
[000625] f: 1.149, acc: 59.76, fv: 1.159, accv: 59.08, lr: 0.0100, time: 10.85
[000687] f: 1.541, acc: 47.45, fv: 1.551, accv: 47.19, lr: 0.0100, time: 11.10
[000749] f: 1.319, acc: 52.39, fv: 1.334, accv: 51.95, lr: 0.0100, time: 11.17
[000751] f: 1.183, acc: 57.42, fv: 1.205, accv: 56.42, lr: 0.0100, time: 10.75
[000813] f: 1.218, acc: 57.34, fv: 1.245, accv: 56.29, lr: 0.0100, time: 11.38
[000875] f: 1.369, acc: 51.01, fv: 1.385, accv: 50.46, lr: 0.0100, time: 12.78
[000937] f: 1.269, acc: 55.07, fv: 1.285, accv: 54.22, lr: 0.0100, time: 10.92
[000999] f: 1.092, acc: 62.57, fv: 1.120, accv: 61.11, lr: 0.0100, time: 12.16
[001001] f: 1.159, acc: 59.04, fv: 1.191, accv: 58.21, lr: 0.0100, time: 11.71
[001063] f: 1.061, acc: 62.70, fv: 1.089, accv: 61.47, lr: 0.0100, time: 11.22
[001125] f: 1.151, acc: 60.13, fv: 1.181, accv: 58.79, lr: 0.0100, time: 11.54
[001187] f: 1.077, acc: 62.83, fv: 1.091, accv: 61.88, lr: 0.0100, time: 11.55
[001249] f: 1.100, acc: 61.61, fv: 1.115, accv: 61.25, lr: 0.0100, time: 11.34
[001500] f: 1.062, acc: 63.25, fv: 1.090, accv: 62.14, lr: 0.0100, time: 12.26
[001750] f: 1.287, acc: 54.77, fv: 1.314, accv: 53.01, lr: 0.0100, time: 12.36
[002000] f: 1.252, acc: 57.01, fv: 1.287, accv: 55.85, lr: 0.0100, time: 11.40
[002250] f: 1.083, acc: 61.25, fv: 1.109, accv: 59.75, lr: 0.0100, time: 12.54
[002500] f: 1.377, acc: 54.08, fv: 1.413, accv: 53.34, lr: 0.0099, time: 12.36
[002750] f: 1.062, acc: 62.52, fv: 1.107, accv: 60.87, lr: 0.0099, time: 11.88
[003000] f: 1.314, acc: 56.15, fv: 1.342, accv: 55.47, lr: 0.0099, time: 11.56
[003250] f: 1.262, acc: 55.22, fv: 1.307, accv: 53.92, lr: 0.0099, time: 11.86
[003500] f: 1.006, acc: 64.60, fv: 1.046, accv: 63.56, lr: 0.0099, time: 12.28
[003750] f: 0.997, acc: 65.10, fv: 1.036, accv: 63.69, lr: 0.0099, time: 11.51
[004000] f: 1.038, acc: 64.86, fv: 1.082, accv: 63.76, lr: 0.0098, time: 11.67
[004250] f: 1.103, acc: 61.61, fv: 1.146, accv: 60.28, lr: 0.0098, time: 11.64
[004500] f: 1.240, acc: 59.21, fv: 1.294, accv: 57.59, lr: 0.0098, time: 12.91
[004750] f: 0.891, acc: 69.35, fv: 0.943, accv: 67.47, lr: 0.0098, time: 11.77
[005000] f: 0.900, acc: 67.93, fv: 0.941, accv: 66.18, lr: 0.0098, time: 11.39
[005250] f: 0.970, acc: 65.84, fv: 1.019, accv: 63.72, lr: 0.0097, time: 11.81
[005500] f: 1.119, acc: 60.36, fv: 1.160, accv: 59.34, lr: 0.0097, time: 13.34
[005750] f: 1.040, acc: 61.95, fv: 1.092, accv: 60.18, lr: 0.0097, time: 11.87
[006000] f: 1.010, acc: 64.41, fv: 1.053, accv: 62.82, lr: 0.0096, time: 13.71
[006250] f: 0.953, acc: 67.68, fv: 0.987, accv: 66.63, lr: 0.0096, time: 12.04
[006500] f: 1.281, acc: 56.49, fv: 1.325, accv: 55.69, lr: 0.0096, time: 11.87
[007250] f: 1.174, acc: 60.07, fv: 1.214, accv: 58.78, lr: 0.0095, time: 12.15
[008250] f: 1.512, acc: 51.83, fv: 1.561, accv: 50.67, lr: 0.0093, time: 11.61
[009250] f: 0.843, acc: 70.72, fv: 0.892, accv: 68.94, lr: 0.0092, time: 13.55
[010250] f: 1.072, acc: 61.46, fv: 1.111, accv: 60.06, lr: 0.0090, time: 11.42
[011250] f: 0.996, acc: 65.21, fv: 1.048, accv: 63.51, lr: 0.0088, time: 12.07
[012250] f: 1.000, acc: 64.36, fv: 1.050, accv: 62.55, lr: 0.0086, time: 13.76
[013250] f: 1.095, acc: 61.33, fv: 1.150, accv: 60.45, lr: 0.0084, time: 12.92
[014250] f: 0.915, acc: 67.88, fv: 0.976, accv: 66.34, lr: 0.0081, time: 11.62
[015250] f: 1.064, acc: 62.84, fv: 1.128, accv: 61.38, lr: 0.0079, time: 11.51
[016250] f: 0.852, acc: 70.78, fv: 0.912, accv: 68.76, lr: 0.0076, time: 12.30
[019000] f: 0.941, acc: 67.62, fv: 0.995, accv: 66.05, lr: 0.0068, time: 12.39
[022750] f: 0.913, acc: 68.38, fv: 0.988, accv: 66.33, lr: 0.0057, time: 11.59
[026500] f: 0.805, acc: 72.84, fv: 0.909, accv: 69.25, lr: 0.0045, time: 11.97
[030250] f: 0.657, acc: 78.46, fv: 0.779, accv: 73.93, lr: 0.0034, time: 12.40
[034000] f: 0.629, acc: 78.82, fv: 0.783, accv: 73.13, lr: 0.0023, time: 11.41
[037750] f: 0.504, acc: 84.09, fv: 0.720, accv: 75.83, lr: 0.0014, time: 11.58
[041500] f: 0.371, acc: 90.44, fv: 0.637, accv: 78.86, lr: 0.0007, time: 11.75
[045250] f: 0.308, acc: 93.38, fv: 0.630, accv: 78.85, lr: 0.0002, time: 10.27
[049000] f: 0.284, acc: 94.82, fv: 0.628, accv: 78.92, lr: 0.0000, time: 9.87
[050000] f: 0.282, acc: 94.81, fv: 0.628, accv: 78.93, lr: 0.0000, time: 9.93
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0100, time: 17.13
[000001] f: 4.637, acc: 10.00, fv: 4.173, accv: 10.00, lr: 0.0100, time: 14.42
[000063] f: 1.915, acc: 30.15, fv: 1.881, accv: 31.04, lr: 0.0100, time: 15.31
[000125] f: 1.828, acc: 31.45, fv: 1.819, accv: 32.25, lr: 0.0100, time: 15.86
[000187] f: 1.648, acc: 39.95, fv: 1.597, accv: 41.53, lr: 0.0100, time: 15.66
[000249] f: 1.628, acc: 41.63, fv: 1.673, accv: 41.19, lr: 0.0100, time: 15.51
[000251] f: 1.605, acc: 42.27, fv: 1.620, accv: 42.48, lr: 0.0100, time: 15.67
[000313] f: 1.428, acc: 49.78, fv: 1.413, accv: 49.31, lr: 0.0100, time: 15.39
[000375] f: 1.470, acc: 47.80, fv: 1.499, accv: 46.48, lr: 0.0100, time: 15.62
[000437] f: 1.588, acc: 45.92, fv: 1.664, accv: 45.25, lr: 0.0100, time: 17.43
[000499] f: 1.315, acc: 53.73, fv: 1.312, accv: 53.37, lr: 0.0100, time: 15.76
[000501] f: 1.415, acc: 48.36, fv: 1.419, accv: 48.24, lr: 0.0100, time: 16.38
[000563] f: 1.453, acc: 47.84, fv: 1.388, accv: 49.65, lr: 0.0100, time: 15.44
[000625] f: 1.356, acc: 52.93, fv: 1.345, accv: 54.84, lr: 0.0100, time: 15.00
[000687] f: 1.490, acc: 49.13, fv: 1.548, accv: 48.73, lr: 0.0100, time: 16.25
[000749] f: 1.472, acc: 47.97, fv: 1.695, accv: 44.90, lr: 0.0100, time: 16.62
[000751] f: 1.349, acc: 51.84, fv: 1.446, accv: 50.11, lr: 0.0100, time: 16.93
[000813] f: 1.607, acc: 41.31, fv: 1.641, accv: 42.72, lr: 0.0100, time: 17.89
[000875] f: 1.390, acc: 50.66, fv: 1.394, accv: 51.39, lr: 0.0100, time: 15.28
[000937] f: 1.806, acc: 39.82, fv: 1.880, accv: 40.84, lr: 0.0100, time: 15.83
[000999] f: 1.447, acc: 49.94, fv: 1.653, accv: 45.69, lr: 0.0100, time: 15.60
[001001] f: 1.225, acc: 56.43, fv: 1.343, accv: 52.62, lr: 0.0100, time: 16.20
[001063] f: 1.257, acc: 55.63, fv: 1.297, accv: 54.36, lr: 0.0100, time: 15.53
[001125] f: 1.318, acc: 54.26, fv: 1.338, accv: 54.09, lr: 0.0100, time: 15.99
[001187] f: 1.442, acc: 48.99, fv: 1.527, accv: 48.66, lr: 0.0100, time: 15.42
[001249] f: 1.422, acc: 50.74, fv: 1.523, accv: 49.30, lr: 0.0100, time: 15.34
[001500] f: 1.573, acc: 48.47, fv: 1.769, accv: 47.49, lr: 0.0100, time: 16.01
[001750] f: 1.432, acc: 49.06, fv: 1.423, accv: 51.56, lr: 0.0100, time: 15.20
[002000] f: 1.157, acc: 61.08, fv: 1.146, accv: 61.23, lr: 0.0100, time: 17.11
[002250] f: 1.075, acc: 62.89, fv: 1.061, accv: 63.43, lr: 0.0100, time: 15.42
[002500] f: 1.516, acc: 47.56, fv: 1.617, accv: 46.07, lr: 0.0099, time: 15.47
[002750] f: 1.246, acc: 54.19, fv: 1.286, accv: 53.85, lr: 0.0099, time: 16.71
[003000] f: 1.080, acc: 61.60, fv: 1.123, accv: 59.39, lr: 0.0099, time: 17.46
[003250] f: 1.178, acc: 58.16, fv: 1.208, accv: 57.73, lr: 0.0099, time: 15.60
[003500] f: 1.240, acc: 57.74, fv: 1.338, accv: 57.37, lr: 0.0099, time: 18.32
[003750] f: 1.283, acc: 56.34, fv: 1.337, accv: 55.92, lr: 0.0099, time: 15.52
[004000] f: 1.151, acc: 59.58, fv: 1.162, accv: 59.84, lr: 0.0098, time: 16.21
[004250] f: 1.065, acc: 64.31, fv: 1.017, accv: 65.50, lr: 0.0098, time: 17.23
[004500] f: 1.137, acc: 60.20, fv: 1.192, accv: 59.91, lr: 0.0098, time: 17.23
[004750] f: 1.089, acc: 61.86, fv: 1.144, accv: 60.60, lr: 0.0098, time: 16.58
[005000] f: 1.423, acc: 53.21, fv: 1.460, accv: 53.63, lr: 0.0098, time: 15.15
[005250] f: 1.064, acc: 63.20, fv: 1.114, accv: 62.56, lr: 0.0097, time: 16.73
[005500] f: 1.027, acc: 63.84, fv: 1.119, accv: 60.45, lr: 0.0097, time: 15.58
[005750] f: 1.204, acc: 58.21, fv: 1.289, accv: 57.68, lr: 0.0097, time: 16.90
[006000] f: 1.151, acc: 61.52, fv: 1.165, accv: 61.56, lr: 0.0096, time: 17.78
[006250] f: 1.007, acc: 65.61, fv: 1.047, accv: 63.68, lr: 0.0096, time: 16.89
[006500] f: 1.326, acc: 55.41, fv: 1.418, accv: 55.21, lr: 0.0096, time: 16.59
[007250] f: 1.077, acc: 63.09, fv: 1.180, accv: 60.50, lr: 0.0095, time: 15.35
[008250] f: 1.309, acc: 53.79, fv: 1.388, accv: 52.81, lr: 0.0093, time: 17.04
[009250] f: 1.128, acc: 61.04, fv: 1.151, accv: 61.48, lr: 0.0092, time: 17.58
[010250] f: 1.502, acc: 51.41, fv: 1.669, accv: 50.58, lr: 0.0090, time: 17.68
[011250] f: 1.430, acc: 51.13, fv: 1.415, accv: 52.74, lr: 0.0088, time: 18.22
[012250] f: 1.010, acc: 64.38, fv: 1.036, accv: 63.85, lr: 0.0086, time: 15.98
[013250] f: 1.028, acc: 64.20, fv: 1.085, accv: 63.29, lr: 0.0084, time: 16.75
[014250] f: 1.074, acc: 62.48, fv: 1.165, accv: 60.75, lr: 0.0081, time: 16.55
[015250] f: 1.048, acc: 63.90, fv: 1.070, accv: 63.05, lr: 0.0079, time: 16.45
[016250] f: 1.040, acc: 64.18, fv: 1.101, accv: 62.73, lr: 0.0076, time: 16.76
[019000] f: 1.455, acc: 53.69, fv: 1.615, accv: 52.51, lr: 0.0068, time: 16.19
[022750] f: 0.935, acc: 67.84, fv: 0.969, accv: 66.22, lr: 0.0057, time: 17.42
[026500] f: 0.780, acc: 74.27, fv: 0.797, accv: 72.71, lr: 0.0045, time: 17.82
[030250] f: 0.763, acc: 74.33, fv: 0.790, accv: 72.71, lr: 0.0034, time: 16.90
[034000] f: 0.753, acc: 74.54, fv: 0.791, accv: 73.06, lr: 0.0023, time: 16.58
[037750] f: 0.678, acc: 77.10, fv: 0.713, accv: 75.90, lr: 0.0014, time: 16.72
[041500] f: 0.575, acc: 81.76, fv: 0.601, accv: 79.89, lr: 0.0007, time: 16.06
[045250] f: 0.535, acc: 82.99, fv: 0.570, accv: 80.86, lr: 0.0002, time: 14.25
[049000] f: 0.512, acc: 83.92, fv: 0.547, accv: 81.72, lr: 0.0000, time: 14.18
[050000] f: 0.511, acc: 84.00, fv: 0.547, accv: 81.57, lr: 0.0000, time: 13.93
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0100, time: 12.23
[000001] f: 3.598, acc: 10.00, fv: 3.583, accv: 10.00, lr: 0.0100, time: 10.06
[000063] f: 1.885, acc: 28.81, fv: 1.879, accv: 28.45, lr: 0.0100, time: 10.04
[000125] f: 1.624, acc: 40.67, fv: 1.629, accv: 40.04, lr: 0.0100, time: 10.27
[000187] f: 1.495, acc: 46.41, fv: 1.498, accv: 46.03, lr: 0.0100, time: 11.51
[000249] f: 1.337, acc: 53.32, fv: 1.344, accv: 52.77, lr: 0.0100, time: 10.80
[000251] f: 1.385, acc: 52.48, fv: 1.394, accv: 52.01, lr: 0.0100, time: 11.61
[000313] f: 1.328, acc: 52.07, fv: 1.347, accv: 51.07, lr: 0.0100, time: 11.26
[000375] f: 1.245, acc: 56.61, fv: 1.264, accv: 56.21, lr: 0.0100, time: 11.19
[000437] f: 1.106, acc: 60.92, fv: 1.142, accv: 59.28, lr: 0.0100, time: 13.62
[000499] f: 1.072, acc: 62.33, fv: 1.111, accv: 60.63, lr: 0.0100, time: 10.87
[000501] f: 1.077, acc: 61.87, fv: 1.120, accv: 60.18, lr: 0.0100, time: 10.97
[000563] f: 0.988, acc: 66.38, fv: 1.032, accv: 64.08, lr: 0.0100, time: 11.20
[000625] f: 0.970, acc: 66.16, fv: 1.019, accv: 64.65, lr: 0.0100, time: 11.68
[000687] f: 0.863, acc: 70.16, fv: 0.915, accv: 67.98, lr: 0.0100, time: 12.16
[000749] f: 0.976, acc: 66.57, fv: 1.034, accv: 64.61, lr: 0.0100, time: 11.62
[000751] f: 0.899, acc: 69.44, fv: 0.961, accv: 66.80, lr: 0.0100, time: 10.74
[000813] f: 0.785, acc: 73.23, fv: 0.857, accv: 70.53, lr: 0.0100, time: 11.23
[000875] f: 0.762, acc: 73.85, fv: 0.841, accv: 70.42, lr: 0.0100, time: 11.29
[000937] f: 0.771, acc: 73.75, fv: 0.857, accv: 70.47, lr: 0.0100, time: 12.86
[000999] f: 0.710, acc: 75.21, fv: 0.813, accv: 71.36, lr: 0.0100, time: 12.07
[001001] f: 0.760, acc: 73.22, fv: 0.872, accv: 69.57, lr: 0.0100, time: 11.27
[001063] f: 0.684, acc: 76.66, fv: 0.788, accv: 73.09, lr: 0.0100, time: 11.80
[001125] f: 0.620, acc: 79.35, fv: 0.745, accv: 74.21, lr: 0.0100, time: 11.26
[001187] f: 0.651, acc: 77.66, fv: 0.772, accv: 73.44, lr: 0.0100, time: 11.35
[001249] f: 0.711, acc: 75.56, fv: 0.830, accv: 71.62, lr: 0.0100, time: 12.25
[001500] f: 0.589, acc: 79.58, fv: 0.762, accv: 73.39, lr: 0.0100, time: 12.38
[001750] f: 0.582, acc: 79.71, fv: 0.775, accv: 73.35, lr: 0.0100, time: 12.43
[002000] f: 0.398, acc: 86.49, fv: 0.655, accv: 78.03, lr: 0.0100, time: 12.37
[002250] f: 0.465, acc: 83.90, fv: 0.745, accv: 74.61, lr: 0.0100, time: 13.67
[002500] f: 0.381, acc: 87.28, fv: 0.712, accv: 76.14, lr: 0.0099, time: 14.25
[002750] f: 0.261, acc: 91.84, fv: 0.633, accv: 78.56, lr: 0.0099, time: 13.26
[003000] f: 0.287, acc: 90.03, fv: 0.723, accv: 77.23, lr: 0.0099, time: 11.81
[003250] f: 0.302, acc: 89.67, fv: 0.786, accv: 75.18, lr: 0.0099, time: 12.32
[003500] f: 0.397, acc: 85.69, fv: 1.002, accv: 72.45, lr: 0.0099, time: 12.10
[003750] f: 0.196, acc: 93.74, fv: 0.691, accv: 77.88, lr: 0.0099, time: 12.29
[004000] f: 0.214, acc: 92.76, fv: 0.782, accv: 76.01, lr: 0.0098, time: 13.06
[004250] f: 0.200, acc: 93.37, fv: 0.754, accv: 76.75, lr: 0.0098, time: 13.12
[004500] f: 0.199, acc: 93.22, fv: 0.814, accv: 75.31, lr: 0.0098, time: 13.11
[004750] f: 0.181, acc: 94.39, fv: 0.738, accv: 76.92, lr: 0.0098, time: 12.62
[005000] f: 0.176, acc: 94.15, fv: 0.791, accv: 76.50, lr: 0.0098, time: 12.48
[005250] f: 0.158, acc: 94.83, fv: 0.770, accv: 76.59, lr: 0.0097, time: 12.42
[005500] f: 0.164, acc: 94.54, fv: 0.796, accv: 76.09, lr: 0.0097, time: 11.86
[005750] f: 0.264, acc: 90.35, fv: 0.983, accv: 72.43, lr: 0.0097, time: 12.59
[006000] f: 0.198, acc: 93.16, fv: 0.884, accv: 74.96, lr: 0.0096, time: 12.27
[006250] f: 0.136, acc: 95.52, fv: 0.806, accv: 76.79, lr: 0.0096, time: 12.16
[006500] f: 0.127, acc: 95.95, fv: 0.826, accv: 76.67, lr: 0.0096, time: 12.79
[007250] f: 0.181, acc: 93.80, fv: 0.903, accv: 75.93, lr: 0.0095, time: 12.53
[008250] f: 0.102, acc: 96.92, fv: 0.788, accv: 77.19, lr: 0.0093, time: 12.80
[009250] f: 0.198, acc: 92.97, fv: 0.983, accv: 74.22, lr: 0.0092, time: 12.56
[010250] f: 0.084, acc: 97.49, fv: 0.856, accv: 77.46, lr: 0.0090, time: 14.21
[011250] f: 0.079, acc: 97.33, fv: 0.901, accv: 77.46, lr: 0.0088, time: 12.98
[012250] f: 0.065, acc: 98.01, fv: 0.841, accv: 77.89, lr: 0.0086, time: 12.70
[013250] f: 0.112, acc: 96.20, fv: 0.927, accv: 76.38, lr: 0.0084, time: 13.03
[014250] f: 0.135, acc: 95.13, fv: 1.018, accv: 75.17, lr: 0.0081, time: 12.40
[015250] f: 0.091, acc: 96.88, fv: 0.976, accv: 77.20, lr: 0.0079, time: 12.42
[016250] f: 0.044, acc: 98.73, fv: 0.865, accv: 78.15, lr: 0.0076, time: 14.18
[019000] f: 0.012, acc: 99.86, fv: 0.774, accv: 80.13, lr: 0.0068, time: 12.96
[022750] f: 0.478, acc: 83.98, fv: 1.057, accv: 71.83, lr: 0.0057, time: 13.16
[026500] f: 0.003, acc: 100.00, fv: 0.716, accv: 81.31, lr: 0.0045, time: 13.21
[030250] f: 0.002, acc: 100.00, fv: 0.738, accv: 80.99, lr: 0.0034, time: 13.42
[034000] f: 0.225, acc: 92.20, fv: 0.964, accv: 75.50, lr: 0.0023, time: 13.32
[037750] f: 0.001, acc: 100.00, fv: 0.718, accv: 81.11, lr: 0.0014, time: 12.64
[041500] f: 0.001, acc: 100.00, fv: 0.714, accv: 81.19, lr: 0.0007, time: 12.23
[045250] f: 0.001, acc: 100.00, fv: 0.718, accv: 81.11, lr: 0.0002, time: 10.56
[049000] f: 0.000, acc: 100.00, fv: 0.720, accv: 81.00, lr: 0.0000, time: 10.30
[050000] f: 0.000, acc: 100.00, fv: 0.725, accv: 80.84, lr: 0.0000, time: 10.75
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0100, time: 16.85
[000001] f: 4.715, acc: 10.00, fv: 4.234, accv: 10.00, lr: 0.0100, time: 14.52
[000063] f: 1.864, acc: 31.96, fv: 1.848, accv: 32.43, lr: 0.0100, time: 14.60
[000125] f: 1.679, acc: 38.03, fv: 1.697, accv: 36.96, lr: 0.0100, time: 15.31
[000187] f: 1.566, acc: 44.00, fv: 1.536, accv: 44.13, lr: 0.0100, time: 15.78
[000249] f: 1.407, acc: 50.03, fv: 1.430, accv: 47.74, lr: 0.0100, time: 15.30
[000251] f: 1.367, acc: 51.64, fv: 1.354, accv: 51.46, lr: 0.0100, time: 15.51
[000313] f: 1.309, acc: 54.55, fv: 1.331, accv: 52.65, lr: 0.0100, time: 15.63
[000375] f: 1.196, acc: 57.63, fv: 1.195, accv: 57.81, lr: 0.0100, time: 17.22
[000437] f: 1.149, acc: 60.21, fv: 1.144, accv: 60.06, lr: 0.0100, time: 16.58
[000499] f: 1.058, acc: 64.00, fv: 1.084, accv: 62.70, lr: 0.0100, time: 16.60
[000501] f: 1.094, acc: 61.70, fv: 1.110, accv: 61.33, lr: 0.0100, time: 15.08
[000563] f: 1.148, acc: 59.42, fv: 1.203, accv: 58.72, lr: 0.0100, time: 16.42
[000625] f: 1.009, acc: 64.32, fv: 1.037, accv: 63.11, lr: 0.0100, time: 14.94
[000687] f: 1.034, acc: 63.47, fv: 1.059, accv: 62.93, lr: 0.0100, time: 16.95
[000749] f: 0.962, acc: 67.30, fv: 0.990, accv: 65.76, lr: 0.0100, time: 16.73
[000751] f: 0.967, acc: 66.88, fv: 1.009, accv: 65.13, lr: 0.0100, time: 16.18
[000813] f: 0.951, acc: 67.37, fv: 0.952, accv: 66.92, lr: 0.0100, time: 15.48
[000875] f: 0.994, acc: 65.11, fv: 1.091, accv: 63.54, lr: 0.0100, time: 16.22
[000937] f: 0.806, acc: 72.77, fv: 0.823, accv: 71.38, lr: 0.0100, time: 15.63
[000999] f: 0.847, acc: 71.14, fv: 0.889, accv: 69.19, lr: 0.0100, time: 16.29
[001001] f: 0.814, acc: 72.10, fv: 0.863, accv: 70.06, lr: 0.0100, time: 15.18
[001063] f: 0.792, acc: 72.93, fv: 0.845, accv: 71.40, lr: 0.0100, time: 16.09
[001125] f: 0.999, acc: 65.72, fv: 1.105, accv: 64.14, lr: 0.0100, time: 15.89
[001187] f: 0.782, acc: 72.90, fv: 0.811, accv: 71.93, lr: 0.0100, time: 16.99
[001249] f: 0.725, acc: 75.02, fv: 0.778, accv: 73.97, lr: 0.0100, time: 19.34
[001500] f: 0.648, acc: 77.60, fv: 0.708, accv: 75.74, lr: 0.0100, time: 16.96
[001750] f: 0.707, acc: 75.26, fv: 0.756, accv: 74.05, lr: 0.0100, time: 15.62
[002000] f: 0.624, acc: 78.53, fv: 0.693, accv: 76.48, lr: 0.0100, time: 17.27
[002250] f: 0.635, acc: 78.02, fv: 0.710, accv: 76.29, lr: 0.0100, time: 15.83
[002500] f: 0.568, acc: 80.51, fv: 0.648, accv: 77.76, lr: 0.0099, time: 16.20
[002750] f: 0.589, acc: 80.37, fv: 0.664, accv: 78.14, lr: 0.0099, time: 16.27
[003000] f: 0.561, acc: 80.46, fv: 0.618, accv: 79.19, lr: 0.0099, time: 16.37
[003250] f: 0.538, acc: 81.53, fv: 0.632, accv: 78.56, lr: 0.0099, time: 17.06
[003500] f: 0.489, acc: 83.25, fv: 0.576, accv: 80.95, lr: 0.0099, time: 15.93
[003750] f: 0.554, acc: 80.66, fv: 0.643, accv: 78.57, lr: 0.0099, time: 16.88
[004000] f: 0.529, acc: 81.93, fv: 0.651, accv: 79.03, lr: 0.0098, time: 18.19
[004250] f: 0.528, acc: 82.06, fv: 0.586, accv: 80.40, lr: 0.0098, time: 17.08
[004500] f: 0.472, acc: 83.70, fv: 0.554, accv: 81.49, lr: 0.0098, time: 17.36
[004750] f: 0.472, acc: 83.61, fv: 0.582, accv: 80.66, lr: 0.0098, time: 17.80
[005000] f: 0.483, acc: 83.33, fv: 0.575, accv: 81.18, lr: 0.0098, time: 18.31
[005250] f: 0.448, acc: 84.76, fv: 0.553, accv: 81.35, lr: 0.0097, time: 16.08
[005500] f: 0.448, acc: 84.67, fv: 0.584, accv: 81.22, lr: 0.0097, time: 16.37
[005750] f: 0.451, acc: 84.37, fv: 0.581, accv: 81.13, lr: 0.0097, time: 16.92
[006000] f: 0.416, acc: 85.43, fv: 0.568, accv: 81.06, lr: 0.0096, time: 18.76
[006250] f: 0.460, acc: 84.24, fv: 0.556, accv: 82.01, lr: 0.0096, time: 16.79
[006500] f: 0.444, acc: 84.72, fv: 0.573, accv: 80.99, lr: 0.0096, time: 16.88
[007250] f: 0.470, acc: 84.10, fv: 0.601, accv: 80.87, lr: 0.0095, time: 16.89
[008250] f: 0.384, acc: 86.82, fv: 0.509, accv: 83.23, lr: 0.0093, time: 18.00
[009250] f: 0.526, acc: 81.77, fv: 0.637, accv: 79.90, lr: 0.0092, time: 17.63
[010250] f: 0.396, acc: 86.05, fv: 0.531, accv: 82.50, lr: 0.0090, time: 17.41
[011250] f: 0.386, acc: 86.61, fv: 0.527, accv: 82.50, lr: 0.0088, time: 17.42
[012250] f: 0.330, acc: 88.47, fv: 0.486, accv: 84.24, lr: 0.0086, time: 19.37
[013250] f: 0.341, acc: 88.12, fv: 0.503, accv: 83.65, lr: 0.0084, time: 17.65
[014250] f: 0.285, acc: 90.16, fv: 0.458, accv: 85.10, lr: 0.0081, time: 17.46
[015250] f: 0.366, acc: 87.26, fv: 0.525, accv: 83.37, lr: 0.0079, time: 16.61
[016250] f: 0.263, acc: 90.76, fv: 0.443, accv: 85.54, lr: 0.0076, time: 18.07
[019000] f: 0.269, acc: 90.58, fv: 0.469, accv: 85.22, lr: 0.0068, time: 17.21
[022750] f: 0.225, acc: 92.23, fv: 0.452, accv: 86.53, lr: 0.0057, time: 17.58
[026500] f: 0.219, acc: 92.21, fv: 0.492, accv: 85.44, lr: 0.0045, time: 16.97
[030250] f: 0.166, acc: 94.19, fv: 0.454, accv: 86.69, lr: 0.0034, time: 19.53
[034000] f: 0.109, acc: 96.36, fv: 0.440, accv: 87.48, lr: 0.0023, time: 17.66
[037750] f: 0.073, acc: 97.85, fv: 0.418, accv: 88.26, lr: 0.0014, time: 16.31
[041500] f: 0.050, acc: 98.71, fv: 0.420, accv: 88.58, lr: 0.0007, time: 15.86
[045250] f: 0.039, acc: 99.18, fv: 0.419, accv: 88.56, lr: 0.0002, time: 14.08
[049000] f: 0.034, acc: 99.33, fv: 0.421, accv: 88.69, lr: 0.0000, time: 14.09
[050000] f: 0.034, acc: 99.34, fv: 0.419, accv: 88.81, lr: 0.0000, time: 13.96
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0250, time: 12.09
[000001] f: 33.554, acc: 10.93, fv: 33.283, accv: 11.02, lr: 0.0250, time: 9.51
[000026] f: 2.132, acc: 21.95, fv: 2.127, accv: 22.56, lr: 0.0250, time: 10.01
[000051] f: 1.930, acc: 28.23, fv: 1.928, accv: 28.21, lr: 0.0250, time: 9.51
[000076] f: 1.849, acc: 30.13, fv: 1.853, accv: 29.81, lr: 0.0250, time: 11.50
[000101] f: 1.768, acc: 32.43, fv: 1.772, accv: 31.78, lr: 0.0250, time: 10.37
[000126] f: 1.617, acc: 41.22, fv: 1.622, accv: 40.82, lr: 0.0250, time: 11.42
[000151] f: 1.719, acc: 39.70, fv: 1.725, accv: 40.20, lr: 0.0250, time: 12.07
[000176] f: 1.430, acc: 49.05, fv: 1.450, accv: 49.09, lr: 0.0250, time: 11.80
[000201] f: 1.398, acc: 50.55, fv: 1.421, accv: 49.75, lr: 0.0250, time: 10.49
[000226] f: 1.351, acc: 52.66, fv: 1.375, accv: 51.23, lr: 0.0250, time: 10.49
[000251] f: 1.246, acc: 54.73, fv: 1.276, accv: 53.43, lr: 0.0250, time: 10.49
[000276] f: 1.249, acc: 57.09, fv: 1.301, accv: 55.32, lr: 0.0250, time: 10.79
[000301] f: 1.212, acc: 57.03, fv: 1.253, accv: 55.74, lr: 0.0250, time: 9.98
[000326] f: 1.205, acc: 56.30, fv: 1.248, accv: 54.48, lr: 0.0250, time: 10.45
[000351] f: 1.025, acc: 63.70, fv: 1.070, accv: 61.66, lr: 0.0250, time: 12.65
[000376] f: 0.970, acc: 65.94, fv: 1.018, accv: 63.85, lr: 0.0250, time: 12.91
[000401] f: 0.974, acc: 65.39, fv: 1.035, accv: 63.31, lr: 0.0250, time: 10.29
[000426] f: 0.966, acc: 65.93, fv: 1.042, accv: 63.34, lr: 0.0250, time: 11.30
[000451] f: 0.913, acc: 68.71, fv: 0.994, accv: 66.02, lr: 0.0250, time: 10.51
[000476] f: 0.904, acc: 68.32, fv: 0.984, accv: 65.17, lr: 0.0250, time: 11.23
[000600] f: 0.728, acc: 74.56, fv: 0.824, accv: 70.60, lr: 0.0249, time: 12.53
[000700] f: 0.748, acc: 73.60, fv: 0.899, accv: 68.77, lr: 0.0249, time: 10.12
[000800] f: 0.762, acc: 73.13, fv: 0.954, accv: 67.65, lr: 0.0249, time: 11.10
[000900] f: 0.530, acc: 81.66, fv: 0.769, accv: 73.66, lr: 0.0249, time: 10.74
[001000] f: 0.740, acc: 73.56, fv: 1.009, accv: 66.11, lr: 0.0248, time: 11.60
[001100] f: 0.532, acc: 81.29, fv: 0.863, accv: 70.63, lr: 0.0248, time: 10.53
[001200] f: 0.463, acc: 83.22, fv: 0.856, accv: 71.64, lr: 0.0248, time: 10.56
[001300] f: 0.430, acc: 84.85, fv: 0.881, accv: 71.52, lr: 0.0247, time: 11.86
[001400] f: 0.273, acc: 90.76, fv: 0.778, accv: 74.78, lr: 0.0247, time: 11.77
[001500] f: 0.317, acc: 88.71, fv: 0.923, accv: 71.88, lr: 0.0247, time: 10.63
[001600] f: 0.226, acc: 92.04, fv: 0.868, accv: 74.89, lr: 0.0246, time: 10.51
[001700] f: 0.156, acc: 95.20, fv: 0.846, accv: 74.42, lr: 0.0246, time: 11.69
[001800] f: 0.142, acc: 95.59, fv: 0.875, accv: 74.28, lr: 0.0245, time: 11.57
[001900] f: 0.114, acc: 96.76, fv: 0.886, accv: 74.48, lr: 0.0244, time: 10.73
[002000] f: 0.055, acc: 98.89, fv: 0.828, accv: 76.63, lr: 0.0244, time: 10.57
[002100] f: 0.034, acc: 99.73, fv: 0.801, accv: 77.07, lr: 0.0243, time: 11.31
[002200] f: 0.012, acc: 99.99, fv: 0.769, accv: 78.01, lr: 0.0243, time: 10.47
[002300] f: 0.007, acc: 100.00, fv: 0.781, accv: 78.39, lr: 0.0242, time: 10.37
[002400] f: 0.005, acc: 100.00, fv: 0.796, accv: 78.15, lr: 0.0241, time: 10.76
[002500] f: 0.004, acc: 100.00, fv: 0.792, accv: 78.44, lr: 0.0240, time: 10.33
[002600] f: 0.003, acc: 100.00, fv: 0.802, accv: 78.34, lr: 0.0240, time: 11.50
[002900] f: 0.002, acc: 100.00, fv: 0.823, accv: 78.33, lr: 0.0237, time: 11.23
[003300] f: 0.001, acc: 100.00, fv: 0.839, accv: 78.48, lr: 0.0234, time: 11.01
[003700] f: 0.001, acc: 100.00, fv: 0.856, accv: 78.12, lr: 0.0229, time: 10.55
[004100] f: 0.001, acc: 100.00, fv: 0.872, accv: 78.31, lr: 0.0225, time: 10.69
[004500] f: 0.001, acc: 100.00, fv: 0.886, accv: 78.31, lr: 0.0220, time: 10.93
[004900] f: 0.000, acc: 100.00, fv: 0.902, accv: 78.36, lr: 0.0215, time: 10.58
[005300] f: 0.000, acc: 100.00, fv: 0.917, accv: 78.28, lr: 0.0209, time: 11.98
[005700] f: 0.455, acc: 84.04, fv: 1.002, accv: 71.00, lr: 0.0203, time: 11.04
[006100] f: 0.073, acc: 97.57, fv: 1.015, accv: 75.26, lr: 0.0197, time: 12.59
[006500] f: 0.003, acc: 100.00, fv: 0.871, accv: 78.41, lr: 0.0190, time: 11.58
[007600] f: 0.001, acc: 100.00, fv: 0.929, accv: 78.48, lr: 0.0171, time: 12.12
[009100] f: 0.001, acc: 100.00, fv: 0.972, accv: 78.60, lr: 0.0143, time: 10.18
[010600] f: 0.000, acc: 100.00, fv: 1.022, accv: 78.48, lr: 0.0113, time: 10.54
[012100] f: 0.000, acc: 100.00, fv: 1.059, accv: 78.57, lr: 0.0085, time: 10.84
[013600] f: 0.000, acc: 100.00, fv: 1.089, accv: 78.49, lr: 0.0058, time: 10.88
[015100] f: 0.000, acc: 100.00, fv: 1.118, accv: 78.38, lr: 0.0035, time: 10.34
[016600] f: 0.000, acc: 100.00, fv: 1.139, accv: 78.60, lr: 0.0017, time: 11.03
[018100] f: 0.000, acc: 100.00, fv: 1.152, accv: 78.54, lr: 0.0006, time: 11.34
[019600] f: 0.000, acc: 100.00, fv: 1.160, accv: 78.64, lr: 0.0000, time: 10.58
[020000] f: 0.000, acc: 100.00, fv: 1.155, accv: 78.55, lr: 0.0000, time: 10.29
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0250, time: 17.03
[000001] f: 48.015, acc: 10.00, fv: 41.473, accv: 10.00, lr: 0.0250, time: 14.82
[000026] f: 2.066, acc: 23.10, fv: 2.034, accv: 24.34, lr: 0.0250, time: 14.55
[000051] f: 1.926, acc: 27.99, fv: 1.843, accv: 31.64, lr: 0.0250, time: 15.68
[000076] f: 1.757, acc: 35.98, fv: 1.744, accv: 35.68, lr: 0.0250, time: 17.20
[000101] f: 1.863, acc: 33.48, fv: 1.922, accv: 32.72, lr: 0.0250, time: 14.62
[000126] f: 2.040, acc: 35.44, fv: 2.093, accv: 35.08, lr: 0.0250, time: 14.91
[000151] f: 1.503, acc: 45.49, fv: 1.526, accv: 45.39, lr: 0.0250, time: 15.02
[000176] f: 1.486, acc: 46.81, fv: 1.509, accv: 46.17, lr: 0.0250, time: 15.74
[000201] f: 1.450, acc: 48.22, fv: 1.494, accv: 47.52, lr: 0.0250, time: 14.75
[000226] f: 1.242, acc: 55.93, fv: 1.247, accv: 55.33, lr: 0.0250, time: 14.68
[000251] f: 1.298, acc: 54.28, fv: 1.359, accv: 52.88, lr: 0.0250, time: 15.40
[000276] f: 1.164, acc: 58.78, fv: 1.191, accv: 57.60, lr: 0.0250, time: 17.35
[000301] f: 1.112, acc: 60.85, fv: 1.187, accv: 59.58, lr: 0.0250, time: 15.84
[000326] f: 1.183, acc: 58.11, fv: 1.298, accv: 55.85, lr: 0.0250, time: 15.24
[000351] f: 1.123, acc: 59.86, fv: 1.215, accv: 58.14, lr: 0.0250, time: 15.33
[000376] f: 1.102, acc: 60.43, fv: 1.113, accv: 59.97, lr: 0.0250, time: 15.05
[000401] f: 0.973, acc: 65.83, fv: 1.013, accv: 64.98, lr: 0.0250, time: 14.34
[000426] f: 1.121, acc: 59.63, fv: 1.160, accv: 58.75, lr: 0.0250, time: 16.59
[000451] f: 1.053, acc: 63.66, fv: 1.170, accv: 61.49, lr: 0.0250, time: 17.75
[000476] f: 1.065, acc: 62.46, fv: 1.152, accv: 60.51, lr: 0.0250, time: 16.48
[000600] f: 0.832, acc: 71.00, fv: 0.900, accv: 69.35, lr: 0.0249, time: 14.83
[000700] f: 0.829, acc: 70.77, fv: 0.880, accv: 69.45, lr: 0.0249, time: 15.34
[000800] f: 0.820, acc: 71.36, fv: 0.877, accv: 70.01, lr: 0.0249, time: 15.08
[000900] f: 0.807, acc: 72.19, fv: 0.883, accv: 70.29, lr: 0.0249, time: 14.89
[001000] f: 0.701, acc: 75.92, fv: 0.749, accv: 74.11, lr: 0.0248, time: 15.38
[001100] f: 0.633, acc: 77.87, fv: 0.712, accv: 76.33, lr: 0.0248, time: 16.91
[001200] f: 0.844, acc: 72.10, fv: 0.940, accv: 70.93, lr: 0.0248, time: 16.49
[001300] f: 0.634, acc: 77.39, fv: 0.715, accv: 75.32, lr: 0.0247, time: 16.05
[001400] f: 0.650, acc: 77.42, fv: 0.809, accv: 74.20, lr: 0.0247, time: 16.16
[001500] f: 0.615, acc: 78.41, fv: 0.737, accv: 74.85, lr: 0.0247, time: 15.28
[001600] f: 0.555, acc: 80.97, fv: 0.677, accv: 78.29, lr: 0.0246, time: 15.09
[001700] f: 0.535, acc: 81.38, fv: 0.659, accv: 78.88, lr: 0.0246, time: 15.92
[001800] f: 0.724, acc: 75.04, fv: 0.910, accv: 72.21, lr: 0.0245, time: 16.23
[001900] f: 0.499, acc: 83.03, fv: 0.608, accv: 79.66, lr: 0.0244, time: 16.00
[002000] f: 0.587, acc: 79.50, fv: 0.742, accv: 76.16, lr: 0.0244, time: 15.33
[002100] f: 0.731, acc: 75.64, fv: 0.833, accv: 74.85, lr: 0.0243, time: 15.73
[002200] f: 0.541, acc: 80.88, fv: 0.679, accv: 78.08, lr: 0.0243, time: 18.34
[002300] f: 0.408, acc: 85.76, fv: 0.559, accv: 81.66, lr: 0.0242, time: 15.01
[002400] f: 0.498, acc: 83.28, fv: 0.671, accv: 79.69, lr: 0.0241, time: 16.85
[002500] f: 0.496, acc: 82.97, fv: 0.660, accv: 78.67, lr: 0.0240, time: 15.41
[002600] f: 0.453, acc: 84.03, fv: 0.619, accv: 80.42, lr: 0.0240, time: 15.83
[002900] f: 0.434, acc: 85.14, fv: 0.646, accv: 80.02, lr: 0.0237, time: 15.78
[003300] f: 0.337, acc: 88.18, fv: 0.534, accv: 83.33, lr: 0.0234, time: 16.79
[003700] f: 0.337, acc: 88.02, fv: 0.592, accv: 82.40, lr: 0.0229, time: 16.75
[004100] f: 0.315, acc: 88.79, fv: 0.535, accv: 83.24, lr: 0.0225, time: 15.86
[004500] f: 0.292, acc: 89.65, fv: 0.570, accv: 82.77, lr: 0.0220, time: 16.51
[004900] f: 0.311, acc: 89.11, fv: 0.621, accv: 82.51, lr: 0.0215, time: 15.40
[005300] f: 0.377, acc: 86.96, fv: 0.688, accv: 81.59, lr: 0.0209, time: 17.38
[005700] f: 0.434, acc: 85.47, fv: 0.775, accv: 79.60, lr: 0.0203, time: 16.20
[006100] f: 0.231, acc: 91.88, fv: 0.557, accv: 84.06, lr: 0.0197, time: 16.08
[006500] f: 0.209, acc: 92.55, fv: 0.547, accv: 84.26, lr: 0.0190, time: 16.04
[007600] f: 0.169, acc: 93.85, fv: 0.545, accv: 84.66, lr: 0.0171, time: 15.34
[009100] f: 0.149, acc: 94.59, fv: 0.634, accv: 84.30, lr: 0.0143, time: 17.29
[010600] f: 0.093, acc: 96.76, fv: 0.602, accv: 85.82, lr: 0.0113, time: 15.79
[012100] f: 0.076, acc: 97.30, fv: 0.626, accv: 85.66, lr: 0.0085, time: 16.03
[013600] f: 0.046, acc: 98.51, fv: 0.620, accv: 86.53, lr: 0.0058, time: 15.70
[015100] f: 0.030, acc: 99.12, fv: 0.632, accv: 86.58, lr: 0.0035, time: 15.59
[016600] f: 0.022, acc: 99.44, fv: 0.637, accv: 86.56, lr: 0.0017, time: 16.26
[018100] f: 0.019, acc: 99.56, fv: 0.635, accv: 86.76, lr: 0.0006, time: 15.33
[019600] f: 0.018, acc: 99.57, fv: 0.635, accv: 86.86, lr: 0.0000, time: 15.32
[020000] f: 0.018, acc: 99.59, fv: 0.635, accv: 86.78, lr: 0.0000, time: 15.50
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0250, time: 12.43
[000001] f: 32.259, acc: 11.14, fv: 32.008, accv: 10.96, lr: 0.0250, time: 10.41
[000026] f: 2.079, acc: 21.70, fv: 2.077, accv: 21.64, lr: 0.0250, time: 10.54
[000051] f: 2.153, acc: 23.12, fv: 2.153, accv: 22.67, lr: 0.0250, time: 11.40
[000076] f: 1.962, acc: 32.61, fv: 1.962, accv: 32.25, lr: 0.0250, time: 14.26
[000101] f: 1.971, acc: 28.32, fv: 1.973, accv: 28.63, lr: 0.0250, time: 11.39
[000126] f: 1.713, acc: 36.22, fv: 1.717, accv: 35.66, lr: 0.0250, time: 11.54
[000151] f: 2.480, acc: 31.80, fv: 2.469, accv: 31.96, lr: 0.0250, time: 12.25
[000176] f: 1.698, acc: 44.34, fv: 1.701, accv: 44.31, lr: 0.0250, time: 11.73
[000201] f: 1.690, acc: 43.73, fv: 1.699, accv: 43.51, lr: 0.0250, time: 11.23
[000226] f: 1.823, acc: 42.66, fv: 1.830, accv: 41.23, lr: 0.0250, time: 12.07
[000251] f: 1.416, acc: 46.94, fv: 1.434, accv: 46.38, lr: 0.0250, time: 10.91
[000276] f: 2.207, acc: 34.73, fv: 2.202, accv: 34.94, lr: 0.0250, time: 10.90
[000301] f: 1.563, acc: 43.94, fv: 1.582, accv: 43.15, lr: 0.0250, time: 10.80
[000326] f: 2.359, acc: 26.05, fv: 2.382, accv: 26.09, lr: 0.0250, time: 10.68
[000351] f: 2.522, acc: 30.02, fv: 2.529, accv: 30.30, lr: 0.0250, time: 12.12
[000376] f: 1.694, acc: 40.12, fv: 1.715, accv: 40.27, lr: 0.0250, time: 11.22
[000401] f: 1.968, acc: 35.87, fv: 1.992, accv: 35.48, lr: 0.0250, time: 11.92
[000426] f: 1.311, acc: 54.62, fv: 1.317, accv: 53.68, lr: 0.0250, time: 10.57
[000451] f: 1.954, acc: 39.86, fv: 1.969, accv: 39.24, lr: 0.0250, time: 10.72
[000476] f: 1.187, acc: 58.06, fv: 1.210, accv: 57.14, lr: 0.0250, time: 10.83
[000600] f: 1.602, acc: 46.27, fv: 1.621, accv: 45.24, lr: 0.0249, time: 11.61
[000700] f: 1.741, acc: 45.08, fv: 1.756, accv: 44.09, lr: 0.0249, time: 11.22
[000800] f: 2.752, acc: 30.21, fv: 2.777, accv: 30.08, lr: 0.0249, time: 11.37
[000900] f: 1.490, acc: 48.73, fv: 1.507, accv: 47.95, lr: 0.0249, time: 11.43
[001000] f: 1.724, acc: 42.80, fv: 1.737, accv: 42.30, lr: 0.0248, time: 12.30
[001100] f: 1.369, acc: 52.74, fv: 1.399, accv: 51.94, lr: 0.0248, time: 10.93
[001200] f: 1.995, acc: 33.08, fv: 2.021, accv: 32.56, lr: 0.0248, time: 11.95
[001300] f: 1.514, acc: 45.21, fv: 1.540, accv: 45.23, lr: 0.0247, time: 11.18
[001400] f: 1.522, acc: 52.00, fv: 1.547, accv: 51.14, lr: 0.0247, time: 12.38
[001500] f: 1.415, acc: 49.83, fv: 1.436, accv: 48.85, lr: 0.0247, time: 11.15
[001600] f: 1.277, acc: 53.83, fv: 1.300, accv: 52.41, lr: 0.0246, time: 10.84
[001700] f: 1.822, acc: 45.27, fv: 1.848, accv: 44.85, lr: 0.0246, time: 11.30
[001800] f: 1.411, acc: 50.01, fv: 1.422, accv: 49.70, lr: 0.0245, time: 11.42
[001900] f: 1.429, acc: 48.36, fv: 1.470, accv: 47.05, lr: 0.0244, time: 11.33
[002000] f: 1.354, acc: 53.20, fv: 1.378, accv: 52.65, lr: 0.0244, time: 11.61
[002100] f: 1.436, acc: 49.89, fv: 1.463, accv: 49.03, lr: 0.0243, time: 10.95
[002200] f: 1.167, acc: 58.46, fv: 1.202, accv: 57.43, lr: 0.0243, time: 11.47
[002300] f: 1.242, acc: 57.03, fv: 1.271, accv: 56.20, lr: 0.0242, time: 10.91
[002400] f: 1.013, acc: 64.65, fv: 1.050, accv: 62.64, lr: 0.0241, time: 11.45
[002500] f: 1.255, acc: 56.81, fv: 1.283, accv: 56.05, lr: 0.0240, time: 11.45
[002600] f: 1.347, acc: 54.07, fv: 1.382, accv: 53.02, lr: 0.0240, time: 11.65
[002900] f: 1.570, acc: 47.77, fv: 1.602, accv: 46.81, lr: 0.0237, time: 12.22
[003300] f: 1.335, acc: 51.91, fv: 1.358, accv: 51.10, lr: 0.0234, time: 11.13
[003700] f: 1.546, acc: 48.80, fv: 1.565, accv: 49.12, lr: 0.0229, time: 10.95
[004100] f: 1.218, acc: 58.22, fv: 1.250, accv: 57.70, lr: 0.0225, time: 10.79
[004500] f: 1.207, acc: 58.75, fv: 1.237, accv: 57.94, lr: 0.0220, time: 11.28
[004900] f: 1.177, acc: 58.19, fv: 1.207, accv: 57.87, lr: 0.0215, time: 13.07
[005300] f: 1.407, acc: 52.23, fv: 1.430, accv: 51.13, lr: 0.0209, time: 10.82
[005700] f: 1.057, acc: 62.93, fv: 1.098, accv: 61.86, lr: 0.0203, time: 11.51
[006100] f: 1.252, acc: 57.05, fv: 1.293, accv: 56.23, lr: 0.0197, time: 11.01
[006500] f: 1.274, acc: 55.93, fv: 1.302, accv: 55.57, lr: 0.0190, time: 10.61
[007600] f: 1.136, acc: 60.50, fv: 1.177, accv: 58.98, lr: 0.0171, time: 12.13
[009100] f: 1.168, acc: 59.19, fv: 1.224, accv: 57.71, lr: 0.0143, time: 11.10
[010600] f: 1.041, acc: 63.93, fv: 1.094, accv: 62.75, lr: 0.0113, time: 10.60
[012100] f: 0.768, acc: 73.26, fv: 0.844, accv: 70.17, lr: 0.0085, time: 11.30
[013600] f: 0.748, acc: 74.63, fv: 0.850, accv: 70.87, lr: 0.0058, time: 10.87
[015100] f: 0.723, acc: 74.57, fv: 0.847, accv: 70.34, lr: 0.0035, time: 11.55
[016600] f: 0.551, acc: 82.59, fv: 0.708, accv: 76.16, lr: 0.0017, time: 10.34
[018100] f: 0.458, acc: 87.11, fv: 0.665, accv: 78.13, lr: 0.0006, time: 10.29
[019600] f: 0.413, acc: 89.35, fv: 0.647, accv: 78.63, lr: 0.0000, time: 9.84
[020000] f: 0.414, acc: 89.32, fv: 0.647, accv: 78.68, lr: 0.0000, time: 9.85
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0250, time: 17.57
[000001] f: 45.278, acc: 10.00, fv: 39.210, accv: 10.00, lr: 0.0250, time: 15.39
[000026] f: 2.069, acc: 20.96, fv: 2.034, accv: 22.22, lr: 0.0250, time: 17.39
[000051] f: 2.066, acc: 25.45, fv: 2.033, accv: 27.15, lr: 0.0250, time: 17.16
[000076] f: 2.045, acc: 22.01, fv: 2.006, accv: 23.25, lr: 0.0250, time: 16.32
[000101] f: 1.776, acc: 36.28, fv: 1.695, accv: 40.42, lr: 0.0250, time: 17.04
[000126] f: 1.896, acc: 35.04, fv: 1.872, accv: 36.05, lr: 0.0250, time: 19.23
[000151] f: 1.636, acc: 41.08, fv: 1.604, accv: 43.24, lr: 0.0250, time: 15.29
[000176] f: 2.688, acc: 21.08, fv: 2.910, accv: 21.41, lr: 0.0250, time: 15.39
[000201] f: 2.081, acc: 32.23, fv: 2.197, accv: 32.06, lr: 0.0250, time: 15.19
[000226] f: 1.927, acc: 30.95, fv: 1.864, accv: 33.62, lr: 0.0250, time: 15.69
[000251] f: 1.601, acc: 37.33, fv: 1.675, accv: 36.49, lr: 0.0250, time: 16.35
[000276] f: 1.713, acc: 44.64, fv: 1.805, accv: 44.43, lr: 0.0250, time: 15.45
[000301] f: 2.043, acc: 33.09, fv: 2.112, accv: 34.58, lr: 0.0250, time: 16.05
[000326] f: 1.911, acc: 38.01, fv: 1.987, accv: 37.45, lr: 0.0250, time: 17.12
[000351] f: 2.075, acc: 38.09, fv: 2.212, accv: 39.75, lr: 0.0250, time: 16.52
[000376] f: 1.456, acc: 48.21, fv: 1.535, accv: 47.63, lr: 0.0250, time: 15.69
[000401] f: 1.380, acc: 51.55, fv: 1.481, accv: 49.95, lr: 0.0250, time: 14.91
[000426] f: 1.505, acc: 43.97, fv: 1.429, accv: 48.19, lr: 0.0250, time: 15.17
[000451] f: 1.757, acc: 40.58, fv: 1.816, accv: 40.96, lr: 0.0250, time: 15.62
[000476] f: 1.629, acc: 45.16, fv: 1.684, accv: 45.66, lr: 0.0250, time: 17.18
[000600] f: 1.669, acc: 44.75, fv: 1.677, accv: 46.40, lr: 0.0249, time: 15.96
[000700] f: 1.505, acc: 48.20, fv: 1.534, accv: 49.62, lr: 0.0249, time: 17.34
[000800] f: 1.355, acc: 52.86, fv: 1.407, accv: 52.40, lr: 0.0249, time: 18.19
[000900] f: 1.460, acc: 52.19, fv: 1.538, accv: 52.66, lr: 0.0249, time: 15.86
[001000] f: 1.377, acc: 49.55, fv: 1.385, accv: 51.08, lr: 0.0248, time: 16.65
[001100] f: 1.727, acc: 40.84, fv: 1.769, accv: 43.15, lr: 0.0248, time: 15.92
[001200] f: 1.713, acc: 44.29, fv: 1.844, accv: 44.60, lr: 0.0248, time: 18.46
[001300] f: 1.495, acc: 50.11, fv: 1.531, accv: 50.42, lr: 0.0247, time: 15.99
[001400] f: 1.356, acc: 51.25, fv: 1.376, accv: 51.81, lr: 0.0247, time: 15.47
[001500] f: 1.377, acc: 52.57, fv: 1.465, accv: 51.34, lr: 0.0247, time: 16.17
[001600] f: 1.792, acc: 44.15, fv: 1.798, accv: 44.51, lr: 0.0246, time: 15.76
[001700] f: 1.925, acc: 42.17, fv: 2.047, accv: 42.71, lr: 0.0246, time: 15.78
[001800] f: 1.300, acc: 55.24, fv: 1.314, accv: 55.91, lr: 0.0245, time: 15.86
[001900] f: 1.275, acc: 55.33, fv: 1.387, accv: 51.85, lr: 0.0244, time: 16.41
[002000] f: 1.631, acc: 48.63, fv: 1.697, accv: 49.20, lr: 0.0244, time: 16.97
[002100] f: 1.685, acc: 41.64, fv: 1.707, accv: 43.09, lr: 0.0243, time: 15.77
[002200] f: 1.277, acc: 55.62, fv: 1.357, accv: 54.48, lr: 0.0243, time: 17.51
[002300] f: 1.729, acc: 39.95, fv: 1.805, accv: 40.90, lr: 0.0242, time: 15.39
[002400] f: 1.458, acc: 52.43, fv: 1.496, accv: 52.48, lr: 0.0241, time: 16.13
[002500] f: 1.328, acc: 51.44, fv: 1.335, accv: 51.77, lr: 0.0240, time: 14.94
[002600] f: 1.939, acc: 41.97, fv: 2.095, accv: 41.31, lr: 0.0240, time: 15.35
[002900] f: 1.292, acc: 55.17, fv: 1.299, accv: 56.48, lr: 0.0237, time: 15.25
[003300] f: 1.509, acc: 48.94, fv: 1.607, accv: 47.65, lr: 0.0234, time: 19.21
[003700] f: 1.529, acc: 49.81, fv: 1.594, accv: 50.67, lr: 0.0229, time: 16.56
[004100] f: 1.541, acc: 47.42, fv: 1.631, accv: 46.99, lr: 0.0225, time: 15.96
[004500] f: 1.428, acc: 53.50, fv: 1.518, accv: 53.20, lr: 0.0220, time: 16.29
[004900] f: 1.406, acc: 48.30, fv: 1.434, accv: 48.14, lr: 0.0215, time: 16.16
[005300] f: 1.549, acc: 48.26, fv: 1.655, accv: 47.01, lr: 0.0209, time: 15.60
[005700] f: 1.479, acc: 51.69, fv: 1.533, accv: 52.39, lr: 0.0203, time: 16.28
[006100] f: 1.810, acc: 42.16, fv: 2.017, accv: 41.21, lr: 0.0197, time: 17.98
[006500] f: 1.502, acc: 51.76, fv: 1.596, accv: 51.85, lr: 0.0190, time: 17.19
[007600] f: 1.149, acc: 59.14, fv: 1.207, accv: 58.50, lr: 0.0171, time: 15.93
[009100] f: 1.093, acc: 62.51, fv: 1.125, accv: 61.33, lr: 0.0143, time: 16.88
[010600] f: 1.245, acc: 58.21, fv: 1.319, accv: 57.67, lr: 0.0113, time: 15.66
[012100] f: 1.003, acc: 65.53, fv: 1.066, accv: 63.45, lr: 0.0085, time: 15.48
[013600] f: 1.027, acc: 63.84, fv: 1.080, accv: 62.92, lr: 0.0058, time: 17.81
[015100] f: 0.851, acc: 70.48, fv: 0.885, accv: 69.74, lr: 0.0035, time: 16.90
[016600] f: 0.726, acc: 75.40, fv: 0.716, accv: 75.21, lr: 0.0017, time: 15.61
[018100] f: 0.641, acc: 78.99, fv: 0.660, accv: 77.55, lr: 0.0006, time: 15.01
[019600] f: 0.605, acc: 80.56, fv: 0.625, accv: 78.71, lr: 0.0000, time: 14.41
[020000] f: 0.607, acc: 80.50, fv: 0.626, accv: 78.71, lr: 0.0000, time: 14.14
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0250, time: 12.64
[000001] f: 33.556, acc: 10.94, fv: 33.285, accv: 11.00, lr: 0.0250, time: 10.43
[000026] f: 2.120, acc: 22.04, fv: 2.114, accv: 22.76, lr: 0.0250, time: 10.60
[000051] f: 1.915, acc: 28.69, fv: 1.912, accv: 28.49, lr: 0.0250, time: 9.74
[000076] f: 1.832, acc: 32.22, fv: 1.833, accv: 32.22, lr: 0.0250, time: 10.43
[000101] f: 1.816, acc: 32.54, fv: 1.821, accv: 32.25, lr: 0.0250, time: 9.87
[000126] f: 1.617, acc: 40.31, fv: 1.625, accv: 39.67, lr: 0.0250, time: 13.27
[000151] f: 1.567, acc: 43.75, fv: 1.578, accv: 43.28, lr: 0.0250, time: 11.17
[000176] f: 1.565, acc: 44.16, fv: 1.581, accv: 43.73, lr: 0.0250, time: 10.11
[000201] f: 1.488, acc: 50.19, fv: 1.508, accv: 49.46, lr: 0.0250, time: 9.97
[000226] f: 1.298, acc: 54.35, fv: 1.326, accv: 53.61, lr: 0.0250, time: 11.69
[000251] f: 1.255, acc: 56.16, fv: 1.285, accv: 55.37, lr: 0.0250, time: 11.70
[000276] f: 1.464, acc: 49.51, fv: 1.507, accv: 48.44, lr: 0.0250, time: 12.02
[000301] f: 1.106, acc: 61.54, fv: 1.149, accv: 59.77, lr: 0.0250, time: 13.41
[000326] f: 1.159, acc: 58.11, fv: 1.197, accv: 57.00, lr: 0.0250, time: 10.78
[000351] f: 1.065, acc: 62.96, fv: 1.114, accv: 61.75, lr: 0.0250, time: 10.77
[000376] f: 1.048, acc: 62.67, fv: 1.100, accv: 60.53, lr: 0.0250, time: 10.72
[000401] f: 0.909, acc: 68.96, fv: 0.959, accv: 66.75, lr: 0.0250, time: 10.19
[000426] f: 1.047, acc: 63.52, fv: 1.106, accv: 61.61, lr: 0.0250, time: 11.61
[000451] f: 0.876, acc: 69.60, fv: 0.946, accv: 66.91, lr: 0.0250, time: 9.82
[000476] f: 1.020, acc: 64.57, fv: 1.095, accv: 62.39, lr: 0.0250, time: 10.68
[000600] f: 0.754, acc: 73.57, fv: 0.847, accv: 70.44, lr: 0.0249, time: 10.03
[000700] f: 0.769, acc: 72.66, fv: 0.891, accv: 68.72, lr: 0.0249, time: 10.79
[000800] f: 0.624, acc: 78.50, fv: 0.770, accv: 73.51, lr: 0.0249, time: 11.15
[000900] f: 0.594, acc: 79.40, fv: 0.766, accv: 73.34, lr: 0.0249, time: 13.14
[001000] f: 0.709, acc: 74.37, fv: 0.920, accv: 68.50, lr: 0.0248, time: 12.46
[001100] f: 0.677, acc: 74.99, fv: 0.899, accv: 68.14, lr: 0.0248, time: 11.87
[001200] f: 0.494, acc: 82.33, fv: 0.760, accv: 73.70, lr: 0.0248, time: 11.41
[001300] f: 0.748, acc: 74.42, fv: 1.043, accv: 66.30, lr: 0.0247, time: 10.42
[001400] f: 0.485, acc: 82.74, fv: 0.814, accv: 73.50, lr: 0.0247, time: 11.26
[001500] f: 0.596, acc: 79.06, fv: 0.958, accv: 69.52, lr: 0.0247, time: 11.09
[001600] f: 0.553, acc: 81.42, fv: 0.978, accv: 71.06, lr: 0.0246, time: 10.48
[001700] f: 0.442, acc: 84.85, fv: 0.876, accv: 72.53, lr: 0.0246, time: 11.76
[001800] f: 0.343, acc: 87.75, fv: 0.801, accv: 74.83, lr: 0.0245, time: 10.63
[001900] f: 0.299, acc: 89.82, fv: 0.749, accv: 75.61, lr: 0.0244, time: 12.61
[002000] f: 0.426, acc: 84.68, fv: 0.910, accv: 72.10, lr: 0.0244, time: 12.03
[002100] f: 0.347, acc: 87.60, fv: 0.869, accv: 72.75, lr: 0.0243, time: 11.08
[002200] f: 0.589, acc: 79.42, fv: 1.158, accv: 68.39, lr: 0.0243, time: 10.64
[002300] f: 0.311, acc: 89.01, fv: 0.895, accv: 73.71, lr: 0.0242, time: 13.29
[002400] f: 0.548, acc: 82.63, fv: 1.223, accv: 70.00, lr: 0.0241, time: 11.08
[002500] f: 0.360, acc: 87.43, fv: 1.007, accv: 72.10, lr: 0.0240, time: 10.74
[002600] f: 0.986, acc: 72.19, fv: 1.786, accv: 61.94, lr: 0.0240, time: 10.34
[002900] f: 0.432, acc: 85.12, fv: 1.150, accv: 70.49, lr: 0.0237, time: 10.59
[003300] f: 0.295, acc: 89.24, fv: 0.999, accv: 73.08, lr: 0.0234, time: 12.72
[003700] f: 0.302, acc: 89.32, fv: 1.050, accv: 72.42, lr: 0.0229, time: 10.41
[004100] f: 0.307, acc: 89.24, fv: 1.107, accv: 71.62, lr: 0.0225, time: 10.45
[004500] f: 0.488, acc: 82.78, fv: 1.400, accv: 66.88, lr: 0.0220, time: 11.09
[004900] f: 0.211, acc: 92.69, fv: 1.071, accv: 74.28, lr: 0.0215, time: 10.55
[005300] f: 0.658, acc: 79.33, fv: 1.569, accv: 65.42, lr: 0.0209, time: 11.26
[005700] f: 0.173, acc: 93.76, fv: 1.082, accv: 74.35, lr: 0.0203, time: 10.93
[006100] f: 0.535, acc: 82.26, fv: 1.557, accv: 65.80, lr: 0.0197, time: 11.71
[006500] f: 0.266, acc: 90.91, fv: 1.175, accv: 72.92, lr: 0.0190, time: 11.32
[007600] f: 0.173, acc: 93.87, fv: 1.117, accv: 74.09, lr: 0.0171, time: 10.42
[009100] f: 0.002, acc: 100.00, fv: 0.788, accv: 80.37, lr: 0.0143, time: 10.33
[010600] f: 0.018, acc: 99.89, fv: 0.761, accv: 79.95, lr: 0.0113, time: 10.75
[012100] f: 0.028, acc: 99.65, fv: 0.788, accv: 79.55, lr: 0.0085, time: 10.41
[013600] f: 0.003, acc: 100.00, fv: 0.790, accv: 80.04, lr: 0.0058, time: 10.52
[015100] f: 0.002, acc: 100.00, fv: 0.751, accv: 80.95, lr: 0.0035, time: 11.50
[016600] f: 0.001, acc: 100.00, fv: 0.772, accv: 80.49, lr: 0.0017, time: 10.77
[018100] f: 0.001, acc: 100.00, fv: 0.780, accv: 80.17, lr: 0.0006, time: 10.80
[019600] f: 0.001, acc: 100.00, fv: 0.788, accv: 79.99, lr: 0.0000, time: 10.04
[020000] f: 0.001, acc: 100.00, fv: 0.786, accv: 80.04, lr: 0.0000, time: 10.27
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0250, time: 18.02
[000001] f: 48.016, acc: 10.00, fv: 41.476, accv: 10.00, lr: 0.0250, time: 15.43
[000026] f: 2.057, acc: 23.29, fv: 2.025, accv: 24.81, lr: 0.0250, time: 15.32
[000051] f: 1.865, acc: 30.29, fv: 1.810, accv: 32.80, lr: 0.0250, time: 16.08
[000076] f: 1.831, acc: 32.92, fv: 1.879, accv: 31.78, lr: 0.0250, time: 17.23
[000101] f: 1.659, acc: 39.72, fv: 1.695, accv: 38.45, lr: 0.0250, time: 16.10
[000126] f: 1.542, acc: 44.14, fv: 1.589, accv: 42.85, lr: 0.0250, time: 14.90
[000151] f: 1.859, acc: 38.07, fv: 1.971, accv: 37.50, lr: 0.0250, time: 16.08
[000176] f: 1.455, acc: 48.10, fv: 1.455, accv: 47.67, lr: 0.0250, time: 16.00
[000201] f: 1.274, acc: 53.92, fv: 1.265, accv: 54.23, lr: 0.0250, time: 15.51
[000226] f: 1.327, acc: 51.83, fv: 1.352, accv: 51.47, lr: 0.0250, time: 16.74
[000251] f: 1.415, acc: 50.68, fv: 1.435, accv: 50.68, lr: 0.0250, time: 19.14
[000276] f: 1.238, acc: 55.71, fv: 1.249, accv: 55.48, lr: 0.0250, time: 16.22
[000301] f: 1.247, acc: 57.58, fv: 1.363, accv: 56.51, lr: 0.0250, time: 16.00
[000326] f: 1.063, acc: 62.07, fv: 1.088, accv: 60.72, lr: 0.0250, time: 16.28
[000351] f: 1.085, acc: 61.66, fv: 1.128, accv: 60.96, lr: 0.0250, time: 15.52
[000376] f: 0.982, acc: 64.87, fv: 1.032, accv: 63.49, lr: 0.0250, time: 16.12
[000401] f: 0.977, acc: 65.68, fv: 1.021, accv: 64.25, lr: 0.0250, time: 15.43
[000426] f: 1.151, acc: 59.52, fv: 1.196, accv: 59.55, lr: 0.0250, time: 14.95
[000451] f: 0.907, acc: 68.47, fv: 0.951, accv: 67.22, lr: 0.0250, time: 15.51
[000476] f: 0.973, acc: 65.84, fv: 1.034, accv: 64.99, lr: 0.0250, time: 15.07
[000600] f: 0.925, acc: 67.65, fv: 0.991, accv: 66.55, lr: 0.0249, time: 18.10
[000700] f: 0.827, acc: 71.26, fv: 0.867, accv: 69.99, lr: 0.0249, time: 15.62
[000800] f: 0.799, acc: 71.76, fv: 0.843, accv: 70.44, lr: 0.0249, time: 16.75
[000900] f: 0.842, acc: 71.37, fv: 0.898, accv: 70.14, lr: 0.0249, time: 14.92
[001000] f: 0.774, acc: 73.34, fv: 0.810, accv: 72.53, lr: 0.0248, time: 15.23
[001100] f: 0.639, acc: 77.56, fv: 0.695, accv: 76.53, lr: 0.0248, time: 15.15
[001200] f: 0.687, acc: 76.53, fv: 0.777, accv: 75.03, lr: 0.0248, time: 15.55
[001300] f: 0.869, acc: 70.34, fv: 0.960, accv: 68.89, lr: 0.0247, time: 15.77
[001400] f: 0.789, acc: 73.51, fv: 0.900, accv: 71.64, lr: 0.0247, time: 16.33
[001500] f: 0.675, acc: 77.29, fv: 0.721, accv: 76.24, lr: 0.0247, time: 15.58
[001600] f: 0.640, acc: 77.76, fv: 0.735, accv: 76.35, lr: 0.0246, time: 15.14
[001700] f: 0.719, acc: 75.20, fv: 0.768, accv: 74.20, lr: 0.0246, time: 15.64
[001800] f: 0.800, acc: 73.03, fv: 0.895, accv: 71.38, lr: 0.0245, time: 16.23
[001900] f: 0.613, acc: 79.07, fv: 0.668, accv: 78.09, lr: 0.0244, time: 16.54
[002000] f: 0.694, acc: 76.35, fv: 0.770, accv: 75.14, lr: 0.0244, time: 18.10
[002100] f: 0.658, acc: 77.08, fv: 0.721, accv: 75.83, lr: 0.0243, time: 16.46
[002200] f: 0.566, acc: 80.34, fv: 0.662, accv: 77.97, lr: 0.0243, time: 16.13
[002300] f: 0.721, acc: 74.94, fv: 0.789, accv: 74.47, lr: 0.0242, time: 15.28
[002400] f: 0.625, acc: 78.60, fv: 0.738, accv: 76.34, lr: 0.0241, time: 14.75
[002500] f: 0.545, acc: 81.30, fv: 0.635, accv: 78.80, lr: 0.0240, time: 14.77
[002600] f: 0.707, acc: 76.70, fv: 0.823, accv: 74.14, lr: 0.0240, time: 14.59
[002900] f: 0.550, acc: 81.17, fv: 0.652, accv: 78.67, lr: 0.0237, time: 16.24
[003300] f: 0.567, acc: 80.40, fv: 0.662, accv: 78.52, lr: 0.0234, time: 16.46
[003700] f: 0.646, acc: 77.74, fv: 0.764, accv: 75.57, lr: 0.0229, time: 15.26
[004100] f: 0.603, acc: 78.96, fv: 0.701, accv: 77.57, lr: 0.0225, time: 16.84
[004500] f: 0.684, acc: 76.89, fv: 0.743, accv: 76.34, lr: 0.0220, time: 15.66
[004900] f: 0.591, acc: 80.17, fv: 0.705, accv: 78.97, lr: 0.0215, time: 17.69
[005300] f: 0.709, acc: 77.27, fv: 0.860, accv: 74.99, lr: 0.0209, time: 16.54
[005700] f: 0.547, acc: 80.69, fv: 0.641, accv: 79.23, lr: 0.0203, time: 15.37
[006100] f: 0.507, acc: 81.74, fv: 0.607, accv: 80.22, lr: 0.0197, time: 15.62
[006500] f: 0.466, acc: 83.79, fv: 0.606, accv: 80.69, lr: 0.0190, time: 15.82
[007600] f: 0.429, acc: 84.80, fv: 0.561, accv: 82.05, lr: 0.0171, time: 16.07
[009100] f: 0.379, acc: 86.69, fv: 0.529, accv: 83.47, lr: 0.0143, time: 16.82
[010600] f: 0.402, acc: 86.00, fv: 0.589, accv: 82.69, lr: 0.0113, time: 16.07
[012100] f: 0.231, acc: 91.89, fv: 0.438, accv: 86.74, lr: 0.0085, time: 15.32
[013600] f: 0.198, acc: 92.96, fv: 0.449, accv: 86.43, lr: 0.0058, time: 15.36
[015100] f: 0.131, acc: 95.63, fv: 0.434, accv: 87.25, lr: 0.0035, time: 15.46
[016600] f: 0.094, acc: 97.05, fv: 0.419, accv: 87.97, lr: 0.0017, time: 15.34
[018100] f: 0.072, acc: 98.02, fv: 0.414, accv: 88.43, lr: 0.0006, time: 16.37
[019600] f: 0.064, acc: 98.29, fv: 0.414, accv: 88.56, lr: 0.0000, time: 14.83
[020000] f: 0.065, acc: 98.28, fv: 0.414, accv: 88.48, lr: 0.0000, time: 14.22
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0500, time: 13.18
[000001] f: 520.358, acc: 10.00, fv: 516.829, accv: 10.00, lr: 0.0500, time: 10.17
[000013] f: 5.995, acc: 12.33, fv: 6.021, accv: 12.42, lr: 0.0500, time: 11.68
[000025] f: 2.265, acc: 21.93, fv: 2.249, accv: 22.39, lr: 0.0500, time: 9.80
[000037] f: 2.077, acc: 24.99, fv: 2.070, accv: 25.27, lr: 0.0500, time: 10.40
[000049] f: 1.782, acc: 32.99, fv: 1.783, accv: 32.78, lr: 0.0500, time: 10.74
[000051] f: 1.775, acc: 33.64, fv: 1.777, accv: 33.17, lr: 0.0500, time: 9.99
[000063] f: 2.058, acc: 27.69, fv: 2.061, accv: 27.11, lr: 0.0500, time: 10.90
[000075] f: 1.717, acc: 36.87, fv: 1.709, accv: 36.78, lr: 0.0500, time: 10.84
[000087] f: 2.001, acc: 27.79, fv: 2.007, accv: 27.55, lr: 0.0500, time: 9.69
[000099] f: 1.750, acc: 38.45, fv: 1.750, accv: 38.55, lr: 0.0500, time: 11.05
[000101] f: 1.692, acc: 40.19, fv: 1.691, accv: 39.98, lr: 0.0500, time: 10.03
[000113] f: 1.443, acc: 47.63, fv: 1.450, accv: 46.89, lr: 0.0500, time: 10.09
[000125] f: 1.703, acc: 42.03, fv: 1.717, accv: 41.32, lr: 0.0500, time: 10.66
[000137] f: 1.449, acc: 46.90, fv: 1.469, accv: 45.95, lr: 0.0500, time: 9.74
[000149] f: 1.416, acc: 48.34, fv: 1.443, accv: 47.38, lr: 0.0500, time: 10.78
[000151] f: 1.380, acc: 48.49, fv: 1.406, accv: 47.51, lr: 0.0500, time: 10.81
[000163] f: 1.612, acc: 44.13, fv: 1.638, accv: 43.69, lr: 0.0500, time: 11.49
[000175] f: 1.509, acc: 47.00, fv: 1.539, accv: 46.17, lr: 0.0500, time: 9.94
[000187] f: 1.315, acc: 53.40, fv: 1.337, accv: 52.62, lr: 0.0500, time: 11.51
[000199] f: 1.512, acc: 47.56, fv: 1.553, accv: 46.23, lr: 0.0500, time: 10.24
[000201] f: 1.418, acc: 50.06, fv: 1.455, accv: 48.67, lr: 0.0500, time: 10.18
[000213] f: 1.239, acc: 55.90, fv: 1.279, accv: 54.85, lr: 0.0499, time: 11.00
[000225] f: 1.412, acc: 52.00, fv: 1.440, accv: 50.63, lr: 0.0499, time: 10.89
[000237] f: 1.115, acc: 61.02, fv: 1.161, accv: 59.65, lr: 0.0499, time: 11.72
[000249] f: 1.282, acc: 55.97, fv: 1.326, accv: 55.08, lr: 0.0499, time: 11.06
[000300] f: 1.073, acc: 60.70, fv: 1.133, accv: 58.54, lr: 0.0499, time: 11.30
[000350] f: 0.948, acc: 66.61, fv: 1.025, accv: 64.32, lr: 0.0498, time: 12.04
[000400] f: 0.961, acc: 66.29, fv: 1.067, accv: 63.46, lr: 0.0498, time: 10.18
[000450] f: 1.031, acc: 64.14, fv: 1.142, accv: 61.68, lr: 0.0498, time: 10.36
[000500] f: 0.839, acc: 70.52, fv: 0.990, accv: 66.04, lr: 0.0497, time: 11.75
[000550] f: 0.787, acc: 71.54, fv: 0.951, accv: 66.67, lr: 0.0496, time: 11.86
[000600] f: 0.828, acc: 72.33, fv: 1.079, accv: 65.92, lr: 0.0496, time: 10.70
[000650] f: 0.582, acc: 79.62, fv: 0.846, accv: 71.62, lr: 0.0495, time: 12.00
[000700] f: 0.566, acc: 80.32, fv: 0.893, accv: 71.12, lr: 0.0494, time: 11.18
[000750] f: 0.666, acc: 77.11, fv: 1.032, accv: 68.50, lr: 0.0493, time: 11.85
[000800] f: 0.478, acc: 82.91, fv: 0.889, accv: 70.90, lr: 0.0492, time: 10.51
[000850] f: 0.388, acc: 86.09, fv: 0.846, accv: 73.25, lr: 0.0491, time: 10.39
[000900] f: 0.431, acc: 84.60, fv: 0.958, accv: 70.34, lr: 0.0490, time: 10.43
[000950] f: 0.311, acc: 89.16, fv: 0.857, accv: 73.25, lr: 0.0489, time: 10.43
[001000] f: 0.339, acc: 87.79, fv: 0.978, accv: 71.39, lr: 0.0488, time: 10.81
[001050] f: 0.246, acc: 91.59, fv: 0.906, accv: 73.60, lr: 0.0487, time: 10.80
[001100] f: 0.266, acc: 90.22, fv: 1.039, accv: 70.96, lr: 0.0485, time: 10.22
[001150] f: 0.199, acc: 92.99, fv: 0.968, accv: 72.75, lr: 0.0484, time: 10.66
[001200] f: 0.187, acc: 93.73, fv: 1.039, accv: 72.47, lr: 0.0482, time: 11.26
[001250] f: 0.072, acc: 98.52, fv: 0.882, accv: 75.70, lr: 0.0481, time: 11.82
[001300] f: 0.067, acc: 98.58, fv: 0.921, accv: 75.30, lr: 0.0479, time: 10.78
[001450] f: 0.014, acc: 99.99, fv: 0.901, accv: 76.51, lr: 0.0475, time: 11.76
[001650] f: 0.004, acc: 100.00, fv: 0.909, accv: 77.17, lr: 0.0467, time: 10.50
[001850] f: 0.003, acc: 100.00, fv: 0.930, accv: 77.18, lr: 0.0459, time: 10.71
[002050] f: 0.002, acc: 100.00, fv: 0.947, accv: 77.29, lr: 0.0450, time: 10.78
[002250] f: 0.001, acc: 100.00, fv: 0.962, accv: 77.27, lr: 0.0440, time: 12.15
[002450] f: 0.001, acc: 100.00, fv: 0.972, accv: 77.37, lr: 0.0430, time: 11.10
[002650] f: 0.001, acc: 100.00, fv: 0.986, accv: 77.23, lr: 0.0418, time: 11.60
[002850] f: 0.001, acc: 100.00, fv: 1.000, accv: 77.28, lr: 0.0406, time: 11.09
[003050] f: 0.001, acc: 100.00, fv: 1.007, accv: 77.16, lr: 0.0394, time: 10.91
[003250] f: 0.001, acc: 100.00, fv: 1.022, accv: 77.04, lr: 0.0381, time: 10.66
[003800] f: 0.000, acc: 100.00, fv: 1.041, accv: 77.16, lr: 0.0342, time: 11.53
[004550] f: 0.000, acc: 100.00, fv: 1.067, accv: 76.96, lr: 0.0285, time: 10.48
[005300] f: 0.000, acc: 100.00, fv: 1.096, accv: 76.85, lr: 0.0226, time: 12.64
[006050] f: 0.000, acc: 100.00, fv: 1.111, accv: 76.78, lr: 0.0169, time: 10.89
[006800] f: 0.000, acc: 100.00, fv: 1.125, accv: 76.84, lr: 0.0116, time: 10.73
[007550] f: 0.000, acc: 100.00, fv: 1.138, accv: 76.84, lr: 0.0070, time: 10.92
[008300] f: 0.000, acc: 100.00, fv: 1.147, accv: 76.72, lr: 0.0035, time: 11.14
[009050] f: 0.000, acc: 100.00, fv: 1.150, accv: 76.76, lr: 0.0011, time: 10.27
[009800] f: 0.000, acc: 100.00, fv: 1.151, accv: 76.82, lr: 0.0000, time: 10.36
[010000] f: 0.000, acc: 100.00, fv: 1.152, accv: 76.77, lr: 0.0000, time: 9.88
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0500, time: 18.38
[000001] f: 523.337, acc: 10.00, fv: 463.072, accv: 10.00, lr: 0.0500, time: 14.95
[000013] f: 3.487, acc: 14.95, fv: 3.788, accv: 15.30, lr: 0.0500, time: 14.83
[000025] f: 2.308, acc: 20.87, fv: 2.336, accv: 21.76, lr: 0.0500, time: 15.98
[000037] f: 1.930, acc: 28.88, fv: 1.930, accv: 28.67, lr: 0.0500, time: 15.91
[000049] f: 2.064, acc: 25.08, fv: 2.020, accv: 25.75, lr: 0.0500, time: 15.20
[000051] f: 1.998, acc: 26.66, fv: 1.973, accv: 26.53, lr: 0.0500, time: 17.15
[000063] f: 2.172, acc: 24.88, fv: 2.357, accv: 23.95, lr: 0.0500, time: 15.10
[000075] f: 2.197, acc: 21.30, fv: 2.320, accv: 21.70, lr: 0.0500, time: 15.08
[000087] f: 1.796, acc: 33.43, fv: 1.855, accv: 32.50, lr: 0.0500, time: 15.29
[000099] f: 1.627, acc: 40.26, fv: 1.628, accv: 39.93, lr: 0.0500, time: 14.81
[000101] f: 1.631, acc: 39.71, fv: 1.601, accv: 40.46, lr: 0.0500, time: 14.85
[000113] f: 1.758, acc: 34.96, fv: 1.812, accv: 34.25, lr: 0.0500, time: 14.57
[000125] f: 1.741, acc: 38.42, fv: 1.824, accv: 37.25, lr: 0.0500, time: 15.27
[000137] f: 1.558, acc: 42.93, fv: 1.599, accv: 41.91, lr: 0.0500, time: 14.35
[000149] f: 1.444, acc: 47.47, fv: 1.457, accv: 47.63, lr: 0.0500, time: 15.11
[000151] f: 1.462, acc: 48.35, fv: 1.544, accv: 46.64, lr: 0.0500, time: 15.07
[000163] f: 1.486, acc: 46.43, fv: 1.537, accv: 44.66, lr: 0.0500, time: 14.15
[000175] f: 1.629, acc: 40.75, fv: 1.684, accv: 40.88, lr: 0.0500, time: 15.58
[000187] f: 1.346, acc: 50.70, fv: 1.375, accv: 50.51, lr: 0.0500, time: 15.56
[000199] f: 1.426, acc: 49.26, fv: 1.508, accv: 48.10, lr: 0.0500, time: 16.91
[000201] f: 1.480, acc: 46.46, fv: 1.554, accv: 45.78, lr: 0.0500, time: 14.46
[000213] f: 1.280, acc: 54.78, fv: 1.360, accv: 53.21, lr: 0.0499, time: 16.32
[000225] f: 1.347, acc: 51.02, fv: 1.429, accv: 50.21, lr: 0.0499, time: 15.71
[000237] f: 1.188, acc: 57.63, fv: 1.218, accv: 55.97, lr: 0.0499, time: 14.45
[000249] f: 1.251, acc: 54.83, fv: 1.271, accv: 55.44, lr: 0.0499, time: 14.35
[000300] f: 1.128, acc: 59.48, fv: 1.198, accv: 58.79, lr: 0.0499, time: 15.05
[000350] f: 1.141, acc: 60.88, fv: 1.247, accv: 59.15, lr: 0.0498, time: 15.98
[000400] f: 0.931, acc: 67.11, fv: 0.993, accv: 65.77, lr: 0.0498, time: 15.02
[000450] f: 0.861, acc: 69.82, fv: 0.916, accv: 68.83, lr: 0.0498, time: 14.99
[000500] f: 0.864, acc: 70.20, fv: 0.937, accv: 68.40, lr: 0.0497, time: 15.77
[000550] f: 1.003, acc: 66.75, fv: 1.170, accv: 63.95, lr: 0.0496, time: 15.86
[000600] f: 1.089, acc: 62.54, fv: 1.192, accv: 61.15, lr: 0.0496, time: 18.47
[000650] f: 0.751, acc: 73.75, fv: 0.807, accv: 72.82, lr: 0.0495, time: 16.35
[000700] f: 0.690, acc: 75.91, fv: 0.749, accv: 74.17, lr: 0.0494, time: 15.15
[000750] f: 0.720, acc: 74.83, fv: 0.838, accv: 71.92, lr: 0.0493, time: 16.04
[000800] f: 0.699, acc: 75.44, fv: 0.806, accv: 72.98, lr: 0.0492, time: 15.14
[000850] f: 0.676, acc: 76.72, fv: 0.783, accv: 74.32, lr: 0.0491, time: 14.86
[000900] f: 0.882, acc: 70.30, fv: 0.992, accv: 69.12, lr: 0.0490, time: 15.36
[000950] f: 0.904, acc: 68.79, fv: 0.943, accv: 70.60, lr: 0.0489, time: 16.19
[001000] f: 0.640, acc: 77.88, fv: 0.691, accv: 77.07, lr: 0.0488, time: 15.04
[001050] f: 0.723, acc: 74.95, fv: 0.821, accv: 73.41, lr: 0.0487, time: 16.05
[001100] f: 0.671, acc: 76.32, fv: 0.765, accv: 74.90, lr: 0.0485, time: 15.97
[001150] f: 0.622, acc: 78.83, fv: 0.763, accv: 75.68, lr: 0.0484, time: 15.35
[001200] f: 0.634, acc: 78.18, fv: 0.829, accv: 74.13, lr: 0.0482, time: 16.11
[001250] f: 0.696, acc: 76.68, fv: 0.838, accv: 74.86, lr: 0.0481, time: 15.42
[001300] f: 0.668, acc: 77.20, fv: 0.757, accv: 75.98, lr: 0.0479, time: 15.79
[001450] f: 0.522, acc: 81.77, fv: 0.641, accv: 78.81, lr: 0.0475, time: 14.60
[001650] f: 0.484, acc: 82.63, fv: 0.627, accv: 80.42, lr: 0.0467, time: 17.41
[001850] f: 0.472, acc: 83.37, fv: 0.645, accv: 79.43, lr: 0.0459, time: 15.36
[002050] f: 0.557, acc: 80.66, fv: 0.752, accv: 76.85, lr: 0.0450, time: 15.93
[002250] f: 0.523, acc: 81.32, fv: 0.689, accv: 78.40, lr: 0.0440, time: 14.75
[002450] f: 0.399, acc: 85.99, fv: 0.667, accv: 79.97, lr: 0.0430, time: 16.20
[002650] f: 0.322, acc: 88.60, fv: 0.552, accv: 82.73, lr: 0.0418, time: 15.00
[002850] f: 0.371, acc: 87.04, fv: 0.608, accv: 81.63, lr: 0.0406, time: 15.46
[003050] f: 0.336, acc: 88.22, fv: 0.654, accv: 81.30, lr: 0.0394, time: 15.02
[003250] f: 0.410, acc: 85.28, fv: 0.689, accv: 80.22, lr: 0.0381, time: 15.21
[003800] f: 0.296, acc: 89.54, fv: 0.616, accv: 83.20, lr: 0.0342, time: 15.80
[004550] f: 0.239, acc: 91.56, fv: 0.624, accv: 83.87, lr: 0.0285, time: 15.27
[005300] f: 0.158, acc: 94.30, fv: 0.632, accv: 84.30, lr: 0.0226, time: 15.75
[006050] f: 0.123, acc: 95.56, fv: 0.613, accv: 85.51, lr: 0.0169, time: 15.91
[006800] f: 0.103, acc: 96.32, fv: 0.651, accv: 85.53, lr: 0.0116, time: 15.62
[007550] f: 0.054, acc: 98.26, fv: 0.613, accv: 86.58, lr: 0.0070, time: 15.10
[008300] f: 0.039, acc: 98.87, fv: 0.619, accv: 86.90, lr: 0.0035, time: 15.94
[009050] f: 0.031, acc: 99.18, fv: 0.614, accv: 86.86, lr: 0.0011, time: 15.33
[009800] f: 0.029, acc: 99.29, fv: 0.617, accv: 86.89, lr: 0.0000, time: 14.15
[010000] f: 0.030, acc: 99.19, fv: 0.617, accv: 86.92, lr: 0.0000, time: 14.08
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0500, time: 13.27
[000001] f: 496.080, acc: 10.00, fv: 492.732, accv: 10.00, lr: 0.0500, time: 10.48
[000013] f: 2.540, acc: 12.21, fv: 2.539, accv: 12.36, lr: 0.0500, time: 10.77
[000025] f: 2.337, acc: 13.46, fv: 2.335, accv: 13.98, lr: 0.0500, time: 9.85
[000037] f: 2.132, acc: 20.34, fv: 2.129, accv: 20.75, lr: 0.0500, time: 11.48
[000049] f: 2.303, acc: 12.60, fv: 2.304, accv: 12.36, lr: 0.0500, time: 9.90
[000051] f: 2.259, acc: 12.99, fv: 2.258, accv: 12.95, lr: 0.0500, time: 12.34
[000063] f: 2.133, acc: 18.20, fv: 2.135, accv: 17.79, lr: 0.0500, time: 11.02
[000075] f: 1.966, acc: 25.61, fv: 1.965, accv: 25.76, lr: 0.0500, time: 10.57
[000087] f: 1.970, acc: 26.70, fv: 1.971, accv: 26.40, lr: 0.0500, time: 10.70
[000099] f: 2.116, acc: 22.49, fv: 2.115, accv: 22.24, lr: 0.0500, time: 11.39
[000101] f: 1.917, acc: 32.08, fv: 1.926, accv: 31.64, lr: 0.0500, time: 10.53
[000113] f: 1.695, acc: 38.90, fv: 1.684, accv: 38.56, lr: 0.0500, time: 10.97
[000125] f: 1.649, acc: 41.02, fv: 1.650, accv: 40.66, lr: 0.0500, time: 13.88
[000137] f: 1.744, acc: 37.80, fv: 1.750, accv: 37.08, lr: 0.0500, time: 10.11
[000149] f: 1.674, acc: 37.50, fv: 1.686, accv: 37.07, lr: 0.0500, time: 11.21
[000151] f: 1.976, acc: 35.20, fv: 1.962, accv: 35.52, lr: 0.0500, time: 10.45
[000163] f: 1.732, acc: 38.25, fv: 1.743, accv: 37.21, lr: 0.0500, time: 12.25
[000175] f: 2.138, acc: 33.37, fv: 2.138, accv: 33.05, lr: 0.0500, time: 14.10
[000187] f: 1.800, acc: 39.42, fv: 1.827, accv: 39.25, lr: 0.0500, time: 10.06
[000199] f: 2.120, acc: 33.58, fv: 2.127, accv: 33.18, lr: 0.0500, time: 11.22
[000201] f: 1.745, acc: 42.51, fv: 1.754, accv: 42.82, lr: 0.0500, time: 11.05
[000213] f: 1.556, acc: 44.21, fv: 1.541, accv: 44.83, lr: 0.0499, time: 10.46
[000225] f: 1.475, acc: 46.44, fv: 1.490, accv: 45.82, lr: 0.0499, time: 10.41
[000237] f: 1.721, acc: 41.68, fv: 1.722, accv: 41.28, lr: 0.0499, time: 10.67
[000249] f: 1.689, acc: 42.63, fv: 1.702, accv: 42.76, lr: 0.0499, time: 11.32
[000300] f: 1.941, acc: 40.42, fv: 1.937, accv: 40.43, lr: 0.0499, time: 10.88
[000350] f: 1.295, acc: 52.42, fv: 1.302, accv: 52.23, lr: 0.0498, time: 11.84
[000400] f: 1.328, acc: 53.66, fv: 1.348, accv: 52.71, lr: 0.0498, time: 10.85
[000450] f: 1.380, acc: 53.19, fv: 1.404, accv: 52.35, lr: 0.0498, time: 11.22
[000500] f: 1.678, acc: 41.87, fv: 1.695, accv: 41.95, lr: 0.0497, time: 11.76
[000550] f: 1.362, acc: 50.57, fv: 1.383, accv: 49.74, lr: 0.0496, time: 10.49
[000600] f: 2.191, acc: 35.86, fv: 2.198, accv: 35.74, lr: 0.0496, time: 10.31
[000650] f: 2.808, acc: 36.41, fv: 2.847, accv: 35.83, lr: 0.0495, time: 11.64
[000700] f: 1.601, acc: 46.35, fv: 1.625, accv: 45.84, lr: 0.0494, time: 10.56
[000750] f: 1.548, acc: 47.51, fv: 1.545, accv: 47.53, lr: 0.0493, time: 11.49
[000800] f: 1.683, acc: 45.52, fv: 1.713, accv: 44.94, lr: 0.0492, time: 12.06
[000850] f: 1.525, acc: 51.19, fv: 1.545, accv: 50.78, lr: 0.0491, time: 11.78
[000900] f: 1.493, acc: 52.07, fv: 1.523, accv: 51.58, lr: 0.0490, time: 11.05
[000950] f: 1.819, acc: 42.06, fv: 1.845, accv: 42.17, lr: 0.0489, time: 11.31
[001000] f: 1.810, acc: 44.50, fv: 1.828, accv: 44.52, lr: 0.0488, time: 10.90
[001050] f: 2.402, acc: 33.72, fv: 2.440, accv: 32.60, lr: 0.0487, time: 10.39
[001100] f: 1.479, acc: 50.33, fv: 1.495, accv: 49.65, lr: 0.0485, time: 11.25
[001150] f: 1.801, acc: 42.01, fv: 1.829, accv: 41.32, lr: 0.0484, time: 11.56
[001200] f: 1.671, acc: 44.88, fv: 1.688, accv: 43.64, lr: 0.0482, time: 11.37
[001250] f: 1.251, acc: 54.20, fv: 1.267, accv: 53.21, lr: 0.0481, time: 10.40
[001300] f: 1.385, acc: 51.16, fv: 1.410, accv: 50.87, lr: 0.0479, time: 12.61
[001450] f: 1.553, acc: 48.44, fv: 1.573, accv: 47.54, lr: 0.0475, time: 10.84
[001650] f: 1.282, acc: 56.53, fv: 1.296, accv: 56.42, lr: 0.0467, time: 12.86
[001850] f: 1.667, acc: 46.10, fv: 1.692, accv: 45.25, lr: 0.0459, time: 12.19
[002050] f: 1.358, acc: 52.33, fv: 1.380, accv: 51.92, lr: 0.0450, time: 11.70
[002250] f: 1.118, acc: 60.30, fv: 1.150, accv: 59.66, lr: 0.0440, time: 10.96
[002450] f: 1.488, acc: 51.54, fv: 1.513, accv: 50.76, lr: 0.0430, time: 11.60
[002650] f: 1.345, acc: 52.30, fv: 1.369, accv: 51.56, lr: 0.0418, time: 11.89
[002850] f: 1.562, acc: 45.57, fv: 1.587, accv: 45.29, lr: 0.0406, time: 12.00
[003050] f: 1.074, acc: 62.61, fv: 1.093, accv: 61.27, lr: 0.0394, time: 11.79
[003250] f: 1.211, acc: 55.89, fv: 1.252, accv: 54.41, lr: 0.0381, time: 10.91
[003800] f: 1.583, acc: 49.88, fv: 1.600, accv: 49.76, lr: 0.0342, time: 11.69
[004550] f: 1.285, acc: 56.35, fv: 1.333, accv: 55.46, lr: 0.0285, time: 10.90
[005300] f: 1.062, acc: 62.88, fv: 1.115, accv: 61.24, lr: 0.0226, time: 10.89
[006050] f: 1.382, acc: 57.07, fv: 1.437, accv: 55.56, lr: 0.0169, time: 11.13
[006800] f: 0.824, acc: 72.05, fv: 0.887, accv: 69.72, lr: 0.0116, time: 11.02
[007550] f: 0.770, acc: 73.81, fv: 0.876, accv: 69.45, lr: 0.0070, time: 11.38
[008300] f: 0.711, acc: 75.85, fv: 0.852, accv: 70.19, lr: 0.0035, time: 11.54
[009050] f: 0.529, acc: 84.18, fv: 0.714, accv: 75.74, lr: 0.0011, time: 10.73
[009800] f: 0.438, acc: 88.49, fv: 0.680, accv: 77.15, lr: 0.0000, time: 11.20
[010000] f: 0.436, acc: 88.57, fv: 0.679, accv: 77.10, lr: 0.0000, time: 10.37
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0500, time: 18.61
[000001] f: 470.914, acc: 10.00, fv: 415.571, accv: 10.00, lr: 0.0500, time: 14.98
[000013] f: 2.265, acc: 19.44, fv: 2.284, accv: 19.47, lr: 0.0500, time: 16.33
[000025] f: 2.277, acc: 16.89, fv: 2.268, accv: 17.05, lr: 0.0500, time: 15.56
[000037] f: 2.551, acc: 10.18, fv: 2.552, accv: 10.46, lr: 0.0500, time: 14.70
[000049] f: 2.372, acc: 10.85, fv: 2.384, accv: 10.56, lr: 0.0500, time: 15.70
[000051] f: 2.452, acc: 10.85, fv: 2.447, accv: 10.87, lr: 0.0500, time: 14.79
[000063] f: 2.277, acc: 17.76, fv: 2.267, accv: 17.74, lr: 0.0500, time: 16.92
[000075] f: 2.080, acc: 16.93, fv: 2.036, accv: 17.37, lr: 0.0500, time: 15.28
[000087] f: 2.242, acc: 21.11, fv: 2.402, accv: 19.62, lr: 0.0500, time: 15.62
[000099] f: 1.733, acc: 37.51, fv: 1.794, accv: 38.25, lr: 0.0500, time: 15.97
[000101] f: 3.079, acc: 16.87, fv: 3.373, accv: 17.03, lr: 0.0500, time: 16.44
[000113] f: 2.341, acc: 19.55, fv: 2.539, accv: 19.97, lr: 0.0500, time: 16.02
[000125] f: 1.860, acc: 30.21, fv: 1.826, accv: 31.67, lr: 0.0500, time: 16.80
[000137] f: 2.418, acc: 30.20, fv: 2.671, accv: 29.54, lr: 0.0500, time: 14.78
[000149] f: 2.258, acc: 27.58, fv: 2.299, accv: 29.34, lr: 0.0500, time: 17.67
[000151] f: 2.014, acc: 34.01, fv: 2.109, accv: 33.75, lr: 0.0500, time: 15.22
[000163] f: 1.632, acc: 42.31, fv: 1.605, accv: 43.20, lr: 0.0500, time: 15.44
[000175] f: 1.989, acc: 34.52, fv: 2.037, accv: 33.96, lr: 0.0500, time: 14.74
[000187] f: 2.095, acc: 34.02, fv: 2.470, accv: 32.84, lr: 0.0500, time: 14.61
[000199] f: 1.687, acc: 39.44, fv: 1.740, accv: 39.24, lr: 0.0500, time: 14.65
[000201] f: 1.568, acc: 43.41, fv: 1.573, accv: 44.35, lr: 0.0500, time: 15.68
[000213] f: 1.715, acc: 42.35, fv: 1.753, accv: 42.68, lr: 0.0499, time: 15.48
[000225] f: 1.839, acc: 38.43, fv: 1.852, accv: 40.75, lr: 0.0499, time: 16.50
[000237] f: 2.348, acc: 32.27, fv: 2.519, accv: 30.05, lr: 0.0499, time: 15.72
[000249] f: 1.970, acc: 35.10, fv: 1.952, accv: 37.27, lr: 0.0499, time: 17.05
[000300] f: 2.212, acc: 39.36, fv: 2.485, accv: 39.26, lr: 0.0499, time: 15.09
[000350] f: 1.919, acc: 39.40, fv: 2.019, accv: 40.07, lr: 0.0498, time: 14.82
[000400] f: 1.905, acc: 37.59, fv: 2.095, accv: 37.05, lr: 0.0498, time: 15.17
[000450] f: 1.590, acc: 45.76, fv: 1.678, accv: 44.79, lr: 0.0498, time: 14.70
[000500] f: 2.601, acc: 27.53, fv: 2.614, accv: 30.86, lr: 0.0497, time: 16.36
[000550] f: 1.496, acc: 47.31, fv: 1.470, accv: 47.93, lr: 0.0496, time: 16.01
[000600] f: 1.657, acc: 43.08, fv: 1.744, accv: 43.56, lr: 0.0496, time: 15.29
[000650] f: 1.484, acc: 49.65, fv: 1.609, accv: 47.77, lr: 0.0495, time: 14.73
[000700] f: 1.584, acc: 46.48, fv: 1.752, accv: 43.37, lr: 0.0494, time: 15.39
[000750] f: 1.951, acc: 36.96, fv: 2.088, accv: 36.89, lr: 0.0493, time: 14.92
[000800] f: 1.572, acc: 45.98, fv: 1.632, accv: 45.68, lr: 0.0492, time: 15.27
[000850] f: 2.494, acc: 30.45, fv: 2.490, accv: 34.15, lr: 0.0491, time: 14.92
[000900] f: 1.326, acc: 52.70, fv: 1.307, accv: 53.17, lr: 0.0490, time: 15.31
[000950] f: 1.733, acc: 44.60, fv: 1.779, accv: 45.68, lr: 0.0489, time: 15.59
[001000] f: 1.883, acc: 40.34, fv: 1.769, accv: 43.40, lr: 0.0488, time: 15.69
[001050] f: 1.355, acc: 51.91, fv: 1.310, accv: 53.89, lr: 0.0487, time: 15.59
[001100] f: 2.248, acc: 35.45, fv: 2.436, accv: 36.36, lr: 0.0485, time: 15.76
[001150] f: 2.326, acc: 28.84, fv: 2.161, accv: 33.66, lr: 0.0484, time: 15.27
[001200] f: 1.577, acc: 42.00, fv: 1.570, accv: 43.15, lr: 0.0482, time: 17.45
[001250] f: 1.863, acc: 44.33, fv: 2.052, accv: 44.02, lr: 0.0481, time: 15.11
[001300] f: 1.501, acc: 49.08, fv: 1.536, accv: 49.43, lr: 0.0479, time: 14.62
[001450] f: 1.792, acc: 39.10, fv: 1.855, accv: 41.09, lr: 0.0475, time: 15.51
[001650] f: 1.370, acc: 50.99, fv: 1.347, accv: 51.97, lr: 0.0467, time: 15.30
[001850] f: 1.524, acc: 47.49, fv: 1.483, accv: 49.02, lr: 0.0459, time: 17.76
[002050] f: 1.440, acc: 50.11, fv: 1.520, accv: 49.19, lr: 0.0450, time: 15.14
[002250] f: 1.788, acc: 42.41, fv: 2.069, accv: 40.96, lr: 0.0440, time: 15.23
[002450] f: 1.508, acc: 46.53, fv: 1.505, accv: 48.32, lr: 0.0430, time: 15.32
[002650] f: 1.184, acc: 58.23, fv: 1.229, accv: 57.66, lr: 0.0418, time: 15.06
[002850] f: 1.672, acc: 42.64, fv: 1.726, accv: 44.80, lr: 0.0406, time: 17.13
[003050] f: 1.583, acc: 44.92, fv: 1.541, accv: 46.53, lr: 0.0394, time: 14.85
[003250] f: 1.473, acc: 50.06, fv: 1.459, accv: 51.11, lr: 0.0381, time: 14.66
[003800] f: 1.504, acc: 51.23, fv: 1.453, accv: 54.25, lr: 0.0342, time: 15.40
[004550] f: 1.351, acc: 53.60, fv: 1.339, accv: 54.89, lr: 0.0285, time: 15.70
[005300] f: 1.496, acc: 49.58, fv: 1.609, accv: 49.41, lr: 0.0226, time: 15.29
[006050] f: 1.178, acc: 59.64, fv: 1.200, accv: 59.34, lr: 0.0169, time: 15.45
[006800] f: 0.975, acc: 66.15, fv: 0.969, accv: 66.72, lr: 0.0116, time: 16.90
[007550] f: 0.956, acc: 67.01, fv: 0.983, accv: 65.80, lr: 0.0070, time: 16.97
[008300] f: 0.821, acc: 71.85, fv: 0.831, accv: 71.08, lr: 0.0035, time: 15.89
[009050] f: 0.722, acc: 76.30, fv: 0.733, accv: 74.98, lr: 0.0011, time: 16.09
[009800] f: 0.669, acc: 78.19, fv: 0.679, accv: 77.00, lr: 0.0000, time: 15.22
[010000] f: 0.667, acc: 78.24, fv: 0.677, accv: 77.05, lr: 0.0000, time: 14.81
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0500, time: 14.70
[000001] f: 523.566, acc: 10.00, fv: 520.004, accv: 10.00, lr: 0.0500, time: 10.63
[000013] f: 5.725, acc: 12.53, fv: 5.754, accv: 12.61, lr: 0.0500, time: 11.77
[000025] f: 2.445, acc: 18.94, fv: 2.423, accv: 19.45, lr: 0.0500, time: 10.96
[000037] f: 1.916, acc: 27.64, fv: 1.909, accv: 27.93, lr: 0.0500, time: 11.24
[000049] f: 1.878, acc: 29.20, fv: 1.881, accv: 29.41, lr: 0.0500, time: 11.76
[000051] f: 1.842, acc: 31.39, fv: 1.843, accv: 31.18, lr: 0.0500, time: 10.08
[000063] f: 1.962, acc: 29.68, fv: 1.959, accv: 29.08, lr: 0.0500, time: 10.95
[000075] f: 1.757, acc: 35.05, fv: 1.749, accv: 35.25, lr: 0.0500, time: 10.05
[000087] f: 1.667, acc: 36.68, fv: 1.671, accv: 36.56, lr: 0.0500, time: 10.92
[000099] f: 1.688, acc: 37.32, fv: 1.694, accv: 37.24, lr: 0.0500, time: 10.76
[000101] f: 1.587, acc: 41.80, fv: 1.591, accv: 42.02, lr: 0.0500, time: 14.01
[000113] f: 1.533, acc: 44.33, fv: 1.543, accv: 43.67, lr: 0.0500, time: 10.18
[000125] f: 1.652, acc: 41.21, fv: 1.666, accv: 40.60, lr: 0.0500, time: 12.39
[000137] f: 1.421, acc: 49.44, fv: 1.431, accv: 48.95, lr: 0.0500, time: 11.10
[000149] f: 1.523, acc: 44.42, fv: 1.544, accv: 43.96, lr: 0.0500, time: 10.09
[000151] f: 1.472, acc: 46.80, fv: 1.493, accv: 46.07, lr: 0.0500, time: 11.85
[000163] f: 1.469, acc: 46.52, fv: 1.497, accv: 45.04, lr: 0.0500, time: 10.15
[000175] f: 1.419, acc: 49.50, fv: 1.443, accv: 48.82, lr: 0.0500, time: 11.77
[000187] f: 1.358, acc: 49.69, fv: 1.375, accv: 48.86, lr: 0.0500, time: 10.29
[000199] f: 1.357, acc: 51.99, fv: 1.380, accv: 50.69, lr: 0.0500, time: 12.29
[000201] f: 1.311, acc: 53.11, fv: 1.337, accv: 51.54, lr: 0.0500, time: 10.54
[000213] f: 1.436, acc: 49.02, fv: 1.474, accv: 47.61, lr: 0.0499, time: 10.31
[000225] f: 1.254, acc: 54.36, fv: 1.287, accv: 52.58, lr: 0.0499, time: 10.55
[000237] f: 1.235, acc: 56.92, fv: 1.272, accv: 56.11, lr: 0.0499, time: 10.73
[000249] f: 1.175, acc: 58.98, fv: 1.211, accv: 57.46, lr: 0.0499, time: 11.85
[000300] f: 1.069, acc: 60.50, fv: 1.123, accv: 59.24, lr: 0.0499, time: 10.53
[000350] f: 1.189, acc: 58.19, fv: 1.249, accv: 56.83, lr: 0.0498, time: 10.68
[000400] f: 0.986, acc: 65.37, fv: 1.064, accv: 62.80, lr: 0.0498, time: 12.61
[000450] f: 1.095, acc: 62.58, fv: 1.219, accv: 59.64, lr: 0.0498, time: 11.28
[000500] f: 0.923, acc: 67.54, fv: 1.068, accv: 63.79, lr: 0.0497, time: 10.47
[000550] f: 1.127, acc: 62.24, fv: 1.314, accv: 58.21, lr: 0.0496, time: 10.44
[000600] f: 0.766, acc: 73.18, fv: 0.939, accv: 67.81, lr: 0.0496, time: 12.00
[000650] f: 1.076, acc: 62.53, fv: 1.277, accv: 58.17, lr: 0.0495, time: 11.86
[000700] f: 0.731, acc: 73.82, fv: 0.967, accv: 67.56, lr: 0.0494, time: 10.96
[000750] f: 0.775, acc: 74.16, fv: 1.033, accv: 68.31, lr: 0.0493, time: 10.63
[000800] f: 0.938, acc: 70.87, fv: 1.232, accv: 65.05, lr: 0.0492, time: 10.42
[000850] f: 0.610, acc: 78.15, fv: 0.923, accv: 69.29, lr: 0.0491, time: 12.46
[000900] f: 0.612, acc: 78.93, fv: 0.967, accv: 70.59, lr: 0.0490, time: 10.65
[000950] f: 0.715, acc: 76.10, fv: 1.084, accv: 67.34, lr: 0.0489, time: 10.80
[001000] f: 0.621, acc: 77.88, fv: 1.034, accv: 67.99, lr: 0.0488, time: 10.34
[001050] f: 0.592, acc: 78.69, fv: 0.956, accv: 69.15, lr: 0.0487, time: 11.79
[001100] f: 0.600, acc: 78.82, fv: 1.070, accv: 67.80, lr: 0.0485, time: 11.12
[001150] f: 0.570, acc: 80.17, fv: 1.045, accv: 69.25, lr: 0.0484, time: 10.48
[001200] f: 0.571, acc: 81.29, fv: 1.097, accv: 68.94, lr: 0.0482, time: 10.43
[001250] f: 0.517, acc: 82.04, fv: 1.040, accv: 70.16, lr: 0.0481, time: 10.51
[001300] f: 0.704, acc: 74.26, fv: 1.201, accv: 64.31, lr: 0.0479, time: 10.98
[001450] f: 0.599, acc: 79.03, fv: 1.166, accv: 67.34, lr: 0.0475, time: 10.80
[001650] f: 0.346, acc: 87.51, fv: 0.966, accv: 72.11, lr: 0.0467, time: 10.41
[001850] f: 0.505, acc: 82.08, fv: 1.193, accv: 68.27, lr: 0.0459, time: 11.16
[002050] f: 0.486, acc: 82.91, fv: 1.160, accv: 68.91, lr: 0.0450, time: 11.29
[002250] f: 0.665, acc: 78.24, fv: 1.493, accv: 65.71, lr: 0.0440, time: 11.37
[002450] f: 0.450, acc: 83.99, fv: 1.225, accv: 68.95, lr: 0.0430, time: 12.93
[002650] f: 0.422, acc: 85.90, fv: 1.208, accv: 69.89, lr: 0.0418, time: 10.74
[002850] f: 0.474, acc: 84.46, fv: 1.371, accv: 67.63, lr: 0.0406, time: 12.03
[003050] f: 0.191, acc: 93.20, fv: 0.956, accv: 75.09, lr: 0.0394, time: 10.44
[003250] f: 0.375, acc: 87.36, fv: 1.220, accv: 70.84, lr: 0.0381, time: 10.78
[003800] f: 0.429, acc: 86.77, fv: 1.371, accv: 69.67, lr: 0.0342, time: 11.57
[004550] f: 0.174, acc: 93.79, fv: 1.145, accv: 74.03, lr: 0.0285, time: 11.01
[005300] f: 0.002, acc: 100.00, fv: 0.839, accv: 79.73, lr: 0.0226, time: 10.50
[006050] f: 0.133, acc: 95.62, fv: 0.851, accv: 76.60, lr: 0.0169, time: 10.66
[006800] f: 0.003, acc: 100.00, fv: 0.827, accv: 78.99, lr: 0.0116, time: 10.82
[007550] f: 0.004, acc: 100.00, fv: 0.782, accv: 80.10, lr: 0.0070, time: 10.32
[008300] f: 0.002, acc: 100.00, fv: 0.811, accv: 79.81, lr: 0.0035, time: 11.82
[009050] f: 0.001, acc: 100.00, fv: 0.824, accv: 79.61, lr: 0.0011, time: 10.59
[009800] f: 0.001, acc: 100.00, fv: 0.826, accv: 79.46, lr: 0.0000, time: 10.36
[010000] f: 0.001, acc: 100.00, fv: 0.828, accv: 79.45, lr: 0.0000, time: 10.24
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/adam-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  399486
[000000] f: 2.303, acc: 10.00, fv: 2.303, accv: 10.00, lr: 0.0500, time: 18.44
[000001] f: 520.408, acc: 10.00, fv: 460.448, accv: 10.00, lr: 0.0500, time: 16.47
[000013] f: 3.432, acc: 15.15, fv: 3.746, accv: 15.63, lr: 0.0500, time: 14.66
[000025] f: 2.365, acc: 20.45, fv: 2.370, accv: 21.15, lr: 0.0500, time: 16.85
[000037] f: 1.983, acc: 27.10, fv: 1.969, accv: 27.88, lr: 0.0500, time: 14.86
[000049] f: 2.028, acc: 26.09, fv: 1.999, accv: 26.03, lr: 0.0500, time: 16.55
[000051] f: 2.410, acc: 18.11, fv: 2.494, accv: 18.56, lr: 0.0500, time: 16.32
[000063] f: 1.925, acc: 29.25, fv: 1.990, accv: 28.43, lr: 0.0500, time: 14.91
[000075] f: 2.159, acc: 20.86, fv: 2.274, accv: 20.59, lr: 0.0500, time: 14.76
[000087] f: 1.758, acc: 33.55, fv: 1.776, accv: 33.39, lr: 0.0500, time: 15.02
[000099] f: 1.765, acc: 36.14, fv: 1.839, accv: 35.30, lr: 0.0500, time: 16.25
[000101] f: 1.743, acc: 35.64, fv: 1.773, accv: 34.40, lr: 0.0500, time: 15.32
[000113] f: 1.574, acc: 42.03, fv: 1.586, accv: 41.03, lr: 0.0500, time: 16.34
[000125] f: 1.537, acc: 43.18, fv: 1.573, accv: 42.67, lr: 0.0500, time: 15.84
[000137] f: 1.687, acc: 40.55, fv: 1.805, accv: 39.35, lr: 0.0500, time: 14.87
[000149] f: 1.528, acc: 44.54, fv: 1.576, accv: 43.63, lr: 0.0500, time: 18.77
[000151] f: 1.547, acc: 46.13, fv: 1.599, accv: 45.36, lr: 0.0500, time: 16.48
[000163] f: 1.516, acc: 44.51, fv: 1.627, accv: 41.22, lr: 0.0500, time: 15.20
[000175] f: 1.497, acc: 43.63, fv: 1.500, accv: 44.11, lr: 0.0500, time: 16.67
[000187] f: 1.464, acc: 45.76, fv: 1.555, accv: 44.31, lr: 0.0500, time: 15.02
[000199] f: 1.704, acc: 43.47, fv: 1.802, accv: 43.27, lr: 0.0500, time: 15.31
[000201] f: 1.535, acc: 47.40, fv: 1.558, accv: 48.43, lr: 0.0500, time: 16.62
[000213] f: 1.171, acc: 58.04, fv: 1.215, accv: 57.47, lr: 0.0499, time: 16.96
[000225] f: 1.360, acc: 50.96, fv: 1.450, accv: 50.10, lr: 0.0499, time: 15.82
[000237] f: 1.208, acc: 56.92, fv: 1.275, accv: 56.38, lr: 0.0499, time: 16.06
[000249] f: 1.307, acc: 53.57, fv: 1.309, accv: 54.25, lr: 0.0499, time: 17.74
[000300] f: 1.306, acc: 54.73, fv: 1.489, accv: 51.46, lr: 0.0499, time: 16.43
[000350] f: 1.383, acc: 54.37, fv: 1.549, accv: 53.25, lr: 0.0498, time: 16.55
[000400] f: 0.952, acc: 66.62, fv: 1.013, accv: 65.21, lr: 0.0498, time: 15.43
[000450] f: 1.085, acc: 62.05, fv: 1.136, accv: 62.56, lr: 0.0498, time: 15.96
[000500] f: 0.897, acc: 69.00, fv: 0.997, accv: 67.40, lr: 0.0497, time: 15.52
[000550] f: 1.028, acc: 64.57, fv: 1.006, accv: 66.91, lr: 0.0496, time: 15.39
[000600] f: 1.326, acc: 58.04, fv: 1.392, accv: 58.34, lr: 0.0496, time: 15.66
[000650] f: 1.053, acc: 65.74, fv: 1.126, accv: 64.97, lr: 0.0495, time: 16.29
[000700] f: 0.931, acc: 68.17, fv: 1.011, accv: 67.64, lr: 0.0494, time: 15.93
[000750] f: 1.174, acc: 63.61, fv: 1.169, accv: 65.40, lr: 0.0493, time: 17.01
[000800] f: 0.744, acc: 73.96, fv: 0.805, accv: 73.24, lr: 0.0492, time: 16.88
[000850] f: 0.890, acc: 69.57, fv: 0.949, accv: 69.36, lr: 0.0491, time: 15.05
[000900] f: 0.903, acc: 68.91, fv: 0.901, accv: 70.50, lr: 0.0490, time: 16.02
[000950] f: 0.660, acc: 77.28, fv: 0.732, accv: 75.25, lr: 0.0489, time: 16.67
[001000] f: 1.163, acc: 62.77, fv: 1.229, accv: 63.49, lr: 0.0488, time: 15.58
[001050] f: 0.728, acc: 74.98, fv: 0.835, accv: 73.07, lr: 0.0487, time: 16.53
[001100] f: 0.810, acc: 72.75, fv: 0.904, accv: 71.68, lr: 0.0485, time: 14.92
[001150] f: 0.985, acc: 66.44, fv: 1.014, accv: 66.68, lr: 0.0484, time: 14.87
[001200] f: 0.713, acc: 75.78, fv: 0.847, accv: 73.62, lr: 0.0482, time: 16.50
[001250] f: 0.896, acc: 70.17, fv: 0.954, accv: 71.30, lr: 0.0481, time: 15.87
[001300] f: 0.899, acc: 71.10, fv: 0.995, accv: 69.60, lr: 0.0479, time: 14.82
[001450] f: 0.825, acc: 71.55, fv: 0.845, accv: 72.11, lr: 0.0475, time: 17.27
[001650] f: 0.873, acc: 71.21, fv: 0.957, accv: 70.25, lr: 0.0467, time: 15.49
[001850] f: 0.851, acc: 70.80, fv: 0.910, accv: 71.30, lr: 0.0459, time: 15.29
[002050] f: 0.799, acc: 72.62, fv: 0.896, accv: 71.50, lr: 0.0450, time: 16.97
[002250] f: 0.898, acc: 70.33, fv: 0.943, accv: 70.84, lr: 0.0440, time: 16.84
[002450] f: 0.661, acc: 77.39, fv: 0.726, accv: 76.71, lr: 0.0430, time: 15.48
[002650] f: 0.763, acc: 74.98, fv: 0.906, accv: 72.26, lr: 0.0418, time: 15.22
[002850] f: 0.553, acc: 80.44, fv: 0.640, accv: 78.54, lr: 0.0406, time: 16.68
[003050] f: 0.807, acc: 75.12, fv: 0.869, accv: 75.17, lr: 0.0394, time: 15.86
[003250] f: 0.576, acc: 79.53, fv: 0.640, accv: 78.60, lr: 0.0381, time: 16.60
[003800] f: 0.733, acc: 76.32, fv: 0.842, accv: 74.69, lr: 0.0342, time: 15.93
[004550] f: 0.490, acc: 83.35, fv: 0.626, accv: 80.95, lr: 0.0285, time: 15.14
[005300] f: 0.601, acc: 80.33, fv: 0.704, accv: 79.46, lr: 0.0226, time: 18.91
[006050] f: 0.456, acc: 83.84, fv: 0.632, accv: 80.46, lr: 0.0169, time: 15.63
[006800] f: 0.280, acc: 90.13, fv: 0.481, accv: 84.73, lr: 0.0116, time: 15.61
[007550] f: 0.205, acc: 93.00, fv: 0.439, accv: 86.19, lr: 0.0070, time: 16.04
[008300] f: 0.150, acc: 94.93, fv: 0.428, accv: 87.06, lr: 0.0035, time: 15.03
[009050] f: 0.113, acc: 96.45, fv: 0.405, accv: 87.75, lr: 0.0011, time: 15.52
[009800] f: 0.101, acc: 96.91, fv: 0.409, accv: 87.85, lr: 0.0000, time: 14.62
[010000] f: 0.103, acc: 96.88, fv: 0.409, accv: 87.71, lr: 0.0000, time: 14.64
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 188.00 MiB (GPU 0; 22.20 GiB total capacity; 7.40 MiB already allocated; 71.06 MiB free; 22.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 376.00 MiB (GPU 0; 22.20 GiB total capacity; 13.55 MiB already allocated; 384.06 MiB free; 14.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 376.00 MiB (GPU 0; 22.20 GiB total capacity; 13.55 MiB already allocated; 384.06 MiB free; 14.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 376.00 MiB (GPU 0; 22.20 GiB total capacity; 13.55 MiB already allocated; 384.06 MiB free; 14.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 376.00 MiB (GPU 0; 22.20 GiB total capacity; 13.55 MiB already allocated; 384.06 MiB free; 14.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgd-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 376.00 MiB (GPU 0; 22.20 GiB total capacity; 13.55 MiB already allocated; 384.06 MiB free; 14.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 376.00 MiB (GPU 0; 22.20 GiB total capacity; 13.55 MiB already allocated; 384.06 MiB free; 14.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 376.00 MiB (GPU 0; 22.20 GiB total capacity; 13.55 MiB already allocated; 384.06 MiB free; 14.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 376.00 MiB (GPU 0; 22.20 GiB total capacity; 13.55 MiB already allocated; 384.06 MiB free; 14.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 376.00 MiB (GPU 0; 22.20 GiB total capacity; 13.55 MiB already allocated; 384.06 MiB free; 14.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/allcnn.py", line 31, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 376.00 MiB (GPU 0; 22.20 GiB total capacity; 13.55 MiB already allocated; 384.06 MiB free; 14.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/allcnn.yaml', optim_config='./configs/optim/sgdn-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='allcnn', model_args={'num_classes': 10, 'c1': 96, 'c2': 144, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"allcnn","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  399486
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/adam-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgd-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/convmixer.yaml', optim_config='./configs/optim/sgdn-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='convmixer', model_args={'dim': 256, 'depth': 8, 'kernel_size': 5, 'patch_size': 2, 'n_classes': 10, 'bn': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"convmixer","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/convmixer.py", line 41, in forward
    return self.m(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 17.78 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 17.78 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 17.78 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 17.78 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 17.78 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 17.78 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 22.20 GiB total capacity; 30.29 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 22.20 GiB total capacity; 30.29 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/adam-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 17.78 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 17.78 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 22.20 GiB total capacity; 30.29 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 22.20 GiB total capacity; 30.29 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 17.78 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 17.78 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 22.20 GiB total capacity; 30.29 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 22.20 GiB total capacity; 30.29 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgd-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 17.78 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 17.78 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 17.78 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 17.78 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 22.20 GiB total capacity; 21.49 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 22.20 GiB total capacity; 30.29 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 22.20 GiB total capacity; 30.29 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 22.20 GiB total capacity; 30.29 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 22.20 GiB total capacity; 30.29 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 22.20 GiB total capacity; 30.29 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/fcnn.py", line 24, in forward
    x = l(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 22.20 GiB total capacity; 30.29 MiB already allocated; 10.06 MiB free; 34.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/fc.yaml', optim_config='./configs/optim/sgdn-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='fcnn', model_args={'dims': [3072, 1024, 512, 256, 128, 10], 'bn': True, 'bias': True, 'dropout_rate': 0.0}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"fc","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  3837066
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/adam-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgd-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.0}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.001}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/vit.yaml', optim_config='./configs/optim/sgdn-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='ViT', model_args={'image_size': 32, 'patch_size': 4, 'num_classes': 10, 'dim': 512, 'depth': 6, 'heads': 8, 'mlp_dim': 512, 'dropout_rate': 0.0, 'emb_dropout': 0.0, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"vit","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":1e-05}
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/vit.py", line 125, in forward
    x = self.to_patch_embedding(img)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/adam-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgd-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-10-4-8.yaml', optim_config='./configs/optim/sgdn-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 10, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 8, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-10-4-8","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  300226
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='Adam', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='Adam', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/adam-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='Adam', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"adam","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgd-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgd","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-200-0.01-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-200-0.1-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-200-0.01-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.01, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.01,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-200-0.1-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=200, epochs=200, opt='SGD', opt_args={'lr': 0.1, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":200,"lr":0.1,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-500-0.025-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-500-0.25-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-500-0.025-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.025, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.025,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-500-0.25-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=500, epochs=200, opt='SGD', opt_args={'lr': 0.25, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":500,"lr":0.25,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.0.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.0}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.0}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-1000-0.05-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-1000-0.5-0.001.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 0.001}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":0.001}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-1000-0.05-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.05, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.05,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 140, in main
    m = get_model(model_args, dev=dev)
  File "/home/ubuntu/ext_vol/inpca/utils/configure.py", line 41, in get_model
    return getattr(networks, m)(**model_args).to(dev)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 907, in to
    return self._apply(convert)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 578, in _apply
    module._apply(fn)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 601, in _apply
    param_applied = fn(param)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 905, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
namespace(seed=42, data_config='./configs/data/cifar10-none.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='none', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"none","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
namespace(seed=42, data_config='./configs/data/cifar10-simple.yaml', model_config='./configs/model/wr-16-4-64.yaml', optim_config='./configs/optim/sgdn-1000-0.5-1e-05.yaml', init_config='./configs/init/normal.yaml', data='CIFAR10', aug='simple', sub_sample=0, resize=1, shuffle=False, m='wide_resnet', model_args={'depth': 16, 'widen_factor': 4, 'dropout_rate': 0.0, 'num_classes': 10, 'in_planes': 64, 'bn': True}, autocast=False, batch_seed=-1, bs=1000, epochs=200, opt='SGD', opt_args={'lr': 0.5, 'momentum': 0.9, 'nesterov': True, 'weight_decay': 1e-05}, sched_args=None, scheduler='cosine', corner='normal')
{"seed":42,"bseed":-1,"aug":"simple","m":"wr-16-4-64","bn":true,"drop":0.0,"opt":"sgdn","bs":1000,"lr":0.5,"wd":1e-05}
Num parameters:  43890122
Traceback (most recent call last):
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 150, in <module>
    main()
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 144, in main
    ss = fit(m, ds, epochs=args.epochs, bs=optim_args['bs'], autocast=optim_args['autocast'], opt=optimizer, sched=scheduler, fix_batch=fix_batch)
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 57, in fit
    ss.append(helper(t))
  File "/home/ubuntu/ext_vol/inpca/runner.py", line 34, in helper
    yh.append(F.log_softmax(m(x), dim=1))
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/ext_vol/inpca/networks/wr.py", line 72, in forward
    out = self.conv1(x)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/ubuntu/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 250.00 MiB (GPU 0; 22.20 GiB total capacity; 179.50 MiB already allocated; 198.06 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
